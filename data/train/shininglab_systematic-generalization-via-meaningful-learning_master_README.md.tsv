#FORMAT=WebAnno TSV 3.3
#T_SP=de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity|identifier|value


#Text=# Systematic-Generalization-via-Meaningful-Learning
#Text=This repository is for the paper [Revisit Systematic Generalization via Meaningful Learning](https://aclanthology.org/2022.blackboxnlp-1.6).
1-1	0-1	#	_	_	
1-2	2-51	Systematic-Generalization-via-Meaningful-Learning	_	_	
1-3	52-56	This	_	_	
1-4	57-67	repository	_	_	
1-5	68-70	is	_	_	
1-6	71-74	for	_	_	
1-7	75-78	the	_	_	
1-8	79-84	paper	_	_	
1-9	85-86	[	_	_	
1-10	86-93	Revisit	*[1]	PUBLICATION[1]	
1-11	94-104	Systematic	*[1]	PUBLICATION[1]	
1-12	105-119	Generalization	*[1]	PUBLICATION[1]	
1-13	120-123	via	*[1]	PUBLICATION[1]	
1-14	124-134	Meaningful	*[1]	PUBLICATION[1]	
1-15	135-143	Learning	*[1]	PUBLICATION[1]	
1-16	143-144	]	_	_	
1-17	144-145	(	_	_	
1-18	145-150	https	_	_	
1-19	150-151	:	_	_	
1-20	151-152	/	_	_	
1-21	152-153	/	_	_	
1-22	153-169	aclanthology.org	_	_	
1-23	169-170	/	_	_	
1-24	170-174	2022	_	_	
1-25	174-175	.	_	_	
1-26	175-186	blackboxnlp	_	_	
1-27	186-187	-	_	_	
1-28	187-190	1.6	_	_	
1-29	190-191	)	_	_	
1-30	191-192	.	_	_	

#Text=*In Proceedings of the Fifth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP*, pages 62–79, Abu Dhabi, United Arab Emirates (Hybrid).
2-1	193-194	*	_	_	
2-2	194-196	In	_	_	
2-3	197-208	Proceedings	*[2]	PUBLICATION[2]	
2-4	209-211	of	*[2]	PUBLICATION[2]	
2-5	212-215	the	*[2]	PUBLICATION[2]	
2-6	216-221	Fifth	*[2]|*[3]	PUBLICATION[2]|WORKSHOP[3]	
2-7	222-233	BlackboxNLP	*[2]|*[3]	PUBLICATION[2]|WORKSHOP[3]	
2-8	234-242	Workshop	*[2]|*[3]	PUBLICATION[2]|WORKSHOP[3]	
2-9	243-245	on	*[2]|*[3]	PUBLICATION[2]|WORKSHOP[3]	
2-10	246-255	Analyzing	*[2]|*[3]	PUBLICATION[2]|WORKSHOP[3]	
2-11	256-259	and	*[2]|*[3]	PUBLICATION[2]|WORKSHOP[3]	
2-12	260-272	Interpreting	*[2]|*[3]	PUBLICATION[2]|WORKSHOP[3]	
2-13	273-279	Neural	*[2]|*[3]	PUBLICATION[2]|WORKSHOP[3]	
2-14	280-288	Networks	*[2]|*[3]	PUBLICATION[2]|WORKSHOP[3]	
2-15	289-292	for	*[2]|*[3]	PUBLICATION[2]|WORKSHOP[3]	
2-16	293-296	NLP	*[2]|*[3]	PUBLICATION[2]|WORKSHOP[3]	
2-17	296-297	*	_	_	
2-18	297-298	,	_	_	
2-19	299-304	pages	_	_	
2-20	305-307	62	_	_	
2-21	307-308	–	_	_	
2-22	308-310	79	_	_	
2-23	310-311	,	_	_	
2-24	312-315	Abu	_	_	
2-25	316-321	Dhabi	_	_	
2-26	321-322	,	_	_	
2-27	323-329	United	_	_	
2-28	330-334	Arab	_	_	
2-29	335-343	Emirates	_	_	
2-30	344-345	(	_	_	
2-31	345-351	Hybrid	_	_	
2-32	351-352	)	_	_	
2-33	352-353	.	_	_	

#Text=Association for Computational Linguistics.
3-1	354-365	Association	_	_	
3-2	366-369	for	_	_	
3-3	370-383	Computational	_	_	
3-4	384-395	Linguistics	_	_	
3-5	395-396	.	_	_	

#Text=[[arXiv](https://arxiv.org/abs/2003.06658)] [[Poster](https://www.shininglab.ai/assets/posters/Revisit%20Systematic%20Generalization%20via%20Meaningful%20Learning.pdf)]
#Text=
#Text=## Directory
#Text=+ **main/config.py** - Configurations
#Text=+ **main/res** - Resources including model check points, datasets, experiment records, and results
#Text=+ **main/src** - Source code including model structures and utility functions
#Text=```
#Text=Systematic-Generalization-via-Meaningful-Learning
#Text=├── README.md
#Text=├── main
#Text=│   ├── config.py
#Text=│   ├── res
#Text=│   │   ├── check_points
#Text=│   │   ├── data
#Text=│   │   │   ├── scan
#Text=│   │   │   ├── geography
#Text=│   │   │   ├── advising
#Text=│   │   │   ├── geo_vars.txt
#Text=│   │   │   ├── adv_vars.txt
#Text=│   │   │   ├── iwslt14
#Text=│   │   │   ├── iwslt15
#Text=│   │   │   ├── prepare-iwslt14.sh
#Text=│   │   │   └── prepare-iwslt15.sh
#Text=│   │   ├── log
#Text=│   │   └── result
#Text=│   ├── src
#Text=│   │   ├── models
#Text=│   │   └── utils
#Text=│   └── train.py
#Text=└── requirements.txt
#Text=```
#Text=
#Text=## Dependencies
#Text=+ python >= 3.10.6
#Text=+ tqdm >= 4.64.1
#Text=+ numpy >= 1.23.4
#Text=+ torch >= 1.13.0
#Text=
#Text=## Data
#Text=All datasets can be downloaded [here](https://drive.google.com/drive/folders/19vFBn5C-nTdjxMeuMgw-BvsPNsLF6DpV?
4-1	398-399	[	_	_	
4-2	399-400	[	_	_	
4-3	400-405	arXiv	_	_	
4-4	405-406	]	_	_	
4-5	406-407	(	_	_	
4-6	407-412	https	_	_	
4-7	412-413	:	_	_	
4-8	413-414	/	_	_	
4-9	414-415	/	_	_	
4-10	415-424	arxiv.org	_	_	
4-11	424-425	/	_	_	
4-12	425-428	abs	_	_	
4-13	428-429	/	_	_	
4-14	429-439	2003.06658	_	_	
4-15	439-440	)	_	_	
4-16	440-441	]	_	_	
4-17	442-443	[	_	_	
4-18	443-444	[	_	_	
4-19	444-450	Poster	_	_	
4-20	450-451	]	_	_	
4-21	451-452	(	_	_	
4-22	452-457	https	_	_	
4-23	457-458	:	_	_	
4-24	458-459	/	_	_	
4-25	459-460	/	_	_	
4-26	460-477	www.shininglab.ai	_	_	
4-27	477-478	/	_	_	
4-28	478-484	assets	_	_	
4-29	484-485	/	_	_	
4-30	485-492	posters	_	_	
4-31	492-493	/	_	_	
4-32	493-500	Revisit	_	_	
4-33	500-501	%	_	_	
4-34	501-513	20Systematic	_	_	
4-35	513-514	%	_	_	
4-36	514-530	20Generalization	_	_	
4-37	530-531	%	_	_	
4-38	531-536	20via	_	_	
4-39	536-537	%	_	_	
4-40	537-549	20Meaningful	_	_	
4-41	549-550	%	_	_	
4-42	550-564	20Learning.pdf	_	_	
4-43	564-565	)	_	_	
4-44	565-566	]	_	_	
4-45	568-569	#	_	_	
4-46	569-570	#	_	_	
4-47	571-580	Directory	_	_	
4-48	581-582	+	_	_	
4-49	583-584	*	_	_	
4-50	584-585	*	_	_	
4-51	585-589	main	_	_	
4-52	589-590	/	_	_	
4-53	590-599	config.py	_	_	
4-54	599-600	*	_	_	
4-55	600-601	*	_	_	
4-56	602-603	-	_	_	
4-57	604-618	Configurations	_	_	
4-58	619-620	+	_	_	
4-59	621-622	*	_	_	
4-60	622-623	*	_	_	
4-61	623-627	main	_	_	
4-62	627-628	/	_	_	
4-63	628-631	res	_	_	
4-64	631-632	*	_	_	
4-65	632-633	*	_	_	
4-66	634-635	-	_	_	
4-67	636-645	Resources	_	_	
4-68	646-655	including	_	_	
4-69	656-661	model	_	_	
4-70	662-667	check	_	_	
4-71	668-674	points	_	_	
4-72	674-675	,	_	_	
4-73	676-684	datasets	_	_	
4-74	684-685	,	_	_	
4-75	686-696	experiment	_	_	
4-76	697-704	records	_	_	
4-77	704-705	,	_	_	
4-78	706-709	and	_	_	
4-79	710-717	results	_	_	
4-80	718-719	+	_	_	
4-81	720-721	*	_	_	
4-82	721-722	*	_	_	
4-83	722-726	main	_	_	
4-84	726-727	/	_	_	
4-85	727-730	src	_	_	
4-86	730-731	*	_	_	
4-87	731-732	*	_	_	
4-88	733-734	-	_	_	
4-89	735-741	Source	_	_	
4-90	742-746	code	_	_	
4-91	747-756	including	_	_	
4-92	757-762	model	_	_	
4-93	763-773	structures	_	_	
4-94	774-777	and	_	_	
4-95	778-785	utility	_	_	
4-96	786-795	functions	_	_	
4-97	796-797	`	_	_	
4-98	797-798	`	_	_	
4-99	798-799	`	_	_	
4-100	800-849	Systematic-Generalization-via-Meaningful-Learning	_	_	
4-101	850-851	├	_	_	
4-102	851-852	─	_	_	
4-103	852-853	─	_	_	
4-104	854-863	README.md	_	_	
4-105	864-865	├	_	_	
4-106	865-866	─	_	_	
4-107	866-867	─	_	_	
4-108	868-872	main	_	_	
4-109	873-874	│	_	_	
4-110	877-878	├	_	_	
4-111	878-879	─	_	_	
4-112	879-880	─	_	_	
4-113	881-890	config.py	_	_	
4-114	891-892	│	_	_	
4-115	895-896	├	_	_	
4-116	896-897	─	_	_	
4-117	897-898	─	_	_	
4-118	899-902	res	_	_	
4-119	903-904	│	_	_	
4-120	907-908	│	_	_	
4-121	911-912	├	_	_	
4-122	912-913	─	_	_	
4-123	913-914	─	_	_	
4-124	915-927	check_points	_	_	
4-125	928-929	│	_	_	
4-126	932-933	│	_	_	
4-127	936-937	├	_	_	
4-128	937-938	─	_	_	
4-129	938-939	─	_	_	
4-130	940-944	data	_	_	
4-131	945-946	│	_	_	
4-132	949-950	│	_	_	
4-133	953-954	│	_	_	
4-134	957-958	├	_	_	
4-135	958-959	─	_	_	
4-136	959-960	─	_	_	
4-137	961-965	scan	_	_	
4-138	966-967	│	_	_	
4-139	970-971	│	_	_	
4-140	974-975	│	_	_	
4-141	978-979	├	_	_	
4-142	979-980	─	_	_	
4-143	980-981	─	_	_	
4-144	982-991	geography	_	_	
4-145	992-993	│	_	_	
4-146	996-997	│	_	_	
4-147	1000-1001	│	_	_	
4-148	1004-1005	├	_	_	
4-149	1005-1006	─	_	_	
4-150	1006-1007	─	_	_	
4-151	1008-1016	advising	_	_	
4-152	1017-1018	│	_	_	
4-153	1021-1022	│	_	_	
4-154	1025-1026	│	_	_	
4-155	1029-1030	├	_	_	
4-156	1030-1031	─	_	_	
4-157	1031-1032	─	_	_	
4-158	1033-1045	geo_vars.txt	_	_	
4-159	1046-1047	│	_	_	
4-160	1050-1051	│	_	_	
4-161	1054-1055	│	_	_	
4-162	1058-1059	├	_	_	
4-163	1059-1060	─	_	_	
4-164	1060-1061	─	_	_	
4-165	1062-1074	adv_vars.txt	_	_	
4-166	1075-1076	│	_	_	
4-167	1079-1080	│	_	_	
4-168	1083-1084	│	_	_	
4-169	1087-1088	├	_	_	
4-170	1088-1089	─	_	_	
4-171	1089-1090	─	_	_	
4-172	1091-1098	iwslt14	_	_	
4-173	1099-1100	│	_	_	
4-174	1103-1104	│	_	_	
4-175	1107-1108	│	_	_	
4-176	1111-1112	├	_	_	
4-177	1112-1113	─	_	_	
4-178	1113-1114	─	_	_	
4-179	1115-1122	iwslt15	_	_	
4-180	1123-1124	│	_	_	
4-181	1127-1128	│	_	_	
4-182	1131-1132	│	_	_	
4-183	1135-1136	├	_	_	
4-184	1136-1137	─	_	_	
4-185	1137-1138	─	_	_	
4-186	1139-1154	prepare-iwslt14	_	_	
4-187	1154-1155	.	_	_	
4-188	1155-1157	sh	_	_	
4-189	1158-1159	│	_	_	
4-190	1162-1163	│	_	_	
4-191	1166-1167	│	_	_	
4-192	1170-1171	└	_	_	
4-193	1171-1172	─	_	_	
4-194	1172-1173	─	_	_	
4-195	1174-1189	prepare-iwslt15	_	_	
4-196	1189-1190	.	_	_	
4-197	1190-1192	sh	_	_	
4-198	1193-1194	│	_	_	
4-199	1197-1198	│	_	_	
4-200	1201-1202	├	_	_	
4-201	1202-1203	─	_	_	
4-202	1203-1204	─	_	_	
4-203	1205-1208	log	_	_	
4-204	1209-1210	│	_	_	
4-205	1213-1214	│	_	_	
4-206	1217-1218	└	_	_	
4-207	1218-1219	─	_	_	
4-208	1219-1220	─	_	_	
4-209	1221-1227	result	_	_	
4-210	1228-1229	│	_	_	
4-211	1232-1233	├	_	_	
4-212	1233-1234	─	_	_	
4-213	1234-1235	─	_	_	
4-214	1236-1239	src	_	_	
4-215	1240-1241	│	_	_	
4-216	1244-1245	│	_	_	
4-217	1248-1249	├	_	_	
4-218	1249-1250	─	_	_	
4-219	1250-1251	─	_	_	
4-220	1252-1258	models	_	_	
4-221	1259-1260	│	_	_	
4-222	1263-1264	│	_	_	
4-223	1267-1268	└	_	_	
4-224	1268-1269	─	_	_	
4-225	1269-1270	─	_	_	
4-226	1271-1276	utils	_	_	
4-227	1277-1278	│	_	_	
4-228	1281-1282	└	_	_	
4-229	1282-1283	─	_	_	
4-230	1283-1284	─	_	_	
4-231	1285-1293	train.py	_	_	
4-232	1294-1295	└	_	_	
4-233	1295-1296	─	_	_	
4-234	1296-1297	─	_	_	
4-235	1298-1314	requirements.txt	_	_	
4-236	1315-1316	`	_	_	
4-237	1316-1317	`	_	_	
4-238	1317-1318	`	_	_	
4-239	1320-1321	#	_	_	
4-240	1321-1322	#	_	_	
4-241	1323-1335	Dependencies	_	_	
4-242	1336-1337	+	_	_	
4-243	1338-1344	python	*[4]	SOFTWARE[4]	
4-244	1345-1346	>	*[4]	SOFTWARE[4]	
4-245	1346-1347	=	*[4]	SOFTWARE[4]	
4-246	1348-1354	3.10.6	*[4]	SOFTWARE[4]	
4-247	1355-1356	+	_	_	
4-248	1357-1361	tqdm	*[5]	SOFTWARE[5]	
4-249	1362-1363	>	*[5]	SOFTWARE[5]	
4-250	1363-1364	=	*[5]	SOFTWARE[5]	
4-251	1365-1371	4.64.1	*[5]	SOFTWARE[5]	
4-252	1372-1373	+	_	_	
4-253	1374-1379	numpy	*[6]	SOFTWARE[6]	
4-254	1380-1381	>	*[6]	SOFTWARE[6]	
4-255	1381-1382	=	*[6]	SOFTWARE[6]	
4-256	1383-1389	1.23.4	*[6]	SOFTWARE[6]	
4-257	1390-1391	+	_	_	
4-258	1392-1397	torch	*[7]	SOFTWARE[7]	
4-259	1398-1399	>	*[7]	SOFTWARE[7]	
4-260	1399-1400	=	*[7]	SOFTWARE[7]	
4-261	1401-1407	1.13.0	*[7]	SOFTWARE[7]	
4-262	1409-1410	#	_	_	
4-263	1410-1411	#	_	_	
4-264	1412-1416	Data	_	_	
4-265	1417-1420	All	_	_	
4-266	1421-1429	datasets	_	_	
4-267	1430-1433	can	_	_	
4-268	1434-1436	be	_	_	
4-269	1437-1447	downloaded	_	_	
4-270	1448-1449	[	_	_	
4-271	1449-1453	here	_	_	
4-272	1453-1454	]	_	_	
4-273	1454-1455	(	_	_	
4-274	1455-1460	https	_	_	
4-275	1460-1461	:	_	_	
4-276	1461-1462	/	_	_	
4-277	1462-1463	/	_	_	
4-278	1463-1479	drive.google.com	_	_	
4-279	1479-1480	/	_	_	
4-280	1480-1485	drive	_	_	
4-281	1485-1486	/	_	_	
4-282	1486-1493	folders	_	_	
4-283	1493-1494	/	_	_	
4-284	1494-1527	19vFBn5C-nTdjxMeuMgw-BvsPNsLF6DpV	_	_	
4-285	1527-1528	?	_	_	

#Text=usp=sharing) and should be placed under **main/res/data** according to specific tasks.
5-1	1528-1531	usp	_	_	
5-2	1531-1532	=	_	_	
5-3	1532-1539	sharing	_	_	
5-4	1539-1540	)	_	_	
5-5	1541-1544	and	_	_	
5-6	1545-1551	should	_	_	
5-7	1552-1554	be	_	_	
5-8	1555-1561	placed	_	_	
5-9	1562-1567	under	_	_	
5-10	1568-1569	*	_	_	
5-11	1569-1570	*	_	_	
5-12	1570-1574	main	_	_	
5-13	1574-1575	/	_	_	
5-14	1575-1578	res	_	_	
5-15	1578-1579	/	_	_	
5-16	1579-1583	data	_	_	
5-17	1583-1584	*	_	_	
5-18	1584-1585	*	_	_	
5-19	1586-1595	according	_	_	
5-20	1596-1598	to	_	_	
5-21	1599-1607	specific	_	_	
5-22	1608-1613	tasks	_	_	
5-23	1613-1614	.	_	_	

#Text=Please refer to [text2sql-data](https://github.com/jkkummerfeld/text2sql-data/tree/master/data) for details.
#Text=* main/res/data/scan
#Text=* main/res/data/geography
#Text=* main/res/data/advising
#Text=
#Text=### Notes
#Text=+ main/res/data/iwslt14 - both vocabulary augmentation set and the entire dataset for IWSLT14
#Text=+ main/res/data/iwslt15 - both vocabulary augmentation set and the entire dataset for IWSLT15
#Text=+ main/res/data/prepare-iwslt14.sh - [fairseq](https://github.com/facebookresearch/fairseq) preprocess script for IWSLT14
#Text=+ main/res/data/prepare-iwslt15.sh - [fairseq](https://github.com/facebookresearch/fairseq) preprocess script for IWSLT15
#Text=+ main/res/data/geo_vars.txt - the entity augmentation set for Grography
#Text=+ main/res/data/adv_vars.txt - the entity augmentation set for Advising
#Text=
#Text=## Setup
#Text=Please ensure required packages are already installed.
6-1	1615-1621	Please	_	_	
6-2	1622-1627	refer	_	_	
6-3	1628-1630	to	_	_	
6-4	1631-1632	[	_	_	
6-5	1632-1645	text2sql-data	_	_	
6-6	1645-1646	]	_	_	
6-7	1646-1647	(	_	_	
6-8	1647-1652	https	_	_	
6-9	1652-1653	:	_	_	
6-10	1653-1654	/	_	_	
6-11	1654-1655	/	_	_	
6-12	1655-1665	github.com	_	_	
6-13	1665-1666	/	_	_	
6-14	1666-1678	jkkummerfeld	_	_	
6-15	1678-1679	/	_	_	
6-16	1679-1692	text2sql-data	_	_	
6-17	1692-1693	/	_	_	
6-18	1693-1697	tree	_	_	
6-19	1697-1698	/	_	_	
6-20	1698-1704	master	_	_	
6-21	1704-1705	/	_	_	
6-22	1705-1709	data	_	_	
6-23	1709-1710	)	_	_	
6-24	1711-1714	for	_	_	
6-25	1715-1722	details	_	_	
6-26	1722-1723	.	_	_	
6-27	1724-1725	*	_	_	
6-28	1726-1730	main	_	_	
6-29	1730-1731	/	_	_	
6-30	1731-1734	res	_	_	
6-31	1734-1735	/	_	_	
6-32	1735-1739	data	_	_	
6-33	1739-1740	/	_	_	
6-34	1740-1744	scan	_	_	
6-35	1745-1746	*	_	_	
6-36	1747-1751	main	_	_	
6-37	1751-1752	/	_	_	
6-38	1752-1755	res	_	_	
6-39	1755-1756	/	_	_	
6-40	1756-1760	data	_	_	
6-41	1760-1761	/	_	_	
6-42	1761-1770	geography	_	_	
6-43	1771-1772	*	_	_	
6-44	1773-1777	main	_	_	
6-45	1777-1778	/	_	_	
6-46	1778-1781	res	_	_	
6-47	1781-1782	/	_	_	
6-48	1782-1786	data	_	_	
6-49	1786-1787	/	_	_	
6-50	1787-1795	advising	_	_	
6-51	1797-1798	#	_	_	
6-52	1798-1799	#	_	_	
6-53	1799-1800	#	_	_	
6-54	1801-1806	Notes	_	_	
6-55	1807-1808	+	_	_	
6-56	1809-1813	main	_	_	
6-57	1813-1814	/	_	_	
6-58	1814-1817	res	_	_	
6-59	1817-1818	/	_	_	
6-60	1818-1822	data	_	_	
6-61	1822-1823	/	_	_	
6-62	1823-1830	iwslt14	_	_	
6-63	1831-1832	-	_	_	
6-64	1833-1837	both	_	_	
6-65	1838-1848	vocabulary	_	_	
6-66	1849-1861	augmentation	_	_	
6-67	1862-1865	set	_	_	
6-68	1866-1869	and	_	_	
6-69	1870-1873	the	_	_	
6-70	1874-1880	entire	_	_	
6-71	1881-1888	dataset	_	_	
6-72	1889-1892	for	_	_	
6-73	1893-1900	IWSLT14	*	WORKSHOP	
6-74	1901-1902	+	_	_	
6-75	1903-1907	main	_	_	
6-76	1907-1908	/	_	_	
6-77	1908-1911	res	_	_	
6-78	1911-1912	/	_	_	
6-79	1912-1916	data	_	_	
6-80	1916-1917	/	_	_	
6-81	1917-1924	iwslt15	_	_	
6-82	1925-1926	-	_	_	
6-83	1927-1931	both	_	_	
6-84	1932-1942	vocabulary	_	_	
6-85	1943-1955	augmentation	_	_	
6-86	1956-1959	set	_	_	
6-87	1960-1963	and	_	_	
6-88	1964-1967	the	_	_	
6-89	1968-1974	entire	_	_	
6-90	1975-1982	dataset	_	_	
6-91	1983-1986	for	_	_	
6-92	1987-1994	IWSLT15	*	WORKSHOP	
6-93	1995-1996	+	_	_	
6-94	1997-2001	main	_	_	
6-95	2001-2002	/	_	_	
6-96	2002-2005	res	_	_	
6-97	2005-2006	/	_	_	
6-98	2006-2010	data	_	_	
6-99	2010-2011	/	_	_	
6-100	2011-2026	prepare-iwslt14	_	_	
6-101	2026-2027	.	_	_	
6-102	2027-2029	sh	_	_	
6-103	2030-2031	-	_	_	
6-104	2032-2033	[	_	_	
6-105	2033-2040	fairseq	_	_	
6-106	2040-2041	]	_	_	
6-107	2041-2042	(	_	_	
6-108	2042-2047	https	_	_	
6-109	2047-2048	:	_	_	
6-110	2048-2049	/	_	_	
6-111	2049-2050	/	_	_	
6-112	2050-2060	github.com	_	_	
6-113	2060-2061	/	_	_	
6-114	2061-2077	facebookresearch	_	_	
6-115	2077-2078	/	_	_	
6-116	2078-2085	fairseq	_	_	
6-117	2085-2086	)	_	_	
6-118	2087-2097	preprocess	_	_	
6-119	2098-2104	script	_	_	
6-120	2105-2108	for	_	_	
6-121	2109-2116	IWSLT14	*	WORKSHOP	
6-122	2117-2118	+	_	_	
6-123	2119-2123	main	_	_	
6-124	2123-2124	/	_	_	
6-125	2124-2127	res	_	_	
6-126	2127-2128	/	_	_	
6-127	2128-2132	data	_	_	
6-128	2132-2133	/	_	_	
6-129	2133-2148	prepare-iwslt15	_	_	
6-130	2148-2149	.	_	_	
6-131	2149-2151	sh	_	_	
6-132	2152-2153	-	_	_	
6-133	2154-2155	[	_	_	
6-134	2155-2162	fairseq	_	_	
6-135	2162-2163	]	_	_	
6-136	2163-2164	(	_	_	
6-137	2164-2169	https	_	_	
6-138	2169-2170	:	_	_	
6-139	2170-2171	/	_	_	
6-140	2171-2172	/	_	_	
6-141	2172-2182	github.com	_	_	
6-142	2182-2183	/	_	_	
6-143	2183-2199	facebookresearch	_	_	
6-144	2199-2200	/	_	_	
6-145	2200-2207	fairseq	_	_	
6-146	2207-2208	)	_	_	
6-147	2209-2219	preprocess	_	_	
6-148	2220-2226	script	_	_	
6-149	2227-2230	for	_	_	
6-150	2231-2238	IWSLT15	*	WORKSHOP	
6-151	2239-2240	+	_	_	
6-152	2241-2245	main	_	_	
6-153	2245-2246	/	_	_	
6-154	2246-2249	res	_	_	
6-155	2249-2250	/	_	_	
6-156	2250-2254	data	_	_	
6-157	2254-2255	/	_	_	
6-158	2255-2267	geo_vars.txt	_	_	
6-159	2268-2269	-	_	_	
6-160	2270-2273	the	_	_	
6-161	2274-2280	entity	_	_	
6-162	2281-2293	augmentation	_	_	
6-163	2294-2297	set	_	_	
6-164	2298-2301	for	_	_	
6-165	2302-2311	Grography	_	_	
6-166	2312-2313	+	_	_	
6-167	2314-2318	main	_	_	
6-168	2318-2319	/	_	_	
6-169	2319-2322	res	_	_	
6-170	2322-2323	/	_	_	
6-171	2323-2327	data	_	_	
6-172	2327-2328	/	_	_	
6-173	2328-2340	adv_vars.txt	_	_	
6-174	2341-2342	-	_	_	
6-175	2343-2346	the	_	_	
6-176	2347-2353	entity	_	_	
6-177	2354-2366	augmentation	_	_	
6-178	2367-2370	set	_	_	
6-179	2371-2374	for	_	_	
6-180	2375-2383	Advising	_	_	
6-181	2385-2386	#	_	_	
6-182	2386-2387	#	_	_	
6-183	2388-2393	Setup	_	_	
6-184	2394-2400	Please	_	_	
6-185	2401-2407	ensure	_	_	
6-186	2408-2416	required	_	_	
6-187	2417-2425	packages	_	_	
6-188	2426-2429	are	_	_	
6-189	2430-2437	already	_	_	
6-190	2438-2447	installed	_	_	
6-191	2447-2448	.	_	_	

#Text=A virtual environment is recommended.
#Text=```
#Text=$ cd Systematic-Generalization-via-Meaningful-Learning
#Text=$ cd main
#Text=$ pip install pip --upgrade
#Text=$ pip install -r requirements.txt
#Text=```
#Text=
#Text=## Run
#Text=Before training, please double check **config.py** to ensure training configurations.
#Text=```
#Text=$ vim config.py
#Text=$ python train.py
#Text=```
#Text=
#Text=## Outputs
#Text=If everything goes well, there should be a similar progressing shown as below.
#Text=```
#Text=Initialize...
7-1	2449-2450	A	_	_	
7-2	2451-2458	virtual	_	_	
7-3	2459-2470	environment	_	_	
7-4	2471-2473	is	_	_	
7-5	2474-2485	recommended	_	_	
7-6	2485-2486	.	_	_	
7-7	2487-2488	`	_	_	
7-8	2488-2489	`	_	_	
7-9	2489-2490	`	_	_	
7-10	2491-2492	$	_	_	
7-11	2493-2495	cd	_	_	
7-12	2496-2545	Systematic-Generalization-via-Meaningful-Learning	_	_	
7-13	2546-2547	$	_	_	
7-14	2548-2550	cd	_	_	
7-15	2551-2555	main	_	_	
7-16	2556-2557	$	_	_	
7-17	2558-2561	pip	*	SOFTWARE	
7-18	2562-2569	install	_	_	
7-19	2570-2573	pip	*	SOFTWARE	
7-20	2574-2575	-	_	_	
7-21	2575-2576	-	_	_	
7-22	2576-2583	upgrade	_	_	
7-23	2584-2585	$	_	_	
7-24	2586-2589	pip	*	SOFTWARE	
7-25	2590-2597	install	_	_	
7-26	2598-2599	-	_	_	
7-27	2599-2600	r	_	_	
7-28	2601-2617	requirements.txt	_	_	
7-29	2618-2619	`	_	_	
7-30	2619-2620	`	_	_	
7-31	2620-2621	`	_	_	
7-32	2623-2624	#	_	_	
7-33	2624-2625	#	_	_	
7-34	2626-2629	Run	_	_	
7-35	2630-2636	Before	_	_	
7-36	2637-2645	training	_	_	
7-37	2645-2646	,	_	_	
7-38	2647-2653	please	_	_	
7-39	2654-2660	double	_	_	
7-40	2661-2666	check	_	_	
7-41	2667-2668	*	_	_	
7-42	2668-2669	*	_	_	
7-43	2669-2678	config.py	_	_	
7-44	2678-2679	*	_	_	
7-45	2679-2680	*	_	_	
7-46	2681-2683	to	_	_	
7-47	2684-2690	ensure	_	_	
7-48	2691-2699	training	_	_	
7-49	2700-2714	configurations	_	_	
7-50	2714-2715	.	_	_	
7-51	2716-2717	`	_	_	
7-52	2717-2718	`	_	_	
7-53	2718-2719	`	_	_	
7-54	2720-2721	$	_	_	
7-55	2722-2725	vim	*	SOFTWARE	
7-56	2726-2735	config.py	_	_	
7-57	2736-2737	$	_	_	
7-58	2738-2744	python	*	SOFTWARE	
7-59	2745-2753	train.py	_	_	
7-60	2754-2755	`	_	_	
7-61	2755-2756	`	_	_	
7-62	2756-2757	`	_	_	
7-63	2759-2760	#	_	_	
7-64	2760-2761	#	_	_	
7-65	2762-2769	Outputs	_	_	
7-66	2770-2772	If	_	_	
7-67	2773-2783	everything	_	_	
7-68	2784-2788	goes	_	_	
7-69	2789-2793	well	_	_	
7-70	2793-2794	,	_	_	
7-71	2795-2800	there	_	_	
7-72	2801-2807	should	_	_	
7-73	2808-2810	be	_	_	
7-74	2811-2812	a	_	_	
7-75	2813-2820	similar	_	_	
7-76	2821-2832	progressing	_	_	
7-77	2833-2838	shown	_	_	
7-78	2839-2841	as	_	_	
7-79	2842-2847	below	_	_	
7-80	2847-2848	.	_	_	
7-81	2849-2850	`	_	_	
7-82	2850-2851	`	_	_	
7-83	2851-2852	`	_	_	
7-84	2853-2863	Initialize	_	_	
7-85	2863-2864	.	_	_	
7-86	2864-2865	.	_	_	
7-87	2865-2866	.	_	_	

#Text=*Configuration*
#Text=model name: bi_lstm_rnn_att
#Text=trainable parameters:5,027,337
#Text=...
8-1	2867-2868	*	_	_	
8-2	2868-2881	Configuration	_	_	
8-3	2881-2882	*	_	_	
8-4	2883-2888	model	_	_	
8-5	2889-2893	name	_	_	
8-6	2893-2894	:	_	_	
8-7	2895-2910	bi_lstm_rnn_att	_	_	
8-8	2911-2920	trainable	_	_	
8-9	2921-2931	parameters	_	_	
8-10	2931-2932	:	_	_	
8-11	2932-2941	5,027,337	_	_	
8-12	2942-2943	.	_	_	
8-13	2943-2944	.	_	_	
8-14	2944-2945	.	_	_	

#Text=Training...
9-1	2946-2954	Training	_	_	
9-2	2954-2955	.	_	_	
9-3	2955-2956	.	_	_	
9-4	2956-2957	.	_	_	

#Text=Loss:1.7061: 100%|██████████| 132/132 [00:14<00:00,  9.37it/s]
#Text=Train Epoch 0 Total Step 132 Loss:1.9179
#Text=...
#Text=```
#Text=
#Text=## NMT
#Text=We use [fairseq](https://github.com/facebookresearch/fairseq) for NMT tasks in Section 4.1.
10-1	2958-2962	Loss	_	_	
10-2	2962-2963	:	_	_	
10-3	2963-2969	1.7061	_	_	
10-4	2969-2970	:	_	_	
10-5	2971-2975	100%	_	_	
10-6	2975-2976	|	_	_	
10-7	2976-2977	█	_	_	
10-8	2977-2978	█	_	_	
10-9	2978-2979	█	_	_	
10-10	2979-2980	█	_	_	
10-11	2980-2981	█	_	_	
10-12	2981-2982	█	_	_	
10-13	2982-2983	█	_	_	
10-14	2983-2984	█	_	_	
10-15	2984-2985	█	_	_	
10-16	2985-2986	█	_	_	
10-17	2986-2987	|	_	_	
10-18	2988-2991	132	_	_	
10-19	2991-2992	/	_	_	
10-20	2992-2995	132	_	_	
10-21	2996-2997	[	_	_	
10-22	2997-2999	00	_	_	
10-23	2999-3000	:	_	_	
10-24	3000-3002	14	_	_	
10-25	3002-3003	<	_	_	
10-26	3003-3005	00	_	_	
10-27	3005-3006	:	_	_	
10-28	3006-3008	00	_	_	
10-29	3008-3009	,	_	_	
10-30	3011-3017	9.37it	_	_	
10-31	3017-3018	/	_	_	
10-32	3018-3019	s	_	_	
10-33	3019-3020	]	_	_	
10-34	3021-3026	Train	_	_	
10-35	3027-3032	Epoch	_	_	
10-36	3033-3034	0	_	_	
10-37	3035-3040	Total	_	_	
10-38	3041-3045	Step	_	_	
10-39	3046-3049	132	_	_	
10-40	3050-3054	Loss	_	_	
10-41	3054-3055	:	_	_	
10-42	3055-3061	1.9179	_	_	
10-43	3062-3063	.	_	_	
10-44	3063-3064	.	_	_	
10-45	3064-3065	.	_	_	
10-46	3066-3067	`	_	_	
10-47	3067-3068	`	_	_	
10-48	3068-3069	`	_	_	
10-49	3071-3072	#	_	_	
10-50	3072-3073	#	_	_	
10-51	3074-3077	NMT	_	_	
10-52	3078-3080	We	_	_	
10-53	3081-3084	use	_	_	
10-54	3085-3086	[	_	_	
10-55	3086-3093	fairseq	*	SOFTWARE	
10-56	3093-3094	]	_	_	
10-57	3094-3095	(	_	_	
10-58	3095-3100	https	_	_	
10-59	3100-3101	:	_	_	
10-60	3101-3102	/	_	_	
10-61	3102-3103	/	_	_	
10-62	3103-3113	github.com	_	_	
10-63	3113-3114	/	_	_	
10-64	3114-3130	facebookresearch	_	_	
10-65	3130-3131	/	_	_	
10-66	3131-3138	fairseq	*	SOFTWARE	
10-67	3138-3139	)	_	_	
10-68	3140-3143	for	_	_	
10-69	3144-3147	NMT	_	_	
10-70	3148-3153	tasks	_	_	
10-71	3154-3156	in	_	_	
10-72	3157-3164	Section	_	_	
10-73	3165-3168	4.1	_	_	
10-74	3168-3169	.	_	_	

#Text=Please find the example pipeline shown below.
#Text=
#Text=### Models
#Text=+ LSTM - lstm_luong_wmt_en_de
#Text=+ Transformer - transformer_iwslt_de_en
#Text=+ Dynamic Conv. - lightconv_iwslt_de_en
#Text=
#Text=### BPE
#Text=```
#Text=examples/translation/subword-nmt/apply_bpe.py -c iwslt14.tokenized.de-en/code <iwslt14.tokenized.de-en/iwslt14.vocab.en> iwslt14.tokenized.de-en/iwslt14.vocab.en.bpe
#Text=```
#Text=
#Text=### Preprocessing
#Text=```
#Text=TEXT=examples/translation/iwslt14.tokenized.de-en
#Text=fairseq-preprocess --source-lang en --target-lang de \\
#Text=    --trainpref $TEXT/train --validpref $TEXT/valid --testpref $TEXT/test \\
#Text=    --destdir data-bin/iwslt14.tokenized.de-en \\
#Text=    --workers 20
#Text=```
#Text=
#Text=### Training
#Text=LSTM
#Text=```
#Text=fairseq-train \\
#Text=    data-bin/iwslt14.tokenized.de-en \\
#Text=    -s en -t de \\
#Text=    --arch lstm_luong_wmt_en_de --share-decoder-input-output-embed \\
#Text=    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\
#Text=    --lr 0.001 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 \\
#Text=    --dropout 0.2 --weight-decay 0.0 \\
#Text=    --encoder-dropout-out 0.2 --decoder-dropout-out 0.2 \\
#Text=    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\
#Text=    --max-tokens 32768 \\
#Text=    --fp16 --no-epoch-checkpoints >train.log 2>&1 &
#Text=```
#Text=Transformer
#Text=```
#Text=fairseq-train \\
#Text=    data-bin/iwslt14.tokenized.de-en \\
#Text=    -s en -t de \\
#Text=    --arch transformer_iwslt_de_en --share-decoder-input-output-embed \\
#Text=    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\
#Text=    --lr 0.001 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 \\
#Text=    --dropout 0.3 --attention-dropout 0.1 --weight-decay 0.0 \\
#Text=    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\
#Text=    --max-tokens 32768 \\
#Text=    --fp16 --no-epoch-checkpoints >train.log 2>&1 &
#Text=```
#Text=Dynamic Conv.
#Text=```
#Text=fairseq-train \\
#Text=    data-bin/iwslt14.tokenized.de-en \\
#Text=    -s en -t de \\
#Text=    --arch lightconv_iwslt_de_en \\
#Text=    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\
#Text=    --lr 0.001 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 \\
#Text=    --dropout 0.1 --weight-decay 0.0 \\
#Text=    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\
#Text=    --max-tokens 32768 \\
#Text=    --fp16 --no-epoch-checkpoints >train.log 2>&1 &
#Text=```
#Text=
#Text=### Evaluation
#Text=BLEU
#Text=```
#Text=fairseq-generate data-bin/iwslt14.tokenized.de-en \\
#Text=    --path checkpoints/checkpoint_best.pt \\
#Text=    -s en -t de \\
#Text=    --batch-size 128 --beam 5 --lenpen 0.6 \\
#Text=    --scoring bleu --remove-bpe --cpu >bleu.log 2>&1 &
#Text=```
#Text=ScareBLEU
#Text=```
#Text=fairseq-generate data-bin/iwslt14.tokenized.de-en \\
#Text=    --path checkpoints/checkpoint_best.pt \\
#Text=    -s en -t de \\
#Text=    --batch-size 128 --beam 5 --lenpen 0.6 \\
#Text=    --scoring sacrebleu --remove-bpe --cpu >sacrebleu.log 2>&1 &
#Text=```
#Text=
#Text=## Authors
#Text=* **Ning Shi** - mrshininnnnn@gmail.com
#Text=
#Text=## BibTex
#Text=```
#Text=@inproceedings{shi-etal-2022-revisit,
#Text=    title = "Revisit Systematic Generalization via Meaningful Learning",
#Text=    author = "Shi, Ning  and
#Text=      Wang, Boxin  and
#Text=      Wang, Wei  and
#Text=      Liu, Xiangyu  and
#Text=      Lin, Zhouhan",
#Text=    booktitle = "Proceedings of the Fifth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP",
#Text=    month = dec,
#Text=    year = "2022",
#Text=    address = "Abu Dhabi, United Arab Emirates (Hybrid)",
#Text=    publisher = "Association for Computational Linguistics",
#Text=    url = "https://aclanthology.org/2022.blackboxnlp-1.6",
#Text=    pages = "62--79",
#Text=    abstract = "Humans can systematically generalize to novel compositions of existing concepts.
11-1	3170-3176	Please	_	_	
11-2	3177-3181	find	_	_	
11-3	3182-3185	the	_	_	
11-4	3186-3193	example	_	_	
11-5	3194-3202	pipeline	_	_	
11-6	3203-3208	shown	_	_	
11-7	3209-3214	below	_	_	
11-8	3214-3215	.	_	_	
11-9	3217-3218	#	_	_	
11-10	3218-3219	#	_	_	
11-11	3219-3220	#	_	_	
11-12	3221-3227	Models	_	_	
11-13	3228-3229	+	_	_	
11-14	3230-3234	LSTM	_	_	
11-15	3235-3236	-	_	_	
11-16	3237-3257	lstm_luong_wmt_en_de	_	_	
11-17	3258-3259	+	_	_	
11-18	3260-3271	Transformer	_	_	
11-19	3272-3273	-	_	_	
11-20	3274-3297	transformer_iwslt_de_en	_	_	
11-21	3298-3299	+	_	_	
11-22	3300-3307	Dynamic	_	_	
11-23	3308-3312	Conv	_	_	
11-24	3312-3313	.	_	_	
11-25	3314-3315	-	_	_	
11-26	3316-3337	lightconv_iwslt_de_en	_	_	
11-27	3339-3340	#	_	_	
11-28	3340-3341	#	_	_	
11-29	3341-3342	#	_	_	
11-30	3343-3346	BPE	_	_	
11-31	3347-3348	`	_	_	
11-32	3348-3349	`	_	_	
11-33	3349-3350	`	_	_	
11-34	3351-3359	examples	_	_	
11-35	3359-3360	/	_	_	
11-36	3360-3371	translation	_	_	
11-37	3371-3372	/	_	_	
11-38	3372-3383	subword-nmt	_	_	
11-39	3383-3384	/	_	_	
11-40	3384-3396	apply_bpe.py	_	_	
11-41	3397-3398	-	_	_	
11-42	3398-3399	c	_	_	
11-43	3400-3407	iwslt14	_	_	
11-44	3407-3408	.	_	_	
11-45	3408-3423	tokenized.de-en	_	_	
11-46	3423-3424	/	_	_	
11-47	3424-3428	code	_	_	
11-48	3429-3430	<	_	_	
11-49	3430-3437	iwslt14	_	_	
11-50	3437-3438	.	_	_	
11-51	3438-3453	tokenized.de-en	_	_	
11-52	3453-3454	/	_	_	
11-53	3454-3461	iwslt14	_	_	
11-54	3461-3462	.	_	_	
11-55	3462-3470	vocab.en	_	_	
11-56	3470-3471	>	_	_	
11-57	3472-3479	iwslt14	_	_	
11-58	3479-3480	.	_	_	
11-59	3480-3495	tokenized.de-en	_	_	
11-60	3495-3496	/	_	_	
11-61	3496-3503	iwslt14	_	_	
11-62	3503-3504	.	_	_	
11-63	3504-3516	vocab.en.bpe	_	_	
11-64	3517-3518	`	_	_	
11-65	3518-3519	`	_	_	
11-66	3519-3520	`	_	_	
11-67	3522-3523	#	_	_	
11-68	3523-3524	#	_	_	
11-69	3524-3525	#	_	_	
11-70	3526-3539	Preprocessing	_	_	
11-71	3540-3541	`	_	_	
11-72	3541-3542	`	_	_	
11-73	3542-3543	`	_	_	
11-74	3544-3548	TEXT	_	_	
11-75	3548-3549	=	_	_	
11-76	3549-3557	examples	_	_	
11-77	3557-3558	/	_	_	
11-78	3558-3569	translation	_	_	
11-79	3569-3570	/	_	_	
11-80	3570-3577	iwslt14	_	_	
11-81	3577-3578	.	_	_	
11-82	3578-3593	tokenized.de-en	_	_	
11-83	3594-3612	fairseq-preprocess	_	_	
11-84	3613-3614	-	_	_	
11-85	3614-3615	-	_	_	
11-86	3615-3626	source-lang	_	_	
11-87	3627-3629	en	_	_	
11-88	3630-3631	-	_	_	
11-89	3631-3632	-	_	_	
11-90	3632-3643	target-lang	_	_	
11-91	3644-3646	de	_	_	
11-92	3647-3648	\	_	_	
11-93	3653-3654	-	_	_	
11-94	3654-3655	-	_	_	
11-95	3655-3664	trainpref	_	_	
11-96	3665-3666	$	_	_	
11-97	3666-3670	TEXT	_	_	
11-98	3670-3671	/	_	_	
11-99	3671-3676	train	_	_	
11-100	3677-3678	-	_	_	
11-101	3678-3679	-	_	_	
11-102	3679-3688	validpref	_	_	
11-103	3689-3690	$	_	_	
11-104	3690-3694	TEXT	_	_	
11-105	3694-3695	/	_	_	
11-106	3695-3700	valid	_	_	
11-107	3701-3702	-	_	_	
11-108	3702-3703	-	_	_	
11-109	3703-3711	testpref	_	_	
11-110	3712-3713	$	_	_	
11-111	3713-3717	TEXT	_	_	
11-112	3717-3718	/	_	_	
11-113	3718-3722	test	_	_	
11-114	3723-3724	\	_	_	
11-115	3729-3730	-	_	_	
11-116	3730-3731	-	_	_	
11-117	3731-3738	destdir	_	_	
11-118	3739-3747	data-bin	_	_	
11-119	3747-3748	/	_	_	
11-120	3748-3755	iwslt14	_	_	
11-121	3755-3756	.	_	_	
11-122	3756-3771	tokenized.de-en	_	_	
11-123	3772-3773	\	_	_	
11-124	3778-3779	-	_	_	
11-125	3779-3780	-	_	_	
11-126	3780-3787	workers	_	_	
11-127	3788-3790	20	_	_	
11-128	3791-3792	`	_	_	
11-129	3792-3793	`	_	_	
11-130	3793-3794	`	_	_	
11-131	3796-3797	#	_	_	
11-132	3797-3798	#	_	_	
11-133	3798-3799	#	_	_	
11-134	3800-3808	Training	_	_	
11-135	3809-3813	LSTM	_	_	
11-136	3814-3815	`	_	_	
11-137	3815-3816	`	_	_	
11-138	3816-3817	`	_	_	
11-139	3818-3831	fairseq-train	_	_	
11-140	3832-3833	\	_	_	
11-141	3838-3846	data-bin	_	_	
11-142	3846-3847	/	_	_	
11-143	3847-3854	iwslt14	_	_	
11-144	3854-3855	.	_	_	
11-145	3855-3870	tokenized.de-en	_	_	
11-146	3871-3872	\	_	_	
11-147	3877-3878	-	_	_	
11-148	3878-3879	s	_	_	
11-149	3880-3882	en	_	_	
11-150	3883-3884	-	_	_	
11-151	3884-3885	t	_	_	
11-152	3886-3888	de	_	_	
11-153	3889-3890	\	_	_	
11-154	3895-3896	-	_	_	
11-155	3896-3897	-	_	_	
11-156	3897-3901	arch	_	_	
11-157	3902-3922	lstm_luong_wmt_en_de	_	_	
11-158	3923-3924	-	_	_	
11-159	3924-3925	-	_	_	
11-160	3925-3957	share-decoder-input-output-embed	_	_	
11-161	3958-3959	\	_	_	
11-162	3964-3965	-	_	_	
11-163	3965-3966	-	_	_	
11-164	3966-3975	optimizer	_	_	
11-165	3976-3980	adam	_	_	
11-166	3981-3982	-	_	_	
11-167	3982-3983	-	_	_	
11-168	3983-3993	adam-betas	_	_	
11-169	3994-3995	'	_	_	
11-170	3995-3996	(	_	_	
11-171	3996-3999	0.9	_	_	
11-172	3999-4000	,	_	_	
11-173	4001-4005	0.98	_	_	
11-174	4005-4006	)	_	_	
11-175	4006-4007	'	_	_	
11-176	4008-4009	-	_	_	
11-177	4009-4010	-	_	_	
11-178	4010-4019	clip-norm	_	_	
11-179	4020-4023	0.0	_	_	
11-180	4024-4025	\	_	_	
11-181	4030-4031	-	_	_	
11-182	4031-4032	-	_	_	
11-183	4032-4034	lr	_	_	
11-184	4035-4040	0.001	_	_	
11-185	4041-4042	-	_	_	
11-186	4042-4043	-	_	_	
11-187	4043-4055	lr-scheduler	_	_	
11-188	4056-4068	inverse_sqrt	_	_	
11-189	4069-4070	-	_	_	
11-190	4070-4071	-	_	_	
11-191	4071-4085	warmup-updates	_	_	
11-192	4086-4090	4000	_	_	
11-193	4091-4092	-	_	_	
11-194	4092-4093	-	_	_	
11-195	4093-4107	warmup-init-lr	_	_	
11-196	4108-4110	1e	_	_	
11-197	4110-4111	-	_	_	
11-198	4111-4113	07	_	_	
11-199	4114-4115	\	_	_	
11-200	4120-4121	-	_	_	
11-201	4121-4122	-	_	_	
11-202	4122-4129	dropout	_	_	
11-203	4130-4133	0.2	_	_	
11-204	4134-4135	-	_	_	
11-205	4135-4136	-	_	_	
11-206	4136-4148	weight-decay	_	_	
11-207	4149-4152	0.0	_	_	
11-208	4153-4154	\	_	_	
11-209	4159-4160	-	_	_	
11-210	4160-4161	-	_	_	
11-211	4161-4180	encoder-dropout-out	_	_	
11-212	4181-4184	0.2	_	_	
11-213	4185-4186	-	_	_	
11-214	4186-4187	-	_	_	
11-215	4187-4206	decoder-dropout-out	_	_	
11-216	4207-4210	0.2	_	_	
11-217	4211-4212	\	_	_	
11-218	4217-4218	-	_	_	
11-219	4218-4219	-	_	_	
11-220	4219-4228	criterion	_	_	
11-221	4229-4257	label_smoothed_cross_entropy	_	_	
11-222	4258-4259	-	_	_	
11-223	4259-4260	-	_	_	
11-224	4260-4275	label-smoothing	_	_	
11-225	4276-4279	0.1	_	_	
11-226	4280-4281	\	_	_	
11-227	4286-4287	-	_	_	
11-228	4287-4288	-	_	_	
11-229	4288-4298	max-tokens	_	_	
11-230	4299-4304	32768	_	_	
11-231	4305-4306	\	_	_	
11-232	4311-4312	-	_	_	
11-233	4312-4313	-	_	_	
11-234	4313-4317	fp16	_	_	
11-235	4318-4319	-	_	_	
11-236	4319-4320	-	_	_	
11-237	4320-4340	no-epoch-checkpoints	_	_	
11-238	4341-4342	>	_	_	
11-239	4342-4351	train.log	_	_	
11-240	4352-4353	2	_	_	
11-241	4353-4354	>	_	_	
11-242	4354-4355	&	_	_	
11-243	4355-4356	1	_	_	
11-244	4357-4358	&	_	_	
11-245	4359-4360	`	_	_	
11-246	4360-4361	`	_	_	
11-247	4361-4362	`	_	_	
11-248	4363-4374	Transformer	_	_	
11-249	4375-4376	`	_	_	
11-250	4376-4377	`	_	_	
11-251	4377-4378	`	_	_	
11-252	4379-4392	fairseq-train	_	_	
11-253	4393-4394	\	_	_	
11-254	4399-4407	data-bin	_	_	
11-255	4407-4408	/	_	_	
11-256	4408-4415	iwslt14	_	_	
11-257	4415-4416	.	_	_	
11-258	4416-4431	tokenized.de-en	_	_	
11-259	4432-4433	\	_	_	
11-260	4438-4439	-	_	_	
11-261	4439-4440	s	_	_	
11-262	4441-4443	en	_	_	
11-263	4444-4445	-	_	_	
11-264	4445-4446	t	_	_	
11-265	4447-4449	de	_	_	
11-266	4450-4451	\	_	_	
11-267	4456-4457	-	_	_	
11-268	4457-4458	-	_	_	
11-269	4458-4462	arch	_	_	
11-270	4463-4486	transformer_iwslt_de_en	_	_	
11-271	4487-4488	-	_	_	
11-272	4488-4489	-	_	_	
11-273	4489-4521	share-decoder-input-output-embed	_	_	
11-274	4522-4523	\	_	_	
11-275	4528-4529	-	_	_	
11-276	4529-4530	-	_	_	
11-277	4530-4539	optimizer	_	_	
11-278	4540-4544	adam	_	_	
11-279	4545-4546	-	_	_	
11-280	4546-4547	-	_	_	
11-281	4547-4557	adam-betas	_	_	
11-282	4558-4559	'	_	_	
11-283	4559-4560	(	_	_	
11-284	4560-4563	0.9	_	_	
11-285	4563-4564	,	_	_	
11-286	4565-4569	0.98	_	_	
11-287	4569-4570	)	_	_	
11-288	4570-4571	'	_	_	
11-289	4572-4573	-	_	_	
11-290	4573-4574	-	_	_	
11-291	4574-4583	clip-norm	_	_	
11-292	4584-4587	0.0	_	_	
11-293	4588-4589	\	_	_	
11-294	4594-4595	-	_	_	
11-295	4595-4596	-	_	_	
11-296	4596-4598	lr	_	_	
11-297	4599-4604	0.001	_	_	
11-298	4605-4606	-	_	_	
11-299	4606-4607	-	_	_	
11-300	4607-4619	lr-scheduler	_	_	
11-301	4620-4632	inverse_sqrt	_	_	
11-302	4633-4634	-	_	_	
11-303	4634-4635	-	_	_	
11-304	4635-4649	warmup-updates	_	_	
11-305	4650-4654	4000	_	_	
11-306	4655-4656	-	_	_	
11-307	4656-4657	-	_	_	
11-308	4657-4671	warmup-init-lr	_	_	
11-309	4672-4674	1e	_	_	
11-310	4674-4675	-	_	_	
11-311	4675-4677	07	_	_	
11-312	4678-4679	\	_	_	
11-313	4684-4685	-	_	_	
11-314	4685-4686	-	_	_	
11-315	4686-4693	dropout	_	_	
11-316	4694-4697	0.3	_	_	
11-317	4698-4699	-	_	_	
11-318	4699-4700	-	_	_	
11-319	4700-4717	attention-dropout	_	_	
11-320	4718-4721	0.1	_	_	
11-321	4722-4723	-	_	_	
11-322	4723-4724	-	_	_	
11-323	4724-4736	weight-decay	_	_	
11-324	4737-4740	0.0	_	_	
11-325	4741-4742	\	_	_	
11-326	4747-4748	-	_	_	
11-327	4748-4749	-	_	_	
11-328	4749-4758	criterion	_	_	
11-329	4759-4787	label_smoothed_cross_entropy	_	_	
11-330	4788-4789	-	_	_	
11-331	4789-4790	-	_	_	
11-332	4790-4805	label-smoothing	_	_	
11-333	4806-4809	0.1	_	_	
11-334	4810-4811	\	_	_	
11-335	4816-4817	-	_	_	
11-336	4817-4818	-	_	_	
11-337	4818-4828	max-tokens	_	_	
11-338	4829-4834	32768	_	_	
11-339	4835-4836	\	_	_	
11-340	4841-4842	-	_	_	
11-341	4842-4843	-	_	_	
11-342	4843-4847	fp16	_	_	
11-343	4848-4849	-	_	_	
11-344	4849-4850	-	_	_	
11-345	4850-4870	no-epoch-checkpoints	_	_	
11-346	4871-4872	>	_	_	
11-347	4872-4881	train.log	_	_	
11-348	4882-4883	2	_	_	
11-349	4883-4884	>	_	_	
11-350	4884-4885	&	_	_	
11-351	4885-4886	1	_	_	
11-352	4887-4888	&	_	_	
11-353	4889-4890	`	_	_	
11-354	4890-4891	`	_	_	
11-355	4891-4892	`	_	_	
11-356	4893-4900	Dynamic	_	_	
11-357	4901-4905	Conv	_	_	
11-358	4905-4906	.	_	_	
11-359	4907-4908	`	_	_	
11-360	4908-4909	`	_	_	
11-361	4909-4910	`	_	_	
11-362	4911-4924	fairseq-train	_	_	
11-363	4925-4926	\	_	_	
11-364	4931-4939	data-bin	_	_	
11-365	4939-4940	/	_	_	
11-366	4940-4947	iwslt14	_	_	
11-367	4947-4948	.	_	_	
11-368	4948-4963	tokenized.de-en	_	_	
11-369	4964-4965	\	_	_	
11-370	4970-4971	-	_	_	
11-371	4971-4972	s	_	_	
11-372	4973-4975	en	_	_	
11-373	4976-4977	-	_	_	
11-374	4977-4978	t	_	_	
11-375	4979-4981	de	_	_	
11-376	4982-4983	\	_	_	
11-377	4988-4989	-	_	_	
11-378	4989-4990	-	_	_	
11-379	4990-4994	arch	_	_	
11-380	4995-5016	lightconv_iwslt_de_en	_	_	
11-381	5017-5018	\	_	_	
11-382	5023-5024	-	_	_	
11-383	5024-5025	-	_	_	
11-384	5025-5034	optimizer	_	_	
11-385	5035-5039	adam	_	_	
11-386	5040-5041	-	_	_	
11-387	5041-5042	-	_	_	
11-388	5042-5052	adam-betas	_	_	
11-389	5053-5054	'	_	_	
11-390	5054-5055	(	_	_	
11-391	5055-5058	0.9	_	_	
11-392	5058-5059	,	_	_	
11-393	5060-5064	0.98	_	_	
11-394	5064-5065	)	_	_	
11-395	5065-5066	'	_	_	
11-396	5067-5068	-	_	_	
11-397	5068-5069	-	_	_	
11-398	5069-5078	clip-norm	_	_	
11-399	5079-5082	0.0	_	_	
11-400	5083-5084	\	_	_	
11-401	5089-5090	-	_	_	
11-402	5090-5091	-	_	_	
11-403	5091-5093	lr	_	_	
11-404	5094-5099	0.001	_	_	
11-405	5100-5101	-	_	_	
11-406	5101-5102	-	_	_	
11-407	5102-5114	lr-scheduler	_	_	
11-408	5115-5127	inverse_sqrt	_	_	
11-409	5128-5129	-	_	_	
11-410	5129-5130	-	_	_	
11-411	5130-5144	warmup-updates	_	_	
11-412	5145-5149	4000	_	_	
11-413	5150-5151	-	_	_	
11-414	5151-5152	-	_	_	
11-415	5152-5166	warmup-init-lr	_	_	
11-416	5167-5169	1e	_	_	
11-417	5169-5170	-	_	_	
11-418	5170-5172	07	_	_	
11-419	5173-5174	\	_	_	
11-420	5179-5180	-	_	_	
11-421	5180-5181	-	_	_	
11-422	5181-5188	dropout	_	_	
11-423	5189-5192	0.1	_	_	
11-424	5193-5194	-	_	_	
11-425	5194-5195	-	_	_	
11-426	5195-5207	weight-decay	_	_	
11-427	5208-5211	0.0	_	_	
11-428	5212-5213	\	_	_	
11-429	5218-5219	-	_	_	
11-430	5219-5220	-	_	_	
11-431	5220-5229	criterion	_	_	
11-432	5230-5258	label_smoothed_cross_entropy	_	_	
11-433	5259-5260	-	_	_	
11-434	5260-5261	-	_	_	
11-435	5261-5276	label-smoothing	_	_	
11-436	5277-5280	0.1	_	_	
11-437	5281-5282	\	_	_	
11-438	5287-5288	-	_	_	
11-439	5288-5289	-	_	_	
11-440	5289-5299	max-tokens	_	_	
11-441	5300-5305	32768	_	_	
11-442	5306-5307	\	_	_	
11-443	5312-5313	-	_	_	
11-444	5313-5314	-	_	_	
11-445	5314-5318	fp16	_	_	
11-446	5319-5320	-	_	_	
11-447	5320-5321	-	_	_	
11-448	5321-5341	no-epoch-checkpoints	_	_	
11-449	5342-5343	>	_	_	
11-450	5343-5352	train.log	_	_	
11-451	5353-5354	2	_	_	
11-452	5354-5355	>	_	_	
11-453	5355-5356	&	_	_	
11-454	5356-5357	1	_	_	
11-455	5358-5359	&	_	_	
11-456	5360-5361	`	_	_	
11-457	5361-5362	`	_	_	
11-458	5362-5363	`	_	_	
11-459	5365-5366	#	_	_	
11-460	5366-5367	#	_	_	
11-461	5367-5368	#	_	_	
11-462	5369-5379	Evaluation	_	_	
11-463	5380-5384	BLEU	*	EVALMETRIC	
11-464	5385-5386	`	_	_	
11-465	5386-5387	`	_	_	
11-466	5387-5388	`	_	_	
11-467	5389-5405	fairseq-generate	_	_	
11-468	5406-5414	data-bin	_	_	
11-469	5414-5415	/	_	_	
11-470	5415-5422	iwslt14	_	_	
11-471	5422-5423	.	_	_	
11-472	5423-5438	tokenized.de-en	_	_	
11-473	5439-5440	\	_	_	
11-474	5445-5446	-	_	_	
11-475	5446-5447	-	_	_	
11-476	5447-5451	path	_	_	
11-477	5452-5463	checkpoints	_	_	
11-478	5463-5464	/	_	_	
11-479	5464-5482	checkpoint_best.pt	_	_	
11-480	5483-5484	\	_	_	
11-481	5489-5490	-	_	_	
11-482	5490-5491	s	_	_	
11-483	5492-5494	en	_	_	
11-484	5495-5496	-	_	_	
11-485	5496-5497	t	_	_	
11-486	5498-5500	de	_	_	
11-487	5501-5502	\	_	_	
11-488	5507-5508	-	_	_	
11-489	5508-5509	-	_	_	
11-490	5509-5519	batch-size	_	_	
11-491	5520-5523	128	_	_	
11-492	5524-5525	-	_	_	
11-493	5525-5526	-	_	_	
11-494	5526-5530	beam	_	_	
11-495	5531-5532	5	_	_	
11-496	5533-5534	-	_	_	
11-497	5534-5535	-	_	_	
11-498	5535-5541	lenpen	_	_	
11-499	5542-5545	0.6	_	_	
11-500	5546-5547	\	_	_	
11-501	5552-5553	-	_	_	
11-502	5553-5554	-	_	_	
11-503	5554-5561	scoring	_	_	
11-504	5562-5566	bleu	_	_	
11-505	5567-5568	-	_	_	
11-506	5568-5569	-	_	_	
11-507	5569-5579	remove-bpe	_	_	
11-508	5580-5581	-	_	_	
11-509	5581-5582	-	_	_	
11-510	5582-5585	cpu	_	_	
11-511	5586-5587	>	_	_	
11-512	5587-5595	bleu.log	_	_	
11-513	5596-5597	2	_	_	
11-514	5597-5598	>	_	_	
11-515	5598-5599	&	_	_	
11-516	5599-5600	1	_	_	
11-517	5601-5602	&	_	_	
11-518	5603-5604	`	_	_	
11-519	5604-5605	`	_	_	
11-520	5605-5606	`	_	_	
11-521	5607-5616	ScareBLEU	*	EVALMETRIC	
11-522	5617-5618	`	_	_	
11-523	5618-5619	`	_	_	
11-524	5619-5620	`	_	_	
11-525	5621-5637	fairseq-generate	_	_	
11-526	5638-5646	data-bin	_	_	
11-527	5646-5647	/	_	_	
11-528	5647-5654	iwslt14	_	_	
11-529	5654-5655	.	_	_	
11-530	5655-5670	tokenized.de-en	_	_	
11-531	5671-5672	\	_	_	
11-532	5677-5678	-	_	_	
11-533	5678-5679	-	_	_	
11-534	5679-5683	path	_	_	
11-535	5684-5695	checkpoints	_	_	
11-536	5695-5696	/	_	_	
11-537	5696-5714	checkpoint_best.pt	_	_	
11-538	5715-5716	\	_	_	
11-539	5721-5722	-	_	_	
11-540	5722-5723	s	_	_	
11-541	5724-5726	en	_	_	
11-542	5727-5728	-	_	_	
11-543	5728-5729	t	_	_	
11-544	5730-5732	de	_	_	
11-545	5733-5734	\	_	_	
11-546	5739-5740	-	_	_	
11-547	5740-5741	-	_	_	
11-548	5741-5751	batch-size	_	_	
11-549	5752-5755	128	_	_	
11-550	5756-5757	-	_	_	
11-551	5757-5758	-	_	_	
11-552	5758-5762	beam	_	_	
11-553	5763-5764	5	_	_	
11-554	5765-5766	-	_	_	
11-555	5766-5767	-	_	_	
11-556	5767-5773	lenpen	_	_	
11-557	5774-5777	0.6	_	_	
11-558	5778-5779	\	_	_	
11-559	5784-5785	-	_	_	
11-560	5785-5786	-	_	_	
11-561	5786-5793	scoring	_	_	
11-562	5794-5803	sacrebleu	_	_	
11-563	5804-5805	-	_	_	
11-564	5805-5806	-	_	_	
11-565	5806-5816	remove-bpe	_	_	
11-566	5817-5818	-	_	_	
11-567	5818-5819	-	_	_	
11-568	5819-5822	cpu	_	_	
11-569	5823-5824	>	_	_	
11-570	5824-5837	sacrebleu.log	_	_	
11-571	5838-5839	2	_	_	
11-572	5839-5840	>	_	_	
11-573	5840-5841	&	_	_	
11-574	5841-5842	1	_	_	
11-575	5843-5844	&	_	_	
11-576	5845-5846	`	_	_	
11-577	5846-5847	`	_	_	
11-578	5847-5848	`	_	_	
11-579	5850-5851	#	_	_	
11-580	5851-5852	#	_	_	
11-581	5853-5860	Authors	_	_	
11-582	5861-5862	*	_	_	
11-583	5863-5864	*	_	_	
11-584	5864-5865	*	_	_	
11-585	5865-5869	Ning	_	_	
11-586	5870-5873	Shi	_	_	
11-587	5873-5874	*	_	_	
11-588	5874-5875	*	_	_	
11-589	5876-5877	-	_	_	
11-590	5878-5890	mrshininnnnn	_	_	
11-591	5890-5891	@	_	_	
11-592	5891-5900	gmail.com	_	_	
11-593	5902-5903	#	_	_	
11-594	5903-5904	#	_	_	
11-595	5905-5911	BibTex	_	_	
11-596	5912-5913	`	_	_	
11-597	5913-5914	`	_	_	
11-598	5914-5915	`	_	_	
11-599	5916-5917	@	_	_	
11-600	5917-5930	inproceedings	_	_	
11-601	5930-5931	{	_	_	
11-602	5931-5939	shi-etal	_	_	
11-603	5939-5940	-	_	_	
11-604	5940-5944	2022	_	_	
11-605	5944-5945	-	_	_	
11-606	5945-5952	revisit	_	_	
11-607	5952-5953	,	_	_	
11-608	5958-5963	title	_	_	
11-609	5964-5965	=	_	_	
11-610	5966-5967	"	_	_	
11-611	5967-5974	Revisit	*[8]	PUBLICATION[8]	
11-612	5975-5985	Systematic	*[8]	PUBLICATION[8]	
11-613	5986-6000	Generalization	*[8]	PUBLICATION[8]	
11-614	6001-6004	via	*[8]	PUBLICATION[8]	
11-615	6005-6015	Meaningful	*[8]	PUBLICATION[8]	
11-616	6016-6024	Learning	*[8]	PUBLICATION[8]	
11-617	6024-6025	"	_	_	
11-618	6025-6026	,	_	_	
11-619	6031-6037	author	_	_	
11-620	6038-6039	=	_	_	
11-621	6040-6041	"	_	_	
11-622	6041-6044	Shi	_	_	
11-623	6044-6045	,	_	_	
11-624	6046-6050	Ning	_	_	
11-625	6052-6055	and	_	_	
11-626	6062-6066	Wang	_	_	
11-627	6066-6067	,	_	_	
11-628	6068-6073	Boxin	_	_	
11-629	6075-6078	and	_	_	
11-630	6085-6089	Wang	_	_	
11-631	6089-6090	,	_	_	
11-632	6091-6094	Wei	_	_	
11-633	6096-6099	and	_	_	
11-634	6106-6109	Liu	_	_	
11-635	6109-6110	,	_	_	
11-636	6111-6118	Xiangyu	_	_	
11-637	6120-6123	and	_	_	
11-638	6130-6133	Lin	_	_	
11-639	6133-6134	,	_	_	
11-640	6135-6142	Zhouhan	_	_	
11-641	6142-6143	"	_	_	
11-642	6143-6144	,	_	_	
11-643	6149-6158	booktitle	_	_	
11-644	6159-6160	=	_	_	
11-645	6161-6162	"	_	_	
11-646	6162-6173	Proceedings	*[9]	PUBLICATION[9]	
11-647	6174-6176	of	*[9]	PUBLICATION[9]	
11-648	6177-6180	the	*[9]	PUBLICATION[9]	
11-649	6181-6186	Fifth	*[9]|*[10]	PUBLICATION[9]|WORKSHOP[10]	
11-650	6187-6198	BlackboxNLP	*[9]|*[10]	PUBLICATION[9]|WORKSHOP[10]	
11-651	6199-6207	Workshop	*[9]|*[10]	PUBLICATION[9]|WORKSHOP[10]	
11-652	6208-6210	on	*[9]|*[10]	PUBLICATION[9]|WORKSHOP[10]	
11-653	6211-6220	Analyzing	*[9]|*[10]	PUBLICATION[9]|WORKSHOP[10]	
11-654	6221-6224	and	*[9]|*[10]	PUBLICATION[9]|WORKSHOP[10]	
11-655	6225-6237	Interpreting	*[9]|*[10]	PUBLICATION[9]|WORKSHOP[10]	
11-656	6238-6244	Neural	*[9]|*[10]	PUBLICATION[9]|WORKSHOP[10]	
11-657	6245-6253	Networks	*[9]|*[10]	PUBLICATION[9]|WORKSHOP[10]	
11-658	6254-6257	for	*[9]|*[10]	PUBLICATION[9]|WORKSHOP[10]	
11-659	6258-6261	NLP	*[9]|*[10]	PUBLICATION[9]|WORKSHOP[10]	
11-660	6261-6262	"	_	_	
11-661	6262-6263	,	_	_	
11-662	6268-6273	month	_	_	
11-663	6274-6275	=	_	_	
11-664	6276-6279	dec	_	_	
11-665	6279-6280	,	_	_	
11-666	6285-6289	year	_	_	
11-667	6290-6291	=	_	_	
11-668	6292-6293	"	_	_	
11-669	6293-6297	2022	_	_	
11-670	6297-6298	"	_	_	
11-671	6298-6299	,	_	_	
11-672	6304-6311	address	_	_	
11-673	6312-6313	=	_	_	
11-674	6314-6315	"	_	_	
11-675	6315-6318	Abu	_	_	
11-676	6319-6324	Dhabi	_	_	
11-677	6324-6325	,	_	_	
11-678	6326-6332	United	_	_	
11-679	6333-6337	Arab	_	_	
11-680	6338-6346	Emirates	_	_	
11-681	6347-6348	(	_	_	
11-682	6348-6354	Hybrid	_	_	
11-683	6354-6355	)	_	_	
11-684	6355-6356	"	_	_	
11-685	6356-6357	,	_	_	
11-686	6362-6371	publisher	_	_	
11-687	6372-6373	=	_	_	
11-688	6374-6375	"	_	_	
11-689	6375-6386	Association	_	_	
11-690	6387-6390	for	_	_	
11-691	6391-6404	Computational	_	_	
11-692	6405-6416	Linguistics	_	_	
11-693	6416-6417	"	_	_	
11-694	6417-6418	,	_	_	
11-695	6423-6426	url	_	_	
11-696	6427-6428	=	_	_	
11-697	6429-6430	"	_	_	
11-698	6430-6435	https	_	_	
11-699	6435-6436	:	_	_	
11-700	6436-6437	/	_	_	
11-701	6437-6438	/	_	_	
11-702	6438-6454	aclanthology.org	_	_	
11-703	6454-6455	/	_	_	
11-704	6455-6459	2022	_	_	
11-705	6459-6460	.	_	_	
11-706	6460-6471	blackboxnlp	_	_	
11-707	6471-6472	-	_	_	
11-708	6472-6475	1.6	_	_	
11-709	6475-6476	"	_	_	
11-710	6476-6477	,	_	_	
11-711	6482-6487	pages	_	_	
11-712	6488-6489	=	_	_	
11-713	6490-6491	"	_	_	
11-714	6491-6493	62	_	_	
11-715	6493-6494	-	_	_	
11-716	6494-6495	-	_	_	
11-717	6495-6497	79	_	_	
11-718	6497-6498	"	_	_	
11-719	6498-6499	,	_	_	
11-720	6504-6512	abstract	_	_	
11-721	6513-6514	=	_	_	
11-722	6515-6516	"	_	_	
11-723	6516-6522	Humans	_	_	
11-724	6523-6526	can	_	_	
11-725	6527-6541	systematically	_	_	
11-726	6542-6552	generalize	_	_	
11-727	6553-6555	to	_	_	
11-728	6556-6561	novel	_	_	
11-729	6562-6574	compositions	_	_	
11-730	6575-6577	of	_	_	
11-731	6578-6586	existing	_	_	
11-732	6587-6595	concepts	_	_	
11-733	6595-6596	.	_	_	

#Text=Recent studies argue that neural networks appear inherently ineffective in such cognitive capacity, leading to a pessimistic view and a lack of attention to optimistic results.
12-1	6597-6603	Recent	_	_	
12-2	6604-6611	studies	_	_	
12-3	6612-6617	argue	_	_	
12-4	6618-6622	that	_	_	
12-5	6623-6629	neural	_	_	
12-6	6630-6638	networks	_	_	
12-7	6639-6645	appear	_	_	
12-8	6646-6656	inherently	_	_	
12-9	6657-6668	ineffective	_	_	
12-10	6669-6671	in	_	_	
12-11	6672-6676	such	_	_	
12-12	6677-6686	cognitive	_	_	
12-13	6687-6695	capacity	_	_	
12-14	6695-6696	,	_	_	
12-15	6697-6704	leading	_	_	
12-16	6705-6707	to	_	_	
12-17	6708-6709	a	_	_	
12-18	6710-6721	pessimistic	_	_	
12-19	6722-6726	view	_	_	
12-20	6727-6730	and	_	_	
12-21	6731-6732	a	_	_	
12-22	6733-6737	lack	_	_	
12-23	6738-6740	of	_	_	
12-24	6741-6750	attention	_	_	
12-25	6751-6753	to	_	_	
12-26	6754-6764	optimistic	_	_	
12-27	6765-6772	results	_	_	
12-28	6772-6773	.	_	_	

#Text=We revisit this controversial topic from the perspective of meaningful learning, an exceptional capability of humans to learn novel concepts by connecting them with known ones.
13-1	6774-6776	We	_	_	
13-2	6777-6784	revisit	_	_	
13-3	6785-6789	this	_	_	
13-4	6790-6803	controversial	_	_	
13-5	6804-6809	topic	_	_	
13-6	6810-6814	from	_	_	
13-7	6815-6818	the	_	_	
13-8	6819-6830	perspective	_	_	
13-9	6831-6833	of	_	_	
13-10	6834-6844	meaningful	_	_	
13-11	6845-6853	learning	_	_	
13-12	6853-6854	,	_	_	
13-13	6855-6857	an	_	_	
13-14	6858-6869	exceptional	_	_	
13-15	6870-6880	capability	_	_	
13-16	6881-6883	of	_	_	
13-17	6884-6890	humans	_	_	
13-18	6891-6893	to	_	_	
13-19	6894-6899	learn	_	_	
13-20	6900-6905	novel	_	_	
13-21	6906-6914	concepts	_	_	
13-22	6915-6917	by	_	_	
13-23	6918-6928	connecting	_	_	
13-24	6929-6933	them	_	_	
13-25	6934-6938	with	_	_	
13-26	6939-6944	known	_	_	
13-27	6945-6949	ones	_	_	
13-28	6949-6950	.	_	_	

#Text=We reassess the compositional skills of sequence-to-sequence models conditioned on the semantic links between new and old concepts.
14-1	6951-6953	We	_	_	
14-2	6954-6962	reassess	_	_	
14-3	6963-6966	the	_	_	
14-4	6967-6980	compositional	_	_	
14-5	6981-6987	skills	_	_	
14-6	6988-6990	of	_	_	
14-7	6991-7011	sequence-to-sequence	_	_	
14-8	7012-7018	models	_	_	
14-9	7019-7030	conditioned	_	_	
14-10	7031-7033	on	_	_	
14-11	7034-7037	the	_	_	
14-12	7038-7046	semantic	_	_	
14-13	7047-7052	links	_	_	
14-14	7053-7060	between	_	_	
14-15	7061-7064	new	_	_	
14-16	7065-7068	and	_	_	
14-17	7069-7072	old	_	_	
14-18	7073-7081	concepts	_	_	
14-19	7081-7082	.	_	_	

#Text=Our observations suggest that models can successfully one-shot generalize to novel concepts and compositions through semantic linking, either inductively or deductively.
15-1	7083-7086	Our	_	_	
15-2	7087-7099	observations	_	_	
15-3	7100-7107	suggest	_	_	
15-4	7108-7112	that	_	_	
15-5	7113-7119	models	_	_	
15-6	7120-7123	can	_	_	
15-7	7124-7136	successfully	_	_	
15-8	7137-7145	one-shot	_	_	
15-9	7146-7156	generalize	_	_	
15-10	7157-7159	to	_	_	
15-11	7160-7165	novel	_	_	
15-12	7166-7174	concepts	_	_	
15-13	7175-7178	and	_	_	
15-14	7179-7191	compositions	_	_	
15-15	7192-7199	through	_	_	
15-16	7200-7208	semantic	_	_	
15-17	7209-7216	linking	_	_	
15-18	7216-7217	,	_	_	
15-19	7218-7224	either	_	_	
15-20	7225-7236	inductively	_	_	
15-21	7237-7239	or	_	_	
15-22	7240-7251	deductively	_	_	
15-23	7251-7252	.	_	_	

#Text=We demonstrate that prior knowledge plays a key role as well.
16-1	7253-7255	We	_	_	
16-2	7256-7267	demonstrate	_	_	
16-3	7268-7272	that	_	_	
16-4	7273-7278	prior	_	_	
16-5	7279-7288	knowledge	_	_	
16-6	7289-7294	plays	_	_	
16-7	7295-7296	a	_	_	
16-8	7297-7300	key	_	_	
16-9	7301-7305	role	_	_	
16-10	7306-7308	as	_	_	
16-11	7309-7313	well	_	_	
16-12	7313-7314	.	_	_	

#Text=In addition to synthetic tests, we further conduct proof-of-concept experiments in machine translation and semantic parsing, showing the benefits of meaningful learning in applications.
17-1	7315-7317	In	_	_	
17-2	7318-7326	addition	_	_	
17-3	7327-7329	to	_	_	
17-4	7330-7339	synthetic	_	_	
17-5	7340-7345	tests	_	_	
17-6	7345-7346	,	_	_	
17-7	7347-7349	we	_	_	
17-8	7350-7357	further	_	_	
17-9	7358-7365	conduct	_	_	
17-10	7366-7382	proof-of-concept	_	_	
17-11	7383-7394	experiments	_	_	
17-12	7395-7397	in	_	_	
17-13	7398-7405	machine	_	_	
17-14	7406-7417	translation	_	_	
17-15	7418-7421	and	_	_	
17-16	7422-7430	semantic	_	_	
17-17	7431-7438	parsing	_	_	
17-18	7438-7439	,	_	_	
17-19	7440-7447	showing	_	_	
17-20	7448-7451	the	_	_	
17-21	7452-7460	benefits	_	_	
17-22	7461-7463	of	_	_	
17-23	7464-7474	meaningful	_	_	
17-24	7475-7483	learning	_	_	
17-25	7484-7486	in	_	_	
17-26	7487-7499	applications	_	_	
17-27	7499-7500	.	_	_	

#Text=We hope our positive findings will encourage excavating modern neural networks{'} potential in systematic generalization through more advanced learning schemes.",
#Text=}
#Text=```
18-1	7501-7503	We	_	_	
18-2	7504-7508	hope	_	_	
18-3	7509-7512	our	_	_	
18-4	7513-7521	positive	_	_	
18-5	7522-7530	findings	_	_	
18-6	7531-7535	will	_	_	
18-7	7536-7545	encourage	_	_	
18-8	7546-7556	excavating	_	_	
18-9	7557-7563	modern	_	_	
18-10	7564-7570	neural	_	_	
18-11	7571-7579	networks	_	_	
18-12	7579-7580	{	_	_	
18-13	7580-7581	'	_	_	
18-14	7581-7582	}	_	_	
18-15	7583-7592	potential	_	_	
18-16	7593-7595	in	_	_	
18-17	7596-7606	systematic	_	_	
18-18	7607-7621	generalization	_	_	
18-19	7622-7629	through	_	_	
18-20	7630-7634	more	_	_	
18-21	7635-7643	advanced	_	_	
18-22	7644-7652	learning	_	_	
18-23	7653-7660	schemes	_	_	
18-24	7660-7661	.	_	_	
18-25	7661-7662	"	_	_	
18-26	7662-7663	,	_	_	
18-27	7664-7665	}	_	_	
18-28	7666-7667	`	_	_	
18-29	7667-7668	`	_	_	
18-30	7668-7669	`	_	_	
