#FORMAT=WebAnno TSV 3.3
#T_SP=de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity|identifier|value


#Text=# OpenAUC: Towards AUC-Oriented Open-Set Recognition
#Text=This is a Pytorch implementation of our paper: [OpenAUC: Towards AUC-Oriented Open-Set Recognition](https://arxiv.org/abs/2210.13458).
1-1	0-1	#	_	_	
1-2	2-9	OpenAUC	*[1]|*[2]	PUBLICATION[1]|EVALMETRIC[2]	
1-3	9-10	:	*[1]	PUBLICATION[1]	
1-4	11-18	Towards	*[1]	PUBLICATION[1]	
1-5	19-31	AUC-Oriented	*[1]	PUBLICATION[1]	
1-6	32-40	Open-Set	*[1]	PUBLICATION[1]	
1-7	41-52	Recognition	*[1]	PUBLICATION[1]	
1-8	53-57	This	_	_	
1-9	58-60	is	_	_	
1-10	61-62	a	_	_	
1-11	63-70	Pytorch	*	SOFTWARE	
1-12	71-85	implementation	_	_	
1-13	86-88	of	_	_	
1-14	89-92	our	_	_	
1-15	93-98	paper	_	_	
1-16	98-99	:	_	_	
1-17	100-101	[	_	_	
1-18	101-108	OpenAUC	*[3]|*[4]	PUBLICATION[3]|EVALMETRIC[4]	
1-19	108-109	:	*[3]	PUBLICATION[3]	
1-20	110-117	Towards	*[3]	PUBLICATION[3]	
1-21	118-130	AUC-Oriented	*[3]	PUBLICATION[3]	
1-22	131-139	Open-Set	*[3]	PUBLICATION[3]	
1-23	140-151	Recognition	*[3]	PUBLICATION[3]	
1-24	151-152	]	_	_	
1-25	152-153	(	_	_	
1-26	153-158	https	_	_	
1-27	158-159	:	_	_	
1-28	159-160	/	_	_	
1-29	160-161	/	_	_	
1-30	161-170	arxiv.org	_	_	
1-31	170-171	/	_	_	
1-32	171-174	abs	_	_	
1-33	174-175	/	_	_	
1-34	175-185	2210.13458	_	_	
1-35	185-186	)	_	_	
1-36	186-187	.	_	_	

#Text=**If you only want to evaluate the model performance on OpenAUC,** please refer the file `utils/test_utils`.
2-1	188-189	*	_	_	
2-2	189-190	*	_	_	
2-3	190-192	If	_	_	
2-4	193-196	you	_	_	
2-5	197-201	only	_	_	
2-6	202-206	want	_	_	
2-7	207-209	to	_	_	
2-8	210-218	evaluate	_	_	
2-9	219-222	the	_	_	
2-10	223-228	model	_	_	
2-11	229-240	performance	_	_	
2-12	241-243	on	_	_	
2-13	244-251	OpenAUC	*	EVALMETRIC	
2-14	251-252	,	_	_	
2-15	252-253	*	_	_	
2-16	253-254	*	_	_	
2-17	255-261	please	_	_	
2-18	262-267	refer	_	_	
2-19	268-271	the	_	_	
2-20	272-276	file	_	_	
2-21	277-278	`	_	_	
2-22	278-283	utils	_	_	
2-23	283-284	/	_	_	
2-24	284-294	test_utils	_	_	
2-25	294-295	`	_	_	
2-26	295-296	.	_	_	

#Text=And a more detailed instruction can be found in our [library](https://github.com/statusrank/XCurve/blob/master/example/example_ipynb/Metrics_for_AUTKC_OpenAUC.ipynb)
3-1	297-300	And	_	_	
3-2	301-302	a	_	_	
3-3	303-307	more	_	_	
3-4	308-316	detailed	_	_	
3-5	317-328	instruction	_	_	
3-6	329-332	can	_	_	
3-7	333-335	be	_	_	
3-8	336-341	found	_	_	
3-9	342-344	in	_	_	
3-10	345-348	our	_	_	
3-11	349-350	[	_	_	
3-12	350-357	library	_	_	
3-13	357-358	]	_	_	
3-14	358-359	(	_	_	
3-15	359-364	https	_	_	
3-16	364-365	:	_	_	
3-17	365-366	/	_	_	
3-18	366-367	/	_	_	
3-19	367-377	github.com	_	_	
3-20	377-378	/	_	_	
3-21	378-388	statusrank	_	_	
3-22	388-389	/	_	_	
3-23	389-395	XCurve	_	_	
3-24	395-396	/	_	_	
3-25	396-400	blob	_	_	
3-26	400-401	/	_	_	
3-27	401-407	master	_	_	
3-28	407-408	/	_	_	
3-29	408-415	example	_	_	
3-30	415-416	/	_	_	
3-31	416-429	example_ipynb	_	_	
3-32	429-430	/	_	_	
3-33	430-461	Metrics_for_AUTKC_OpenAUC.ipynb	_	_	
3-33.1	448-455	OpenAUC	*	EVALMETRIC	
3-34	461-462	)	_	_	

#Text=.
4-1	462-463	.	_	_	

#Text=> **Abstract:** Traditional machine learning follows a close-set assumption that the training and test set share the same label space.
5-1	465-466	>	_	_	
5-2	467-468	*	_	_	
5-3	468-469	*	_	_	
5-4	469-477	Abstract	_	_	
5-5	477-478	:	_	_	
5-6	478-479	*	_	_	
5-7	479-480	*	_	_	
5-8	481-492	Traditional	_	_	
5-9	493-500	machine	_	_	
5-10	501-509	learning	_	_	
5-11	510-517	follows	_	_	
5-12	518-519	a	_	_	
5-13	520-529	close-set	_	_	
5-14	530-540	assumption	_	_	
5-15	541-545	that	_	_	
5-16	546-549	the	_	_	
5-17	550-558	training	_	_	
5-18	559-562	and	_	_	
5-19	563-567	test	_	_	
5-20	568-571	set	_	_	
5-21	572-577	share	_	_	
5-22	578-581	the	_	_	
5-23	582-586	same	_	_	
5-24	587-592	label	_	_	
5-25	593-598	space	_	_	
5-26	598-599	.	_	_	

#Text=While in many practical scenarios, it is inevitable that some test samples belong to unknown classes (open-set).
6-1	600-605	While	_	_	
6-2	606-608	in	_	_	
6-3	609-613	many	_	_	
6-4	614-623	practical	_	_	
6-5	624-633	scenarios	_	_	
6-6	633-634	,	_	_	
6-7	635-637	it	_	_	
6-8	638-640	is	_	_	
6-9	641-651	inevitable	_	_	
6-10	652-656	that	_	_	
6-11	657-661	some	_	_	
6-12	662-666	test	_	_	
6-13	667-674	samples	_	_	
6-14	675-681	belong	_	_	
6-15	682-684	to	_	_	
6-16	685-692	unknown	_	_	
6-17	693-700	classes	_	_	
6-18	701-702	(	_	_	
6-19	702-710	open-set	_	_	
6-20	710-711	)	_	_	
6-21	711-712	.	_	_	

#Text=To fix this issue, Open-Set Recognition (OSR), whose goal is to make correct predictions on both close-set samples and open-set samples, has attracted rising attention.
7-1	713-715	To	_	_	
7-2	716-719	fix	_	_	
7-3	720-724	this	_	_	
7-4	725-730	issue	_	_	
7-5	730-731	,	_	_	
7-6	732-740	Open-Set	_	_	
7-7	741-752	Recognition	_	_	
7-8	753-754	(	_	_	
7-9	754-757	OSR	_	_	
7-10	757-758	)	_	_	
7-11	758-759	,	_	_	
7-12	760-765	whose	_	_	
7-13	766-770	goal	_	_	
7-14	771-773	is	_	_	
7-15	774-776	to	_	_	
7-16	777-781	make	_	_	
7-17	782-789	correct	_	_	
7-18	790-801	predictions	_	_	
7-19	802-804	on	_	_	
7-20	805-809	both	_	_	
7-21	810-819	close-set	_	_	
7-22	820-827	samples	_	_	
7-23	828-831	and	_	_	
7-24	832-840	open-set	_	_	
7-25	841-848	samples	_	_	
7-26	848-849	,	_	_	
7-27	850-853	has	_	_	
7-28	854-863	attracted	_	_	
7-29	864-870	rising	_	_	
7-30	871-880	attention	_	_	
7-31	880-881	.	_	_	

#Text=In this direction, the vast majority of literature focuses on the pattern of open-set samples.
8-1	882-884	In	_	_	
8-2	885-889	this	_	_	
8-3	890-899	direction	_	_	
8-4	899-900	,	_	_	
8-5	901-904	the	_	_	
8-6	905-909	vast	_	_	
8-7	910-918	majority	_	_	
8-8	919-921	of	_	_	
8-9	922-932	literature	_	_	
8-10	933-940	focuses	_	_	
8-11	941-943	on	_	_	
8-12	944-947	the	_	_	
8-13	948-955	pattern	_	_	
8-14	956-958	of	_	_	
8-15	959-967	open-set	_	_	
8-16	968-975	samples	_	_	
8-17	975-976	.	_	_	

#Text=However, how to evaluate model performance in this challenging task is still unsolved.
9-1	977-984	However	_	_	
9-2	984-985	,	_	_	
9-3	986-989	how	_	_	
9-4	990-992	to	_	_	
9-5	993-1001	evaluate	_	_	
9-6	1002-1007	model	_	_	
9-7	1008-1019	performance	_	_	
9-8	1020-1022	in	_	_	
9-9	1023-1027	this	_	_	
9-10	1028-1039	challenging	_	_	
9-11	1040-1044	task	_	_	
9-12	1045-1047	is	_	_	
9-13	1048-1053	still	_	_	
9-14	1054-1062	unsolved	_	_	
9-15	1062-1063	.	_	_	

#Text=In this paper, a systematic analysis reveals that most existing metrics are essentially inconsistent with the aforementioned goal of OSR: (1) For metrics extended from close-set classification, such as Open-set F-score, Youden's index, and Normalized Accuracy, a poor open-set prediction can escape from a low performance score with a superior close-set prediction. (2) Novelty detection AUC, which measures the ranking performance between close-set and open-set samples, ignores the close-set performance.
10-1	1064-1066	In	_	_	
10-2	1067-1071	this	_	_	
10-3	1072-1077	paper	_	_	
10-4	1077-1078	,	_	_	
10-5	1079-1080	a	_	_	
10-6	1081-1091	systematic	_	_	
10-7	1092-1100	analysis	_	_	
10-8	1101-1108	reveals	_	_	
10-9	1109-1113	that	_	_	
10-10	1114-1118	most	_	_	
10-11	1119-1127	existing	_	_	
10-12	1128-1135	metrics	_	_	
10-13	1136-1139	are	_	_	
10-14	1140-1151	essentially	_	_	
10-15	1152-1164	inconsistent	_	_	
10-16	1165-1169	with	_	_	
10-17	1170-1173	the	_	_	
10-18	1174-1188	aforementioned	_	_	
10-19	1189-1193	goal	_	_	
10-20	1194-1196	of	_	_	
10-21	1197-1200	OSR	_	_	
10-22	1200-1201	:	_	_	
10-23	1202-1203	(	_	_	
10-24	1203-1204	1	_	_	
10-25	1204-1205	)	_	_	
10-26	1206-1209	For	_	_	
10-27	1210-1217	metrics	_	_	
10-28	1218-1226	extended	_	_	
10-29	1227-1231	from	_	_	
10-30	1232-1241	close-set	_	_	
10-31	1242-1256	classification	_	_	
10-32	1256-1257	,	_	_	
10-33	1258-1262	such	_	_	
10-34	1263-1265	as	_	_	
10-35	1266-1274	Open-set	*[5]	EVALMETRIC[5]	
10-36	1275-1282	F-score	*[5]	EVALMETRIC[5]	
10-37	1282-1283	,	_	_	
10-38	1284-1292	Youden's	*[6]	EVALMETRIC[6]	
10-39	1293-1298	index	*[6]	EVALMETRIC[6]	
10-40	1298-1299	,	_	_	
10-41	1300-1303	and	_	_	
10-42	1304-1314	Normalized	*[7]	EVALMETRIC[7]	
10-43	1315-1323	Accuracy	*[7]	EVALMETRIC[7]	
10-44	1323-1324	,	_	_	
10-45	1325-1326	a	_	_	
10-46	1327-1331	poor	_	_	
10-47	1332-1340	open-set	_	_	
10-48	1341-1351	prediction	_	_	
10-49	1352-1355	can	_	_	
10-50	1356-1362	escape	_	_	
10-51	1363-1367	from	_	_	
10-52	1368-1369	a	_	_	
10-53	1370-1373	low	_	_	
10-54	1374-1385	performance	_	_	
10-55	1386-1391	score	_	_	
10-56	1392-1396	with	_	_	
10-57	1397-1398	a	_	_	
10-58	1399-1407	superior	_	_	
10-59	1408-1417	close-set	_	_	
10-60	1418-1428	prediction	_	_	
10-61	1428-1429	.	_	_	
10-62	1430-1431	(	_	_	
10-63	1431-1432	2	_	_	
10-64	1432-1433	)	_	_	
10-65	1434-1441	Novelty	_	_	
10-66	1442-1451	detection	_	_	
10-67	1452-1455	AUC	*	EVALMETRIC	
10-68	1455-1456	,	_	_	
10-69	1457-1462	which	_	_	
10-70	1463-1471	measures	_	_	
10-71	1472-1475	the	_	_	
10-72	1476-1483	ranking	_	_	
10-73	1484-1495	performance	_	_	
10-74	1496-1503	between	_	_	
10-75	1504-1513	close-set	_	_	
10-76	1514-1517	and	_	_	
10-77	1518-1526	open-set	_	_	
10-78	1527-1534	samples	_	_	
10-79	1534-1535	,	_	_	
10-80	1536-1543	ignores	_	_	
10-81	1544-1547	the	_	_	
10-82	1548-1557	close-set	_	_	
10-83	1558-1569	performance	_	_	
10-84	1569-1570	.	_	_	

#Text=To fix these issues, we propose a novel metric named OpenAUC.
11-1	1571-1573	To	_	_	
11-2	1574-1577	fix	_	_	
11-3	1578-1583	these	_	_	
11-4	1584-1590	issues	_	_	
11-5	1590-1591	,	_	_	
11-6	1592-1594	we	_	_	
11-7	1595-1602	propose	_	_	
11-8	1603-1604	a	_	_	
11-9	1605-1610	novel	_	_	
11-10	1611-1617	metric	_	_	
11-11	1618-1623	named	_	_	
11-12	1624-1631	OpenAUC	*	EVALMETRIC	
11-13	1631-1632	.	_	_	

#Text=Compared with existing metrics, OpenAUC enjoys a concise pairwise formulation that evaluates open-set performance and close-set performance in a coupling manner.
12-1	1633-1641	Compared	_	_	
12-2	1642-1646	with	_	_	
12-3	1647-1655	existing	_	_	
12-4	1656-1663	metrics	_	_	
12-5	1663-1664	,	_	_	
12-6	1665-1672	OpenAUC	*	EVALMETRIC	
12-7	1673-1679	enjoys	_	_	
12-8	1680-1681	a	_	_	
12-9	1682-1689	concise	_	_	
12-10	1690-1698	pairwise	_	_	
12-11	1699-1710	formulation	_	_	
12-12	1711-1715	that	_	_	
12-13	1716-1725	evaluates	_	_	
12-14	1726-1734	open-set	_	_	
12-15	1735-1746	performance	_	_	
12-16	1747-1750	and	_	_	
12-17	1751-1760	close-set	_	_	
12-18	1761-1772	performance	_	_	
12-19	1773-1775	in	_	_	
12-20	1776-1777	a	_	_	
12-21	1778-1786	coupling	_	_	
12-22	1787-1793	manner	_	_	
12-23	1793-1794	.	_	_	

#Text=Further analysis shows that OpenAUC is free from the aforementioned inconsistency properties.
13-1	1795-1802	Further	_	_	
13-2	1803-1811	analysis	_	_	
13-3	1812-1817	shows	_	_	
13-4	1818-1822	that	_	_	
13-5	1823-1830	OpenAUC	*	EVALMETRIC	
13-6	1831-1833	is	_	_	
13-7	1834-1838	free	_	_	
13-8	1839-1843	from	_	_	
13-9	1844-1847	the	_	_	
13-10	1848-1862	aforementioned	_	_	
13-11	1863-1876	inconsistency	_	_	
13-12	1877-1887	properties	_	_	
13-13	1887-1888	.	_	_	

#Text=Finally, an end-to-end learning method is proposed to minimize the OpenAUC risk, and the experimental results on popular benchmark datasets speak to its effectiveness.
14-1	1889-1896	Finally	_	_	
14-2	1896-1897	,	_	_	
14-3	1898-1900	an	_	_	
14-4	1901-1911	end-to-end	_	_	
14-5	1912-1920	learning	_	_	
14-6	1921-1927	method	_	_	
14-7	1928-1930	is	_	_	
14-8	1931-1939	proposed	_	_	
14-9	1940-1942	to	_	_	
14-10	1943-1951	minimize	_	_	
14-11	1952-1955	the	_	_	
14-12	1956-1963	OpenAUC	*	EVALMETRIC	
14-13	1964-1968	risk	_	_	
14-14	1968-1969	,	_	_	
14-15	1970-1973	and	_	_	
14-16	1974-1977	the	_	_	
14-17	1978-1990	experimental	_	_	
14-18	1991-1998	results	_	_	
14-19	1999-2001	on	_	_	
14-20	2002-2009	popular	_	_	
14-21	2010-2019	benchmark	_	_	
14-22	2020-2028	datasets	_	_	
14-23	2029-2034	speak	_	_	
14-24	2035-2037	to	_	_	
14-25	2038-2041	its	_	_	
14-26	2042-2055	effectiveness	_	_	
14-27	2055-2056	.	_	_	

#Text=Our codes are based on the repositories [Open-Set Recognition: a Good Closed-Set Classifier is All You Need?]
15-1	2058-2061	Our	_	_	
15-2	2062-2067	codes	_	_	
15-3	2068-2071	are	_	_	
15-4	2072-2077	based	_	_	
15-5	2078-2080	on	_	_	
15-6	2081-2084	the	_	_	
15-7	2085-2097	repositories	_	_	
15-8	2098-2099	[	_	_	
15-9	2099-2107	Open-Set	_	_	
15-10	2108-2119	Recognition	_	_	
15-11	2119-2120	:	_	_	
15-12	2121-2122	a	_	_	
15-13	2123-2127	Good	_	_	
15-14	2128-2138	Closed-Set	_	_	
15-15	2139-2149	Classifier	_	_	
15-16	2150-2152	is	_	_	
15-17	2153-2156	All	_	_	
15-18	2157-2160	You	_	_	
15-19	2161-2165	Need	_	_	
15-20	2165-2166	?	_	_	
15-21	2166-2167	]	_	_	

#Text=(https://github.com/sgvaze/osr_closed_set_all_you_need) and [Learning Placeholders for Open-Set Recognition](https://github.com/zhoudw-zdw/CVPR21-Proser).
#Text=
#Text=## Dependencies
#Text=Please refer to the `requirements.yml` in the root folder.
#Text=
#Text=## Settings
#Text=The parameters are stored in the file `utils/config.py`.
16-1	2167-2168	(	_	_	
16-2	2168-2173	https	_	_	
16-3	2173-2174	:	_	_	
16-4	2174-2175	/	_	_	
16-5	2175-2176	/	_	_	
16-6	2176-2186	github.com	_	_	
16-7	2186-2187	/	_	_	
16-8	2187-2193	sgvaze	_	_	
16-9	2193-2194	/	_	_	
16-10	2194-2221	osr_closed_set_all_you_need	_	_	
16-11	2221-2222	)	_	_	
16-12	2223-2226	and	_	_	
16-13	2227-2228	[	_	_	
16-14	2228-2236	Learning	*[8]	PUBLICATION[8]	
16-15	2237-2249	Placeholders	*[8]	PUBLICATION[8]	
16-16	2250-2253	for	*[8]	PUBLICATION[8]	
16-17	2254-2262	Open-Set	*[8]	PUBLICATION[8]	
16-18	2263-2274	Recognition	*[8]	PUBLICATION[8]	
16-19	2274-2275	]	_	_	
16-20	2275-2276	(	_	_	
16-21	2276-2281	https	_	_	
16-22	2281-2282	:	_	_	
16-23	2282-2283	/	_	_	
16-24	2283-2284	/	_	_	
16-25	2284-2294	github.com	_	_	
16-26	2294-2295	/	_	_	
16-27	2295-2305	zhoudw-zdw	_	_	
16-28	2305-2306	/	_	_	
16-29	2306-2312	CVPR21	*	CONFERENCE	
16-30	2312-2313	-	_	_	
16-31	2313-2319	Proser	_	_	
16-32	2319-2320	)	_	_	
16-33	2320-2321	.	_	_	
16-34	2323-2324	#	_	_	
16-35	2324-2325	#	_	_	
16-36	2326-2338	Dependencies	_	_	
16-37	2339-2345	Please	_	_	
16-38	2346-2351	refer	_	_	
16-39	2352-2354	to	_	_	
16-40	2355-2358	the	_	_	
16-41	2359-2360	`	_	_	
16-42	2360-2376	requirements.yml	_	_	
16-43	2376-2377	`	_	_	
16-44	2378-2380	in	_	_	
16-45	2381-2384	the	_	_	
16-46	2385-2389	root	_	_	
16-47	2390-2396	folder	_	_	
16-48	2396-2397	.	_	_	
16-49	2399-2400	#	_	_	
16-50	2400-2401	#	_	_	
16-51	2402-2410	Settings	_	_	
16-52	2411-2414	The	_	_	
16-53	2415-2425	parameters	_	_	
16-54	2426-2429	are	_	_	
16-55	2430-2436	stored	_	_	
16-56	2437-2439	in	_	_	
16-57	2440-2443	the	_	_	
16-58	2444-2448	file	_	_	
16-59	2449-2450	`	_	_	
16-60	2450-2455	utils	_	_	
16-61	2455-2456	/	_	_	
16-62	2456-2465	config.py	_	_	
16-63	2465-2466	`	_	_	
16-64	2466-2467	.	_	_	

#Text=The datasets can be found in the README of [Open-Set Recognition: a Good Closed-Set Classifier is All You Need?]
17-1	2469-2472	The	_	_	
17-2	2473-2481	datasets	_	_	
17-3	2482-2485	can	_	_	
17-4	2486-2488	be	_	_	
17-5	2489-2494	found	_	_	
17-6	2495-2497	in	_	_	
17-7	2498-2501	the	_	_	
17-8	2502-2508	README	_	_	
17-9	2509-2511	of	_	_	
17-10	2512-2513	[	_	_	
17-11	2513-2521	Open-Set	*[9]	PUBLICATION[9]	
17-12	2522-2533	Recognition	*[9]	PUBLICATION[9]	
17-13	2533-2534	:	*[9]	PUBLICATION[9]	
17-14	2535-2536	a	*[9]	PUBLICATION[9]	
17-15	2537-2541	Good	*[9]	PUBLICATION[9]	
17-16	2542-2552	Closed-Set	*[9]	PUBLICATION[9]	
17-17	2553-2563	Classifier	*[9]	PUBLICATION[9]	
17-18	2564-2566	is	*[9]	PUBLICATION[9]	
17-19	2567-2570	All	*[9]	PUBLICATION[9]	
17-20	2571-2574	You	*[9]	PUBLICATION[9]	
17-21	2575-2579	Need	*[9]	PUBLICATION[9]	
17-22	2579-2580	?	*[9]	PUBLICATION[9]	
17-23	2580-2581	]	_	_	

#Text=(https://github.com/sgvaze/osr_closed_set_all_you_need).
18-1	2581-2582	(	_	_	
18-2	2582-2587	https	_	_	
18-3	2587-2588	:	_	_	
18-4	2588-2589	/	_	_	
18-5	2589-2590	/	_	_	
18-6	2590-2600	github.com	_	_	
18-7	2600-2601	/	_	_	
18-8	2601-2607	sgvaze	_	_	
18-9	2607-2608	/	_	_	
18-10	2608-2635	osr_closed_set_all_you_need	_	_	
18-11	2635-2636	)	_	_	
18-12	2636-2637	.	_	_	

#Text=After downloading the datasets, please put them in the folder `data`.
19-1	2638-2643	After	_	_	
19-2	2644-2655	downloading	_	_	
19-3	2656-2659	the	_	_	
19-4	2660-2668	datasets	_	_	
19-5	2668-2669	,	_	_	
19-6	2670-2676	please	_	_	
19-7	2677-2680	put	_	_	
19-8	2681-2685	them	_	_	
19-9	2686-2688	in	_	_	
19-10	2689-2692	the	_	_	
19-11	2693-2699	folder	_	_	
19-12	2700-2701	`	_	_	
19-13	2701-2705	data	_	_	
19-14	2705-2706	`	_	_	
19-15	2706-2707	.	_	_	

#Text=Please put pre-trained models in the folder `models`.
20-1	2709-2715	Please	_	_	
20-2	2716-2719	put	_	_	
20-3	2720-2731	pre-trained	_	_	
20-4	2732-2738	models	_	_	
20-5	2739-2741	in	_	_	
20-6	2742-2745	the	_	_	
20-7	2746-2752	folder	_	_	
20-8	2753-2754	`	_	_	
20-9	2754-2760	models	_	_	
20-10	2760-2761	`	_	_	
20-11	2761-2762	.	_	_	

#Text=And all the outputs will be stored in the folder `log` with a unique id.
21-1	2763-2766	And	_	_	
21-2	2767-2770	all	_	_	
21-3	2771-2774	the	_	_	
21-4	2775-2782	outputs	_	_	
21-5	2783-2787	will	_	_	
21-6	2788-2790	be	_	_	
21-7	2791-2797	stored	_	_	
21-8	2798-2800	in	_	_	
21-9	2801-2804	the	_	_	
21-10	2805-2811	folder	_	_	
21-11	2812-2813	`	_	_	
21-12	2813-2816	log	_	_	
21-13	2816-2817	`	_	_	
21-14	2818-2822	with	_	_	
21-15	2823-2824	a	_	_	
21-16	2825-2831	unique	_	_	
21-17	2832-2834	id	_	_	
21-18	2834-2835	.	_	_	

#Text=We provide the bash script in the folder `bash_scripts` for the experiments on the *CUB* dataset.
22-1	2837-2839	We	_	_	
22-2	2840-2847	provide	_	_	
22-3	2848-2851	the	_	_	
22-4	2852-2856	bash	*	SOFTWARE	
22-5	2857-2863	script	_	_	
22-6	2864-2866	in	_	_	
22-7	2867-2870	the	_	_	
22-8	2871-2877	folder	_	_	
22-9	2878-2879	`	_	_	
22-10	2879-2891	bash_scripts	_	_	
22-11	2891-2892	`	_	_	
22-12	2893-2896	for	_	_	
22-13	2897-2900	the	_	_	
22-14	2901-2912	experiments	_	_	
22-15	2913-2915	on	_	_	
22-16	2916-2919	the	_	_	
22-17	2920-2921	*	_	_	
22-18	2921-2924	CUB	*	DATASET	
22-19	2924-2925	*	_	_	
22-20	2926-2933	dataset	_	_	
22-21	2933-2934	.	_	_	

#Text=Note that here we follow the traditional assumption that $\\forall c \\in Y_k, \\mathbb{P}[y = c \\mid x]$ and $r(x) \\propto 1 / \\max_{k \\in Y_k} f(x)_k$, which shows similar performances as those reported in our paper.
#Text=
#Text=
#Text=## Citation
#Text=
#Text=```
#Text=@InProceedings{openauc,
#Text=    title = {OpenAUC: Towards AUC-Oriented Open-Set Recognition},
#Text=    author = {Zitai Wang and  Qianqian Xu and Zhiyong Yang and Yuan He and Xiaochun Cao and Qingming Huang},
#Text=    booktitle = {Annual Conference on Neural Information Processing Systems},
#Text=    year = {2022},
#Text=    pages = {25033--25045}
#Text=}
#Text=```
23-1	2935-2939	Note	_	_	
23-2	2940-2944	that	_	_	
23-3	2945-2949	here	_	_	
23-4	2950-2952	we	_	_	
23-5	2953-2959	follow	_	_	
23-6	2960-2963	the	_	_	
23-7	2964-2975	traditional	_	_	
23-8	2976-2986	assumption	_	_	
23-9	2987-2991	that	_	_	
23-10	2992-2993	$	_	_	
23-11	2993-2994	\	_	_	
23-12	2994-3000	forall	_	_	
23-13	3001-3002	c	_	_	
23-14	3003-3004	\	_	_	
23-15	3004-3006	in	_	_	
23-16	3007-3010	Y_k	_	_	
23-17	3010-3011	,	_	_	
23-18	3012-3013	\	_	_	
23-19	3013-3019	mathbb	_	_	
23-20	3019-3020	{	_	_	
23-21	3020-3021	P	_	_	
23-22	3021-3022	}	_	_	
23-23	3022-3023	[	_	_	
23-24	3023-3024	y	_	_	
23-25	3025-3026	=	_	_	
23-26	3027-3028	c	_	_	
23-27	3029-3030	\	_	_	
23-28	3030-3033	mid	_	_	
23-29	3034-3035	x	_	_	
23-30	3035-3036	]	_	_	
23-31	3036-3037	$	_	_	
23-32	3038-3041	and	_	_	
23-33	3042-3043	$	_	_	
23-34	3043-3044	r	_	_	
23-35	3044-3045	(	_	_	
23-36	3045-3046	x	_	_	
23-37	3046-3047	)	_	_	
23-38	3048-3049	\	_	_	
23-39	3049-3055	propto	_	_	
23-40	3056-3057	1	_	_	
23-41	3058-3059	/	_	_	
23-42	3060-3061	\	_	_	
23-43	3061-3064	max	_	_	
23-44	3064-3065	_	_	_	
23-45	3065-3066	{	_	_	
23-46	3066-3067	k	_	_	
23-47	3068-3069	\	_	_	
23-48	3069-3071	in	_	_	
23-49	3072-3075	Y_k	_	_	
23-50	3075-3076	}	_	_	
23-51	3077-3078	f	_	_	
23-52	3078-3079	(	_	_	
23-53	3079-3080	x	_	_	
23-54	3080-3081	)	_	_	
23-55	3081-3082	_	_	_	
23-56	3082-3083	k	_	_	
23-57	3083-3084	$	_	_	
23-58	3084-3085	,	_	_	
23-59	3086-3091	which	_	_	
23-60	3092-3097	shows	_	_	
23-61	3098-3105	similar	_	_	
23-62	3106-3118	performances	_	_	
23-63	3119-3121	as	_	_	
23-64	3122-3127	those	_	_	
23-65	3128-3136	reported	_	_	
23-66	3137-3139	in	_	_	
23-67	3140-3143	our	_	_	
23-68	3144-3149	paper	_	_	
23-69	3149-3150	.	_	_	
23-70	3153-3154	#	_	_	
23-71	3154-3155	#	_	_	
23-72	3156-3164	Citation	_	_	
23-73	3166-3167	`	_	_	
23-74	3167-3168	`	_	_	
23-75	3168-3169	`	_	_	
23-76	3170-3171	@	_	_	
23-77	3171-3184	InProceedings	_	_	
23-78	3184-3185	{	_	_	
23-79	3185-3192	openauc	_	_	
23-80	3192-3193	,	_	_	
23-81	3198-3203	title	_	_	
23-82	3204-3205	=	_	_	
23-83	3206-3207	{	_	_	
23-84	3207-3214	OpenAUC	*[10]|*[11]	PUBLICATION[10]|EVALMETRIC[11]	
23-85	3214-3215	:	*[10]	PUBLICATION[10]	
23-86	3216-3223	Towards	*[10]	PUBLICATION[10]	
23-87	3224-3236	AUC-Oriented	*[10]	PUBLICATION[10]	
23-88	3237-3245	Open-Set	*[10]	PUBLICATION[10]	
23-89	3246-3257	Recognition	*[10]	PUBLICATION[10]	
23-90	3257-3258	}	_	_	
23-91	3258-3259	,	_	_	
23-92	3264-3270	author	_	_	
23-93	3271-3272	=	_	_	
23-94	3273-3274	{	_	_	
23-95	3274-3279	Zitai	_	_	
23-96	3280-3284	Wang	_	_	
23-97	3285-3288	and	_	_	
23-98	3290-3298	Qianqian	_	_	
23-99	3299-3301	Xu	_	_	
23-100	3302-3305	and	_	_	
23-101	3306-3313	Zhiyong	_	_	
23-102	3314-3318	Yang	_	_	
23-103	3319-3322	and	_	_	
23-104	3323-3327	Yuan	_	_	
23-105	3328-3330	He	_	_	
23-106	3331-3334	and	_	_	
23-107	3335-3343	Xiaochun	_	_	
23-108	3344-3347	Cao	_	_	
23-109	3348-3351	and	_	_	
23-110	3352-3360	Qingming	_	_	
23-111	3361-3366	Huang	_	_	
23-112	3366-3367	}	_	_	
23-113	3367-3368	,	_	_	
23-114	3373-3382	booktitle	_	_	
23-115	3383-3384	=	_	_	
23-116	3385-3386	{	_	_	
23-117	3386-3392	Annual	*[12]	CONFERENCE[12]	
23-118	3393-3403	Conference	*[12]	CONFERENCE[12]	
23-119	3404-3406	on	*[12]	CONFERENCE[12]	
23-120	3407-3413	Neural	*[12]	CONFERENCE[12]	
23-121	3414-3425	Information	*[12]	CONFERENCE[12]	
23-122	3426-3436	Processing	*[12]	CONFERENCE[12]	
23-123	3437-3444	Systems	*[12]	CONFERENCE[12]	
23-124	3444-3445	}	_	_	
23-125	3445-3446	,	_	_	
23-126	3451-3455	year	_	_	
23-127	3456-3457	=	_	_	
23-128	3458-3459	{	_	_	
23-129	3459-3463	2022	_	_	
23-130	3463-3464	}	_	_	
23-131	3464-3465	,	_	_	
23-132	3470-3475	pages	_	_	
23-133	3476-3477	=	_	_	
23-134	3478-3479	{	_	_	
23-135	3479-3484	25033	_	_	
23-136	3484-3485	-	_	_	
23-137	3485-3486	-	_	_	
23-138	3486-3491	25045	_	_	
23-139	3491-3492	}	_	_	
23-140	3493-3494	}	_	_	
23-141	3495-3496	`	_	_	
23-142	3496-3497	`	_	_	
23-143	3497-3498	`	_	_	
