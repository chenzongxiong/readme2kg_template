#FORMAT=WebAnno TSV 3.3
#T_SP=de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity|identifier|value


#Text=# Sparse Coding with Multi-Layer Decoders using Variance Regularization
#Text=This is a PyTorch implementation for the setup described in 
#Text=[Sparse Coding with Multi-Layer Decoders using Variance Regularization](https://arxiv.org/abs/2112.09214). 
#Text=
#Text=### Requirements
#Text=
#Text=- Python 3.7
#Text=- [PyTorch](https://pytorch.org/get-started/previous-versions/) 1.6.0 with torchvision 0.7.0
#Text=- Other dependencies: numpy, tensorboardX
#Text=
#Text=### Datasets
#Text=
#Text=In our experiments, we use:
#Text=- the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset.
1-1	0-1	#	_	_	
1-2	2-8	Sparse	*[1]	PUBLICATION[1]	
1-3	9-15	Coding	*[1]	PUBLICATION[1]	
1-4	16-20	with	*[1]	PUBLICATION[1]	
1-5	21-32	Multi-Layer	*[1]	PUBLICATION[1]	
1-6	33-41	Decoders	*[1]	PUBLICATION[1]	
1-7	42-47	using	*[1]	PUBLICATION[1]	
1-8	48-56	Variance	*[1]	PUBLICATION[1]	
1-9	57-71	Regularization	*[1]	PUBLICATION[1]	
1-10	72-76	This	_	_	
1-11	77-79	is	_	_	
1-12	80-81	a	_	_	
1-13	82-89	PyTorch	*	SOFTWARE	
1-14	90-104	implementation	_	_	
1-15	105-108	for	_	_	
1-16	109-112	the	_	_	
1-17	113-118	setup	_	_	
1-18	119-128	described	_	_	
1-19	129-131	in	_	_	
1-20	133-134	[	_	_	
1-21	134-140	Sparse	*[2]	PUBLICATION[2]	
1-22	141-147	Coding	*[2]	PUBLICATION[2]	
1-23	148-152	with	*[2]	PUBLICATION[2]	
1-24	153-164	Multi-Layer	*[2]	PUBLICATION[2]	
1-25	165-173	Decoders	*[2]	PUBLICATION[2]	
1-26	174-179	using	*[2]	PUBLICATION[2]	
1-27	180-188	Variance	*[2]	PUBLICATION[2]	
1-28	189-203	Regularization	*[2]	PUBLICATION[2]	
1-29	203-204	]	_	_	
1-30	204-205	(	_	_	
1-31	205-210	https	_	_	
1-32	210-211	:	_	_	
1-33	211-212	/	_	_	
1-34	212-213	/	_	_	
1-35	213-222	arxiv.org	_	_	
1-36	222-223	/	_	_	
1-37	223-226	abs	_	_	
1-38	226-227	/	_	_	
1-39	227-237	2112.09214	_	_	
1-40	237-238	)	_	_	
1-41	238-239	.	_	_	
1-42	242-243	#	_	_	
1-43	243-244	#	_	_	
1-44	244-245	#	_	_	
1-45	246-258	Requirements	_	_	
1-46	260-261	-	_	_	
1-47	262-268	Python	*[3]	PROGLANG[3]	
1-48	269-272	3.7	*[3]	PROGLANG[3]	
1-49	273-274	-	_	_	
1-50	275-276	[	_	_	
1-51	276-283	PyTorch	*	SOFTWARE	
1-52	283-284	]	_	_	
1-53	284-285	(	_	_	
1-54	285-290	https	_	_	
1-55	290-291	:	_	_	
1-56	291-292	/	_	_	
1-57	292-293	/	_	_	
1-58	293-304	pytorch.org	_	_	
1-58.1	293-300	pytorch	*	SOFTWARE	
1-59	304-305	/	_	_	
1-60	305-316	get-started	_	_	
1-61	316-317	/	_	_	
1-62	317-334	previous-versions	_	_	
1-63	334-335	/	_	_	
1-64	335-336	)	_	_	
1-65	337-342	1.6.0	_	_	
1-66	343-347	with	_	_	
1-67	348-359	torchvision	*[4]	SOFTWARE[4]	
1-68	360-365	0.7.0	*[4]	SOFTWARE[4]	
1-69	366-367	-	_	_	
1-70	368-373	Other	_	_	
1-71	374-386	dependencies	_	_	
1-72	386-387	:	_	_	
1-73	388-393	numpy	*	SOFTWARE	
1-74	393-394	,	_	_	
1-75	395-407	tensorboardX	*	SOFTWARE	
1-76	409-410	#	_	_	
1-77	410-411	#	_	_	
1-78	411-412	#	_	_	
1-79	413-421	Datasets	_	_	
1-80	423-425	In	_	_	
1-81	426-429	our	_	_	
1-82	430-441	experiments	_	_	
1-83	441-442	,	_	_	
1-84	443-445	we	_	_	
1-85	446-449	use	_	_	
1-86	449-450	:	_	_	
1-87	451-452	-	_	_	
1-88	453-456	the	_	_	
1-89	457-458	[	_	_	
1-90	458-463	MNIST	*	DATASET	
1-91	463-464	]	_	_	
1-92	464-465	(	_	_	
1-93	465-469	http	_	_	
1-94	469-470	:	_	_	
1-95	470-471	/	_	_	
1-96	471-472	/	_	_	
1-97	472-486	yann.lecun.com	_	_	
1-98	486-487	/	_	_	
1-99	487-491	exdb	_	_	
1-100	491-492	/	_	_	
1-101	492-497	mnist	*	DATASET	
1-102	497-498	/	_	_	
1-103	498-499	)	_	_	
1-104	500-507	dataset	_	_	
1-105	507-508	.	_	_	

#Text=We provide the train and validation splits in 
#Text=```data/MNIST_train.npy``` and ```data/MNIST_val.npy```.
#Text=- a custom dataset with 200,000 gray-scale natural image patches of size 28x28 extracted from 
#Text=[ImageNet](https://www.image-net.org/index.php).
2-1	509-511	We	_	_	
2-2	512-519	provide	_	_	
2-3	520-523	the	_	_	
2-4	524-529	train	_	_	
2-5	530-533	and	_	_	
2-6	534-544	validation	_	_	
2-7	545-551	splits	_	_	
2-8	552-554	in	_	_	
2-9	556-557	`	_	_	
2-10	557-558	`	_	_	
2-11	558-559	`	_	_	
2-12	559-563	data	_	_	
2-13	563-564	/	_	_	
2-14	564-579	MNIST_train.npy	_	_	
2-14.1	564-569	MNIST	*	DATASET	
2-15	579-580	`	_	_	
2-16	580-581	`	_	_	
2-17	581-582	`	_	_	
2-18	583-586	and	_	_	
2-19	587-588	`	_	_	
2-20	588-589	`	_	_	
2-21	589-590	`	_	_	
2-22	590-594	data	_	_	
2-23	594-595	/	_	_	
2-24	595-608	MNIST_val.npy	_	_	
2-24.1	595-600	MNIST	*	DATASET	
2-25	608-609	`	_	_	
2-26	609-610	`	_	_	
2-27	610-611	`	_	_	
2-28	611-612	.	_	_	
2-29	613-614	-	_	_	
2-30	615-616	a	_	_	
2-31	617-623	custom	_	_	
2-32	624-631	dataset	_	_	
2-33	632-636	with	_	_	
2-34	637-644	200,000	_	_	
2-35	645-655	gray-scale	_	_	
2-36	656-663	natural	_	_	
2-37	664-669	image	_	_	
2-38	670-677	patches	_	_	
2-39	678-680	of	_	_	
2-40	681-685	size	_	_	
2-41	686-691	28x28	_	_	
2-42	692-701	extracted	_	_	
2-43	702-706	from	_	_	
2-44	708-709	[	_	_	
2-45	709-717	ImageNet	*	DATASET	
2-46	717-718	]	_	_	
2-47	718-719	(	_	_	
2-48	719-724	https	_	_	
2-49	724-725	:	_	_	
2-50	725-726	/	_	_	
2-51	726-727	/	_	_	
2-52	727-744	www.image-net.org	_	_	
2-52.1	731-740	image-net	*	DATASET	
2-53	744-745	/	_	_	
2-54	745-754	index.php	_	_	
2-55	754-755	)	_	_	
2-56	755-756	.	_	_	

#Text=The script to generate it is 
#Text=[build_imagenet_LCN.sh](https://github.com/kevtimova/deep-sparse/blob/main/scripts/build_ImageNet_LCN.sh).
#Text=
#Text=### Training
#Text=
#Text=The scripts below can be used to train sparse autoencoders with our different setups
3-1	757-760	The	_	_	
3-2	761-767	script	_	_	
3-3	768-770	to	_	_	
3-4	771-779	generate	_	_	
3-5	780-782	it	_	_	
3-6	783-785	is	_	_	
3-7	787-788	[	_	_	
3-8	788-809	build_imagenet_LCN.sh	_	_	
3-8.1	794-802	imagenet	*	DATASET	
3-9	809-810	]	_	_	
3-10	810-811	(	_	_	
3-11	811-816	https	_	_	
3-12	816-817	:	_	_	
3-13	817-818	/	_	_	
3-14	818-819	/	_	_	
3-15	819-829	github.com	_	_	
3-16	829-830	/	_	_	
3-17	830-839	kevtimova	_	_	
3-18	839-840	/	_	_	
3-19	840-851	deep-sparse	_	_	
3-20	851-852	/	_	_	
3-21	852-856	blob	_	_	
3-22	856-857	/	_	_	
3-23	857-861	main	_	_	
3-24	861-862	/	_	_	
3-25	862-869	scripts	_	_	
3-26	869-870	/	_	_	
3-27	870-891	build_ImageNet_LCN.sh	_	_	
3-27.1	876-884	ImageNet	*	DATASET	
3-28	891-892	)	_	_	
3-29	892-893	.	_	_	
3-30	895-896	#	_	_	
3-31	896-897	#	_	_	
3-32	897-898	#	_	_	
3-33	899-907	Training	_	_	
3-34	909-912	The	_	_	
3-35	913-920	scripts	_	_	
3-36	921-926	below	_	_	
3-37	927-930	can	_	_	
3-38	931-933	be	_	_	
3-39	934-938	used	_	_	
3-40	939-941	to	_	_	
3-41	942-947	train	_	_	
3-42	948-954	sparse	_	_	
3-43	955-967	autoencoders	_	_	
3-44	968-972	with	_	_	
3-45	973-976	our	_	_	
3-46	977-986	different	_	_	
3-47	987-993	setups	_	_	

#Text=.
4-1	993-994	.	_	_	

#Text=| dataset          | model    | script |
#Text=|------------------|----------|--------|
#Text=| MNIST            | SDL      | [link](https://github.com/kevtimova/deep-sparse/blob/main/scripts/MNIST_SDL.sh)       |
#Text=| MNIST            | SDL-NL   | [link](https://github.com/kevtimova/deep-sparse/blob/main/scripts/MNIST_SDL-NL.sh)       |
#Text=| MNIST            | VDL      | [link](https://github.com/kevtimova/deep-sparse/blob/main/scripts/MNIST_VDL.sh)       |
#Text=| MNIST            | VDL-NL   | [link](https://github.com/kevtimova/deep-sparse/blob/main/scripts/MNIST_VDL-NL.sh)       |
#Text=| ImageNet_patches | SDL      | [link](https://github.com/kevtimova/deep-sparse/blob/main/scripts/ImageNet_SDL.sh)       |
#Text=| ImageNet_patches | SDL-NL   | [link](https://github.com/kevtimova/deep-sparse/blob/main/scripts/ImageNet_SDL-NL.sh)       |
#Text=| ImageNet_patches | VDL      | [link](https://github.com/kevtimova/deep-sparse/blob/main/scripts/ImageNet_VDL.sh)       |
#Text=| Imagenet_patches | VDL-NL   | [link](https://github.com/kevtimova/deep-sparse/blob/main/scripts/ImageNet_VDL-NL.sh)       |
#Text=
#Text=### Evaluation
#Text=
#Text=We evaluate our pre-trained sparse autoencoders on the downstream tasks of denoising (for MNIST and our custom 
#Text=ImageNet patches dataset) and classification in the low-data regime (for MNIST only).
#Text=
#Text=#### Denoising
#Text=
#Text=The denoising perfomance on the test set can be measured at the end of training by providing a list with levels of 
#Text=random noise (measured by std of Gaussian noise; the noise is added to the input images) in the ```noise``` argument 
#Text=in ```main.py```.
5-1	996-997	|	_	_	
5-2	998-1005	dataset	_	_	
5-3	1015-1016	|	_	_	
5-4	1017-1022	model	_	_	
5-5	1026-1027	|	_	_	
5-6	1028-1034	script	_	_	
5-7	1035-1036	|	_	_	
5-8	1037-1038	|	_	_	
5-9	1038-1039	-	_	_	
5-10	1039-1040	-	_	_	
5-11	1040-1041	-	_	_	
5-12	1041-1042	-	_	_	
5-13	1042-1043	-	_	_	
5-14	1043-1044	-	_	_	
5-15	1044-1045	-	_	_	
5-16	1045-1046	-	_	_	
5-17	1046-1047	-	_	_	
5-18	1047-1048	-	_	_	
5-19	1048-1049	-	_	_	
5-20	1049-1050	-	_	_	
5-21	1050-1051	-	_	_	
5-22	1051-1052	-	_	_	
5-23	1052-1053	-	_	_	
5-24	1053-1054	-	_	_	
5-25	1054-1055	-	_	_	
5-26	1055-1056	-	_	_	
5-27	1056-1057	|	_	_	
5-28	1057-1058	-	_	_	
5-29	1058-1059	-	_	_	
5-30	1059-1060	-	_	_	
5-31	1060-1061	-	_	_	
5-32	1061-1062	-	_	_	
5-33	1062-1063	-	_	_	
5-34	1063-1064	-	_	_	
5-35	1064-1065	-	_	_	
5-36	1065-1066	-	_	_	
5-37	1066-1067	-	_	_	
5-38	1067-1068	|	_	_	
5-39	1068-1069	-	_	_	
5-40	1069-1070	-	_	_	
5-41	1070-1071	-	_	_	
5-42	1071-1072	-	_	_	
5-43	1072-1073	-	_	_	
5-44	1073-1074	-	_	_	
5-45	1074-1075	-	_	_	
5-46	1075-1076	-	_	_	
5-47	1076-1077	|	_	_	
5-48	1078-1079	|	_	_	
5-49	1080-1085	MNIST	*	DATASET	
5-50	1097-1098	|	_	_	
5-51	1099-1102	SDL	*	SOFTWARE	
5-52	1108-1109	|	_	_	
5-53	1110-1111	[	_	_	
5-54	1111-1115	link	_	_	
5-55	1115-1116	]	_	_	
5-56	1116-1117	(	_	_	
5-57	1117-1122	https	_	_	
5-58	1122-1123	:	_	_	
5-59	1123-1124	/	_	_	
5-60	1124-1125	/	_	_	
5-61	1125-1135	github.com	_	_	
5-62	1135-1136	/	_	_	
5-63	1136-1145	kevtimova	_	_	
5-64	1145-1146	/	_	_	
5-65	1146-1157	deep-sparse	_	_	
5-66	1157-1158	/	_	_	
5-67	1158-1162	blob	_	_	
5-68	1162-1163	/	_	_	
5-69	1163-1167	main	_	_	
5-70	1167-1168	/	_	_	
5-71	1168-1175	scripts	_	_	
5-72	1175-1176	/	_	_	
5-73	1176-1188	MNIST_SDL.sh	_	_	
5-73.1	1176-1181	MNIST	*	DATASET	
5-74	1188-1189	)	_	_	
5-75	1196-1197	|	_	_	
5-76	1198-1199	|	_	_	
5-77	1200-1205	MNIST	*	DATASET	
5-78	1217-1218	|	_	_	
5-79	1219-1225	SDL-NL	*	SOFTWARE	
5-80	1228-1229	|	_	_	
5-81	1230-1231	[	_	_	
5-82	1231-1235	link	_	_	
5-83	1235-1236	]	_	_	
5-84	1236-1237	(	_	_	
5-85	1237-1242	https	_	_	
5-86	1242-1243	:	_	_	
5-87	1243-1244	/	_	_	
5-88	1244-1245	/	_	_	
5-89	1245-1255	github.com	_	_	
5-90	1255-1256	/	_	_	
5-91	1256-1265	kevtimova	_	_	
5-92	1265-1266	/	_	_	
5-93	1266-1277	deep-sparse	_	_	
5-94	1277-1278	/	_	_	
5-95	1278-1282	blob	_	_	
5-96	1282-1283	/	_	_	
5-97	1283-1287	main	_	_	
5-98	1287-1288	/	_	_	
5-99	1288-1295	scripts	_	_	
5-100	1295-1296	/	_	_	
5-101	1296-1311	MNIST_SDL-NL.sh	_	_	
5-102	1311-1312	)	_	_	
5-103	1319-1320	|	_	_	
5-104	1321-1322	|	_	_	
5-105	1323-1328	MNIST	*	DATASET	
5-106	1340-1341	|	_	_	
5-107	1342-1345	VDL	*	SOFTWARE	
5-108	1351-1352	|	_	_	
5-109	1353-1354	[	_	_	
5-110	1354-1358	link	_	_	
5-111	1358-1359	]	_	_	
5-112	1359-1360	(	_	_	
5-113	1360-1365	https	_	_	
5-114	1365-1366	:	_	_	
5-115	1366-1367	/	_	_	
5-116	1367-1368	/	_	_	
5-117	1368-1378	github.com	_	_	
5-118	1378-1379	/	_	_	
5-119	1379-1388	kevtimova	_	_	
5-120	1388-1389	/	_	_	
5-121	1389-1400	deep-sparse	_	_	
5-122	1400-1401	/	_	_	
5-123	1401-1405	blob	_	_	
5-124	1405-1406	/	_	_	
5-125	1406-1410	main	_	_	
5-126	1410-1411	/	_	_	
5-127	1411-1418	scripts	_	_	
5-128	1418-1419	/	_	_	
5-129	1419-1431	MNIST_VDL.sh	_	_	
5-129.1	1419-1424	MNIST	*	DATASET	
5-130	1431-1432	)	_	_	
5-131	1439-1440	|	_	_	
5-132	1441-1442	|	_	_	
5-133	1443-1448	MNIST	*	DATASET	
5-134	1460-1461	|	_	_	
5-135	1462-1468	VDL-NL	*	SOFTWARE	
5-136	1471-1472	|	_	_	
5-137	1473-1474	[	_	_	
5-138	1474-1478	link	_	_	
5-139	1478-1479	]	_	_	
5-140	1479-1480	(	_	_	
5-141	1480-1485	https	_	_	
5-142	1485-1486	:	_	_	
5-143	1486-1487	/	_	_	
5-144	1487-1488	/	_	_	
5-145	1488-1498	github.com	_	_	
5-146	1498-1499	/	_	_	
5-147	1499-1508	kevtimova	_	_	
5-148	1508-1509	/	_	_	
5-149	1509-1520	deep-sparse	_	_	
5-150	1520-1521	/	_	_	
5-151	1521-1525	blob	_	_	
5-152	1525-1526	/	_	_	
5-153	1526-1530	main	_	_	
5-154	1530-1531	/	_	_	
5-155	1531-1538	scripts	_	_	
5-156	1538-1539	/	_	_	
5-157	1539-1554	MNIST_VDL-NL.sh	_	_	
5-157.1	1539-1544	MNIST	*	DATASET	
5-158	1554-1555	)	_	_	
5-159	1562-1563	|	_	_	
5-160	1564-1565	|	_	_	
5-161	1566-1582	ImageNet_patches	*	DATASET	
5-162	1583-1584	|	_	_	
5-163	1585-1588	SDL	_	_	
5-164	1594-1595	|	_	_	
5-165	1596-1597	[	_	_	
5-166	1597-1601	link	_	_	
5-167	1601-1602	]	_	_	
5-168	1602-1603	(	_	_	
5-169	1603-1608	https	_	_	
5-170	1608-1609	:	_	_	
5-171	1609-1610	/	_	_	
5-172	1610-1611	/	_	_	
5-173	1611-1621	github.com	_	_	
5-174	1621-1622	/	_	_	
5-175	1622-1631	kevtimova	_	_	
5-176	1631-1632	/	_	_	
5-177	1632-1643	deep-sparse	_	_	
5-178	1643-1644	/	_	_	
5-179	1644-1648	blob	_	_	
5-180	1648-1649	/	_	_	
5-181	1649-1653	main	_	_	
5-182	1653-1654	/	_	_	
5-183	1654-1661	scripts	_	_	
5-184	1661-1662	/	_	_	
5-185	1662-1677	ImageNet_SDL.sh	_	_	
5-185.1	1662-1670	ImageNet	*	DATASET	
5-186	1677-1678	)	_	_	
5-187	1685-1686	|	_	_	
5-188	1687-1688	|	_	_	
5-189	1689-1705	ImageNet_patches	*	DATASET	
5-190	1706-1707	|	_	_	
5-191	1708-1714	SDL-NL	*	SOFTWARE	
5-192	1717-1718	|	_	_	
5-193	1719-1720	[	_	_	
5-194	1720-1724	link	_	_	
5-195	1724-1725	]	_	_	
5-196	1725-1726	(	_	_	
5-197	1726-1731	https	_	_	
5-198	1731-1732	:	_	_	
5-199	1732-1733	/	_	_	
5-200	1733-1734	/	_	_	
5-201	1734-1744	github.com	_	_	
5-202	1744-1745	/	_	_	
5-203	1745-1754	kevtimova	_	_	
5-204	1754-1755	/	_	_	
5-205	1755-1766	deep-sparse	_	_	
5-206	1766-1767	/	_	_	
5-207	1767-1771	blob	_	_	
5-208	1771-1772	/	_	_	
5-209	1772-1776	main	_	_	
5-210	1776-1777	/	_	_	
5-211	1777-1784	scripts	_	_	
5-212	1784-1785	/	_	_	
5-213	1785-1803	ImageNet_SDL-NL.sh	_	_	
5-213.1	1785-1793	ImageNet	*	DATASET	
5-214	1803-1804	)	_	_	
5-215	1811-1812	|	_	_	
5-216	1813-1814	|	_	_	
5-217	1815-1831	ImageNet_patches	*	DATASET	
5-218	1832-1833	|	_	_	
5-219	1834-1837	VDL	*	SOFTWARE	
5-220	1843-1844	|	_	_	
5-221	1845-1846	[	_	_	
5-222	1846-1850	link	_	_	
5-223	1850-1851	]	_	_	
5-224	1851-1852	(	_	_	
5-225	1852-1857	https	_	_	
5-226	1857-1858	:	_	_	
5-227	1858-1859	/	_	_	
5-228	1859-1860	/	_	_	
5-229	1860-1870	github.com	_	_	
5-230	1870-1871	/	_	_	
5-231	1871-1880	kevtimova	_	_	
5-232	1880-1881	/	_	_	
5-233	1881-1892	deep-sparse	_	_	
5-234	1892-1893	/	_	_	
5-235	1893-1897	blob	_	_	
5-236	1897-1898	/	_	_	
5-237	1898-1902	main	_	_	
5-238	1902-1903	/	_	_	
5-239	1903-1910	scripts	_	_	
5-240	1910-1911	/	_	_	
5-241	1911-1926	ImageNet_VDL.sh	_	_	
5-241.1	1911-1919	ImageNet	*	DATASET	
5-242	1926-1927	)	_	_	
5-243	1934-1935	|	_	_	
5-244	1936-1937	|	_	_	
5-245	1938-1954	Imagenet_patches	*	DATASET	
5-246	1955-1956	|	_	_	
5-247	1957-1963	VDL-NL	*	SOFTWARE	
5-248	1966-1967	|	_	_	
5-249	1968-1969	[	_	_	
5-250	1969-1973	link	_	_	
5-251	1973-1974	]	_	_	
5-252	1974-1975	(	_	_	
5-253	1975-1980	https	_	_	
5-254	1980-1981	:	_	_	
5-255	1981-1982	/	_	_	
5-256	1982-1983	/	_	_	
5-257	1983-1993	github.com	_	_	
5-258	1993-1994	/	_	_	
5-259	1994-2003	kevtimova	_	_	
5-260	2003-2004	/	_	_	
5-261	2004-2015	deep-sparse	_	_	
5-262	2015-2016	/	_	_	
5-263	2016-2020	blob	_	_	
5-264	2020-2021	/	_	_	
5-265	2021-2025	main	_	_	
5-266	2025-2026	/	_	_	
5-267	2026-2033	scripts	_	_	
5-268	2033-2034	/	_	_	
5-269	2034-2052	ImageNet_VDL-NL.sh	_	_	
5-269.1	2034-2042	ImageNet	*	DATASET	
5-270	2052-2053	)	_	_	
5-271	2060-2061	|	_	_	
5-272	2063-2064	#	_	_	
5-273	2064-2065	#	_	_	
5-274	2065-2066	#	_	_	
5-275	2067-2077	Evaluation	_	_	
5-276	2079-2081	We	_	_	
5-277	2082-2090	evaluate	_	_	
5-278	2091-2094	our	_	_	
5-279	2095-2106	pre-trained	_	_	
5-280	2107-2113	sparse	_	_	
5-281	2114-2126	autoencoders	_	_	
5-282	2127-2129	on	_	_	
5-283	2130-2133	the	_	_	
5-284	2134-2144	downstream	_	_	
5-285	2145-2150	tasks	_	_	
5-286	2151-2153	of	_	_	
5-287	2154-2163	denoising	_	_	
5-288	2164-2165	(	_	_	
5-289	2165-2168	for	_	_	
5-290	2169-2174	MNIST	*	DATASET	
5-291	2175-2178	and	_	_	
5-292	2179-2182	our	_	_	
5-293	2183-2189	custom	_	_	
5-294	2191-2199	ImageNet	*	DATASET	
5-295	2200-2207	patches	_	_	
5-296	2208-2215	dataset	_	_	
5-297	2215-2216	)	_	_	
5-298	2217-2220	and	_	_	
5-299	2221-2235	classification	_	_	
5-300	2236-2238	in	_	_	
5-301	2239-2242	the	_	_	
5-302	2243-2251	low-data	_	_	
5-303	2252-2258	regime	_	_	
5-304	2259-2260	(	_	_	
5-305	2260-2263	for	_	_	
5-306	2264-2269	MNIST	*	DATASET	
5-307	2270-2274	only	_	_	
5-308	2274-2275	)	_	_	
5-309	2275-2276	.	_	_	
5-310	2278-2279	#	_	_	
5-311	2279-2280	#	_	_	
5-312	2280-2281	#	_	_	
5-313	2281-2282	#	_	_	
5-314	2283-2292	Denoising	_	_	
5-315	2294-2297	The	_	_	
5-316	2298-2307	denoising	_	_	
5-317	2308-2318	perfomance	_	_	
5-318	2319-2321	on	_	_	
5-319	2322-2325	the	_	_	
5-320	2326-2330	test	_	_	
5-321	2331-2334	set	_	_	
5-322	2335-2338	can	_	_	
5-323	2339-2341	be	_	_	
5-324	2342-2350	measured	_	_	
5-325	2351-2353	at	_	_	
5-326	2354-2357	the	_	_	
5-327	2358-2361	end	_	_	
5-328	2362-2364	of	_	_	
5-329	2365-2373	training	_	_	
5-330	2374-2376	by	_	_	
5-331	2377-2386	providing	_	_	
5-332	2387-2388	a	_	_	
5-333	2389-2393	list	_	_	
5-334	2394-2398	with	_	_	
5-335	2399-2405	levels	_	_	
5-336	2406-2408	of	_	_	
5-337	2410-2416	random	_	_	
5-338	2417-2422	noise	_	_	
5-339	2423-2424	(	_	_	
5-340	2424-2432	measured	_	_	
5-341	2433-2435	by	_	_	
5-342	2436-2439	std	_	_	
5-343	2440-2442	of	_	_	
5-344	2443-2451	Gaussian	_	_	
5-345	2452-2457	noise	_	_	
5-346	2457-2458	;	_	_	
5-347	2459-2462	the	_	_	
5-348	2463-2468	noise	_	_	
5-349	2469-2471	is	_	_	
5-350	2472-2477	added	_	_	
5-351	2478-2480	to	_	_	
5-352	2481-2484	the	_	_	
5-353	2485-2490	input	_	_	
5-354	2491-2497	images	_	_	
5-355	2497-2498	)	_	_	
5-356	2499-2501	in	_	_	
5-357	2502-2505	the	_	_	
5-358	2506-2507	`	_	_	
5-359	2507-2508	`	_	_	
5-360	2508-2509	`	_	_	
5-361	2509-2514	noise	_	_	
5-362	2514-2515	`	_	_	
5-363	2515-2516	`	_	_	
5-364	2516-2517	`	_	_	
5-365	2518-2526	argument	_	_	
5-366	2528-2530	in	_	_	
5-367	2531-2532	`	_	_	
5-368	2532-2533	`	_	_	
5-369	2533-2534	`	_	_	
5-370	2534-2541	main.py	_	_	
5-371	2541-2542	`	_	_	
5-372	2542-2543	`	_	_	
5-373	2543-2544	`	_	_	
5-374	2544-2545	.	_	_	

#Text=Alternatively, ```eval_denoising.py``` can be used given a pre-trained autoencoder.
#Text=
#Text=#### Classification
#Text=
#Text=To evaluate the linear separability of codes obtained from the sparse autoencoders, we provide the steps below.
6-1	2547-2560	Alternatively	_	_	
6-2	2560-2561	,	_	_	
6-3	2562-2563	`	_	_	
6-4	2563-2564	`	_	_	
6-5	2564-2565	`	_	_	
6-6	2565-2582	eval_denoising.py	_	_	
6-7	2582-2583	`	_	_	
6-8	2583-2584	`	_	_	
6-9	2584-2585	`	_	_	
6-10	2586-2589	can	_	_	
6-11	2590-2592	be	_	_	
6-12	2593-2597	used	_	_	
6-13	2598-2603	given	_	_	
6-14	2604-2605	a	_	_	
6-15	2606-2617	pre-trained	_	_	
6-16	2618-2629	autoencoder	_	_	
6-17	2629-2630	.	_	_	
6-18	2632-2633	#	_	_	
6-19	2633-2634	#	_	_	
6-20	2634-2635	#	_	_	
6-21	2635-2636	#	_	_	
6-22	2637-2651	Classification	_	_	
6-23	2653-2655	To	_	_	
6-24	2656-2664	evaluate	_	_	
6-25	2665-2668	the	_	_	
6-26	2669-2675	linear	_	_	
6-27	2676-2688	separability	_	_	
6-28	2689-2691	of	_	_	
6-29	2692-2697	codes	_	_	
6-30	2698-2706	obtained	_	_	
6-31	2707-2711	from	_	_	
6-32	2712-2715	the	_	_	
6-33	2716-2722	sparse	_	_	
6-34	2723-2735	autoencoders	_	_	
6-35	2735-2736	,	_	_	
6-36	2737-2739	we	_	_	
6-37	2740-2747	provide	_	_	
6-38	2748-2751	the	_	_	
6-39	2752-2757	steps	_	_	
6-40	2758-2763	below	_	_	
6-41	2763-2764	.	_	_	

#Text=Step 1: Given a pre-trained encoder, ```compute_codes.py``` can be used to create a dataset containing the codes 
#Text=for each MNIST image.
7-1	2766-2770	Step	_	_	
7-2	2771-2772	1	_	_	
7-3	2772-2773	:	_	_	
7-4	2774-2779	Given	_	_	
7-5	2780-2781	a	_	_	
7-6	2782-2793	pre-trained	_	_	
7-7	2794-2801	encoder	_	_	
7-8	2801-2802	,	_	_	
7-9	2803-2804	`	_	_	
7-10	2804-2805	`	_	_	
7-11	2805-2806	`	_	_	
7-12	2806-2822	compute_codes.py	_	_	
7-13	2822-2823	`	_	_	
7-14	2823-2824	`	_	_	
7-15	2824-2825	`	_	_	
7-16	2826-2829	can	_	_	
7-17	2830-2832	be	_	_	
7-18	2833-2837	used	_	_	
7-19	2838-2840	to	_	_	
7-20	2841-2847	create	_	_	
7-21	2848-2849	a	_	_	
7-22	2850-2857	dataset	_	_	
7-23	2858-2868	containing	_	_	
7-24	2869-2872	the	_	_	
7-25	2873-2878	codes	_	_	
7-26	2880-2883	for	_	_	
7-27	2884-2888	each	_	_	
7-28	2889-2894	MNIST	*	DATASET	
7-29	2895-2900	image	_	_	
7-30	2900-2901	.	_	_	

#Text=Step 2: Using the dataset from the previous step, ```eval_classification.py``` can be used to measure classification 
#Text=performance with a set number of training samples per class.
8-1	2903-2907	Step	_	_	
8-2	2908-2909	2	_	_	
8-3	2909-2910	:	_	_	
8-4	2911-2916	Using	_	_	
8-5	2917-2920	the	_	_	
8-6	2921-2928	dataset	_	_	
8-7	2929-2933	from	_	_	
8-8	2934-2937	the	_	_	
8-9	2938-2946	previous	_	_	
8-10	2947-2951	step	_	_	
8-11	2951-2952	,	_	_	
8-12	2953-2954	`	_	_	
8-13	2954-2955	`	_	_	
8-14	2955-2956	`	_	_	
8-15	2956-2978	eval_classification.py	_	_	
8-16	2978-2979	`	_	_	
8-17	2979-2980	`	_	_	
8-18	2980-2981	`	_	_	
8-19	2982-2985	can	_	_	
8-20	2986-2988	be	_	_	
8-21	2989-2993	used	_	_	
8-22	2994-2996	to	_	_	
8-23	2997-3004	measure	_	_	
8-24	3005-3019	classification	_	_	
8-25	3021-3032	performance	_	_	
8-26	3033-3037	with	_	_	
8-27	3038-3039	a	_	_	
8-28	3040-3043	set	_	_	
8-29	3044-3050	number	_	_	
8-30	3051-3053	of	_	_	
8-31	3054-3062	training	_	_	
8-32	3063-3070	samples	_	_	
8-33	3071-3074	per	_	_	
8-34	3075-3080	class	_	_	
8-35	3080-3081	.	_	_	

#Text=There are two options for the classifier - a linear classifier
#Text=(located in ```modles/linear_classifier.py```) and a classifier which uses a randomly initialized LISTA encoder module 
#Text=followed by a linear classification layer (located in ```modles/lista_classifier.py```).
9-1	3083-3088	There	_	_	
9-2	3089-3092	are	_	_	
9-3	3093-3096	two	_	_	
9-4	3097-3104	options	_	_	
9-5	3105-3108	for	_	_	
9-6	3109-3112	the	_	_	
9-7	3113-3123	classifier	_	_	
9-8	3124-3125	-	_	_	
9-9	3126-3127	a	_	_	
9-10	3128-3134	linear	_	_	
9-11	3135-3145	classifier	_	_	
9-12	3146-3147	(	_	_	
9-13	3147-3154	located	_	_	
9-14	3155-3157	in	_	_	
9-15	3158-3159	`	_	_	
9-16	3159-3160	`	_	_	
9-17	3160-3161	`	_	_	
9-18	3161-3167	modles	_	_	
9-19	3167-3168	/	_	_	
9-20	3168-3188	linear_classifier.py	_	_	
9-21	3188-3189	`	_	_	
9-22	3189-3190	`	_	_	
9-23	3190-3191	`	_	_	
9-24	3191-3192	)	_	_	
9-25	3193-3196	and	_	_	
9-26	3197-3198	a	_	_	
9-27	3199-3209	classifier	_	_	
9-28	3210-3215	which	_	_	
9-29	3216-3220	uses	_	_	
9-30	3221-3222	a	_	_	
9-31	3223-3231	randomly	_	_	
9-32	3232-3243	initialized	_	_	
9-33	3244-3249	LISTA	_	_	
9-34	3250-3257	encoder	_	_	
9-35	3258-3264	module	_	_	
9-36	3266-3274	followed	_	_	
9-37	3275-3277	by	_	_	
9-38	3278-3279	a	_	_	
9-39	3280-3286	linear	_	_	
9-40	3287-3301	classification	_	_	
9-41	3302-3307	layer	_	_	
9-42	3308-3309	(	_	_	
9-43	3309-3316	located	_	_	
9-44	3317-3319	in	_	_	
9-45	3320-3321	`	_	_	
9-46	3321-3322	`	_	_	
9-47	3322-3323	`	_	_	
9-48	3323-3329	modles	_	_	
9-49	3329-3330	/	_	_	
9-50	3330-3349	lista_classifier.py	_	_	
9-51	3349-3350	`	_	_	
9-52	3350-3351	`	_	_	
9-53	3351-3352	`	_	_	
9-54	3352-3353	)	_	_	
9-55	3353-3354	.	_	_	
