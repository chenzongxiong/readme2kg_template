#FORMAT=WebAnno TSV 3.3
#T_SP=de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity|identifier|value


#Text=# Scaffolding Learning Regime (SLR)  \[!
1-1	0-1	#	_	_
1-2	2-13	Scaffolding	_	_
1-3	14-22	Learning	_	_
1-4	23-29	Regime	_	_
1-5	30-31	(	_	_
1-6	31-34	SLR	_	_
1-7	34-35	)	_	_
1-8	37-38	\[	_	_
1-9	38-39	!	_	_

#Text=\[paper\](https://img.shields.io/badge/paper-52b69a?
2-1	39-40	\[	_	_
2-2	40-45	paper	_	_
2-3	45-46	\]	_	_
2-4	46-47	(	_	_
2-5	47-52	https	_	_
2-6	52-53	:	_	_
2-7	53-54	/	_	_
2-8	54-55	/	_	_
2-9	55-69	img.shields.io	_	_
2-10	69-70	/	_	_
2-11	70-75	badge	_	_
2-12	75-76	/	_	_
2-13	76-81	paper	_	_
2-14	81-82	-	_	_
2-15	82-88	52b69a	_	_
2-16	88-89	?	_	_

#Text=style=for-the-badge&logo=arxiv&logoColor=white)\](https://arxiv.org/abs/2206.13263) \[!
3-1	89-94	style	_	_
3-2	94-95	=	_	_
3-3	95-108	for-the-badge	_	_
3-4	108-109	&	_	_
3-5	109-113	logo	_	_
3-6	113-114	=	_	_
3-7	114-119	arxiv	_	_
3-8	119-120	&	_	_
3-9	120-129	logoColor	_	_
3-10	129-130	=	_	_
3-11	130-135	white	_	_
3-12	135-136	)	_	_
3-13	136-137	\]	_	_
3-14	137-138	(	_	_
3-15	138-143	https	_	_
3-16	143-144	:	_	_
3-17	144-145	/	_	_
3-18	145-146	/	_	_
3-19	146-155	arxiv.org	_	_
3-20	155-156	/	_	_
3-21	156-159	abs	_	_
3-22	159-160	/	_	_
3-23	160-170	2206.13263	_	_
3-24	170-171	)	_	_
3-25	172-173	\[	_	_
3-26	173-174	!	_	_

#Text=\[weights\](https://img.shields.io/badge/weights-34a0a4?
4-1	174-175	\[	_	_
4-2	175-182	weights	_	_
4-3	182-183	\]	_	_
4-4	183-184	(	_	_
4-5	184-189	https	_	_
4-6	189-190	:	_	_
4-7	190-191	/	_	_
4-8	191-192	/	_	_
4-9	192-206	img.shields.io	_	_
4-10	206-207	/	_	_
4-11	207-212	badge	_	_
4-12	212-213	/	_	_
4-13	213-220	weights	_	_
4-14	220-221	-	_	_
4-15	221-227	34a0a4	_	_
4-16	227-228	?	_	_

#Text=style=for-the-badge&logo=DocuSign&logoColor=white)\](#pretrained-models) \[!
5-1	228-233	style	_	_
5-2	233-234	=	_	_
5-3	234-247	for-the-badge	_	_
5-4	247-248	&	_	_
5-5	248-252	logo	_	_
5-6	252-253	=	_	_
5-7	253-261	DocuSign	_	_
5-8	261-262	&	_	_
5-9	262-271	logoColor	_	_
5-10	271-272	=	_	_
5-11	272-277	white	_	_
5-12	277-278	)	_	_
5-13	278-279	\]	_	_
5-14	279-280	(	_	_
5-15	280-281	#	_	_
5-16	281-298	pretrained-models	_	_
5-17	298-299	)	_	_
5-18	300-301	\[	_	_
5-19	301-302	!	_	_

#Text=\[presentation\](https://img.shields.io/badge/presentation-168aad?
6-1	302-303	\[	_	_
6-2	303-315	presentation	_	_
6-3	315-316	\]	_	_
6-4	316-317	(	_	_
6-5	317-322	https	_	_
6-6	322-323	:	_	_
6-7	323-324	/	_	_
6-8	324-325	/	_	_
6-9	325-339	img.shields.io	_	_
6-10	339-340	/	_	_
6-11	340-345	badge	_	_
6-12	345-346	/	_	_
6-13	346-358	presentation	_	_
6-14	358-359	-	_	_
6-15	359-365	168aad	_	_
6-16	365-366	?	_	_

#Text=style=for-the-badge&logo=youtube&logoColor=white)\](https://www.youtube.com/watch?
7-1	366-371	style	_	_
7-2	371-372	=	_	_
7-3	372-385	for-the-badge	_	_
7-4	385-386	&	_	_
7-5	386-390	logo	_	_
7-6	390-391	=	_	_
7-7	391-398	youtube	_	_
7-8	398-399	&	_	_
7-9	399-408	logoColor	_	_
7-10	408-409	=	_	_
7-11	409-414	white	_	_
7-12	414-415	)	_	_
7-13	415-416	\]	_	_
7-14	416-417	(	_	_
7-15	417-422	https	_	_
7-16	422-423	:	_	_
7-17	423-424	/	_	_
7-18	424-425	/	_	_
7-19	425-440	www.youtube.com	_	_
7-20	440-441	/	_	_
7-21	441-446	watch	_	_
7-22	446-447	?	_	_

#Text=v=F4sLbbMsoHw) \[!
8-1	447-448	v	_	_
8-2	448-449	=	_	_
8-3	449-460	F4sLbbMsoHw	_	_
8-4	460-461	)	_	_
8-5	462-463	\[	_	_
8-6	463-464	!	_	_

#Text=\[cite\](https://img.shields.io/badge/bibtex-1a759f?
9-1	464-465	\[	_	_
9-2	465-469	cite	_	_
9-3	469-470	\]	_	_
9-4	470-471	(	_	_
9-5	471-476	https	_	_
9-6	476-477	:	_	_
9-7	477-478	/	_	_
9-8	478-479	/	_	_
9-9	479-493	img.shields.io	_	_
9-10	493-494	/	_	_
9-11	494-499	badge	_	_
9-12	499-500	/	_	_
9-13	500-506	bibtex	_	_
9-14	506-507	-	_	_
9-15	507-513	1a759f	_	_
9-16	513-514	?	_	_

#Text=style=for-the-badge&logo=overleaf&logoColor=white)\](#cite)   A PyTorch implementation of the Scaffolding Learning Regime (SLR) for training obstacle detection models for aquatic domains.
10-1	514-519	style	_	_
10-2	519-520	=	_	_
10-3	520-533	for-the-badge	_	_
10-4	533-534	&	_	_
10-5	534-538	logo	_	_
10-6	538-539	=	_	_
10-7	539-547	overleaf	_	_
10-8	547-548	&	_	_
10-9	548-557	logoColor	_	_
10-10	557-558	=	_	_
10-11	558-563	white	_	_
10-12	563-564	)	_	_
10-13	564-565	\]	_	_
10-14	565-566	(	_	_
10-15	566-567	#	_	_
10-16	567-571	cite	_	_
10-17	571-572	)	_	_
10-18	575-576	A	_	_
10-19	577-584	PyTorch	_	_
10-20	585-599	implementation	_	_
10-21	600-602	of	_	_
10-22	603-606	the	_	_
10-23	607-618	Scaffolding	_	_
10-24	619-627	Learning	_	_
10-25	628-634	Regime	_	_
10-26	635-636	(	_	_
10-27	636-639	SLR	_	_
10-28	639-640	)	_	_
10-29	641-644	for	_	_
10-30	645-653	training	_	_
10-31	654-662	obstacle	_	_
10-32	663-672	detection	_	_
10-33	673-679	models	_	_
10-34	680-683	for	_	_
10-35	684-691	aquatic	_	_
10-36	692-699	domains	_	_
10-37	699-700	.	_	_

#Text=<p align="center">     <img src="resources/annotations.png" alt="SLR annotations" width="400px"> </p>  \*\*November 2022\*\*: Published in Sensors.
11-1	703-704	<	_	_
11-2	704-705	p	_	_
11-3	706-711	align	_	_
11-4	711-712	=	_	_
11-5	712-713	"	_	_
11-6	713-719	center	_	_
11-7	719-720	"	_	_
11-8	720-721	>	_	_
11-9	726-727	<	_	_
11-10	727-730	img	_	_
11-11	731-734	src	_	_
11-12	734-735	=	_	_
11-13	735-736	"	_	_
11-14	736-745	resources	_	_
11-15	745-746	/	_	_
11-16	746-761	annotations.png	_	_
11-17	761-762	"	_	_
11-18	763-766	alt	_	_
11-19	766-767	=	_	_
11-20	767-768	"	_	_
11-21	768-771	SLR	_	_
11-22	772-783	annotations	_	_
11-23	783-784	"	_	_
11-24	785-790	width	_	_
11-25	790-791	=	_	_
11-26	791-792	"	_	_
11-27	792-797	400px	_	_
11-28	797-798	"	_	_
11-29	798-799	>	_	_
11-30	800-801	<	_	_
11-31	801-802	/	_	_
11-32	802-803	p	_	_
11-33	803-804	>	_	_
11-34	806-807	\*	_	_
11-35	807-808	\*	_	_
11-36	808-816	November	_	_
11-37	817-821	2022	_	_
11-38	821-822	\*	_	_
11-39	822-823	\*	_	_
11-40	823-824	:	_	_
11-41	825-834	Published	_	_
11-42	835-837	in	_	_
11-43	838-845	Sensors	_	_
11-44	845-846	.	_	_

#Text=\*\*January 2022\*\*: Preliminary version presented at WACV 2022.  ## About SLR  Scaffolding Learning Regime (SLR) is a method for training semantic segmentation models for maritime obstacle detection using only weak annotations (obstacle bounding boxes and water-edge poly-line).
12-1	849-850	\*	_	_
12-2	850-851	\*	_	_
12-3	851-858	January	_	_
12-4	859-863	2022	_	_
12-5	863-864	\*	_	_
12-6	864-865	\*	_	_
12-7	865-866	:	_	_
12-8	867-878	Preliminary	_	_
12-9	879-886	version	_	_
12-10	887-896	presented	_	_
12-11	897-899	at	_	_
12-12	900-904	WACV	_	_
12-13	905-909	2022	_	_
12-14	909-910	.	_	_
12-15	912-913	#	_	_
12-16	913-914	#	_	_
12-17	915-920	About	_	_
12-18	921-924	SLR	_	_
12-19	926-937	Scaffolding	_	_
12-20	938-946	Learning	_	_
12-21	947-953	Regime	_	_
12-22	954-955	(	_	_
12-23	955-958	SLR	_	_
12-24	958-959	)	_	_
12-25	960-962	is	_	_
12-26	963-964	a	_	_
12-27	965-971	method	_	_
12-28	972-975	for	_	_
12-29	976-984	training	_	_
12-30	985-993	semantic	_	_
12-31	994-1006	segmentation	_	_
12-32	1007-1013	models	_	_
12-33	1014-1017	for	_	_
12-34	1018-1026	maritime	_	_
12-35	1027-1035	obstacle	_	_
12-36	1036-1045	detection	_	_
12-37	1046-1051	using	_	_
12-38	1052-1056	only	_	_
12-39	1057-1061	weak	_	_
12-40	1062-1073	annotations	_	_
12-41	1074-1075	(	_	_
12-42	1075-1083	obstacle	_	_
12-43	1084-1092	bounding	_	_
12-44	1093-1098	boxes	_	_
12-45	1099-1102	and	_	_
12-46	1103-1113	water-edge	_	_
12-47	1114-1123	poly-line	_	_
12-48	1123-1124	)	_	_
12-49	1124-1125	.	_	_

#Text=Despite a \*\*signifficant reduction in annotation time (20x)\*\*, SLR training \*\*improves robustness\*\* of networks for obstacle detection, which is a remarkable result.  !
13-1	1126-1133	Despite	_	_
13-2	1134-1135	a	_	_
13-3	1136-1137	\*	_	_
13-4	1137-1138	\*	_	_
13-5	1138-1150	signifficant	_	_
13-6	1151-1160	reduction	_	_
13-7	1161-1163	in	_	_
13-8	1164-1174	annotation	_	_
13-9	1175-1179	time	_	_
13-10	1180-1181	(	_	_
13-11	1181-1184	20x	_	_
13-12	1184-1185	)	_	_
13-13	1185-1186	\*	_	_
13-14	1186-1187	\*	_	_
13-15	1187-1188	,	_	_
13-16	1189-1192	SLR	_	_
13-17	1193-1201	training	_	_
13-18	1202-1203	\*	_	_
13-19	1203-1204	\*	_	_
13-20	1204-1212	improves	_	_
13-21	1213-1223	robustness	_	_
13-22	1223-1224	\*	_	_
13-23	1224-1225	\*	_	_
13-24	1226-1228	of	_	_
13-25	1229-1237	networks	_	_
13-26	1238-1241	for	_	_
13-27	1242-1250	obstacle	_	_
13-28	1251-1260	detection	_	_
13-29	1260-1261	,	_	_
13-30	1262-1267	which	_	_
13-31	1268-1270	is	_	_
13-32	1271-1272	a	_	_
13-33	1273-1283	remarkable	_	_
13-34	1284-1290	result	_	_
13-35	1290-1291	.	_	_
13-36	1293-1294	!	_	_

#Text=\[SLR Architecture\](resources/slr.png)  SLR is comprised of three steps. 1) The model is warmed-up using object-wise and global objectives derived from weak annotations and IMU. 2) he learned encoder features and model predictions are used to estimate the pseudo labels. 3) The network is fine-tuned on the estimated pseudo labels.
14-1	1294-1295	\[	_	_
14-2	1295-1298	SLR	_	_
14-3	1299-1311	Architecture	_	_
14-4	1311-1312	\]	_	_
14-5	1312-1313	(	_	_
14-6	1313-1322	resources	_	_
14-7	1322-1323	/	_	_
14-8	1323-1330	slr.png	_	_
14-9	1330-1331	)	_	_
14-10	1333-1336	SLR	_	_
14-11	1337-1339	is	_	_
14-12	1340-1349	comprised	_	_
14-13	1350-1352	of	_	_
14-14	1353-1358	three	_	_
14-15	1359-1364	steps	_	_
14-16	1364-1365	.	_	_
14-17	1366-1367	1	_	_
14-18	1367-1368	)	_	_
14-19	1369-1372	The	_	_
14-20	1373-1378	model	_	_
14-21	1379-1381	is	_	_
14-22	1382-1391	warmed-up	_	_
14-23	1392-1397	using	_	_
14-24	1398-1409	object-wise	_	_
14-25	1410-1413	and	_	_
14-26	1414-1420	global	_	_
14-27	1421-1431	objectives	_	_
14-28	1432-1439	derived	_	_
14-29	1440-1444	from	_	_
14-30	1445-1449	weak	_	_
14-31	1450-1461	annotations	_	_
14-32	1462-1465	and	_	_
14-33	1466-1469	IMU	_	_
14-34	1469-1470	.	_	_
14-35	1471-1472	2	_	_
14-36	1472-1473	)	_	_
14-37	1474-1476	he	_	_
14-38	1477-1484	learned	_	_
14-39	1485-1492	encoder	_	_
14-40	1493-1501	features	_	_
14-41	1502-1505	and	_	_
14-42	1506-1511	model	_	_
14-43	1512-1523	predictions	_	_
14-44	1524-1527	are	_	_
14-45	1528-1532	used	_	_
14-46	1533-1535	to	_	_
14-47	1536-1544	estimate	_	_
14-48	1545-1548	the	_	_
14-49	1549-1555	pseudo	_	_
14-50	1556-1562	labels	_	_
14-51	1562-1563	.	_	_
14-52	1564-1565	3	_	_
14-53	1565-1566	)	_	_
14-54	1567-1570	The	_	_
14-55	1571-1578	network	_	_
14-56	1579-1581	is	_	_
14-57	1582-1592	fine-tuned	_	_
14-58	1593-1595	on	_	_
14-59	1596-1599	the	_	_
14-60	1600-1609	estimated	_	_
14-61	1610-1616	pseudo	_	_
14-62	1617-1623	labels	_	_
14-63	1623-1624	.	_	_

#Text=For additional details please refer to the \[paper\](https://arxiv.org/abs/2206.13263).   ## Getting started  ### Installation  1.
15-1	1627-1630	For	_	_
15-2	1631-1641	additional	_	_
15-3	1642-1649	details	_	_
15-4	1650-1656	please	_	_
15-5	1657-1662	refer	_	_
15-6	1663-1665	to	_	_
15-7	1666-1669	the	_	_
15-8	1670-1671	\[	_	_
15-9	1671-1676	paper	_	_
15-10	1676-1677	\]	_	_
15-11	1677-1678	(	_	_
15-12	1678-1683	https	_	_
15-13	1683-1684	:	_	_
15-14	1684-1685	/	_	_
15-15	1685-1686	/	_	_
15-16	1686-1695	arxiv.org	_	_
15-17	1695-1696	/	_	_
15-18	1696-1699	abs	_	_
15-19	1699-1700	/	_	_
15-20	1700-1710	2206.13263	_	_
15-21	1710-1711	)	_	_
15-22	1711-1712	.	_	_
15-23	1715-1716	#	_	_
15-24	1716-1717	#	_	_
15-25	1718-1725	Getting	_	_
15-26	1726-1733	started	_	_
15-27	1735-1736	#	_	_
15-28	1736-1737	#	_	_
15-29	1737-1738	#	_	_
15-30	1739-1751	Installation	_	_
15-31	1753-1754	1	_	_
15-32	1754-1755	.	_	_

#Text=Clone the repository     ```bash     git clone https://github.com/lojzezust/SLR     cd SLR     ``` 2.
16-1	1756-1761	Clone	_	_
16-2	1762-1765	the	_	_
16-3	1766-1776	repository	_	_
16-4	1781-1782	`	_	_
16-5	1782-1783	`	_	_
16-6	1783-1784	`	_	_
16-7	1784-1788	bash	_	_
16-8	1793-1796	git	_	_
16-9	1797-1802	clone	_	_
16-10	1803-1808	https	_	_
16-11	1808-1809	:	_	_
16-12	1809-1810	/	_	_
16-13	1810-1811	/	_	_
16-14	1811-1821	github.com	_	_
16-15	1821-1822	/	_	_
16-16	1822-1831	lojzezust	_	_
16-17	1831-1832	/	_	_
16-18	1832-1835	SLR	_	_
16-19	1840-1842	cd	_	_
16-20	1843-1846	SLR	_	_
16-21	1851-1852	`	_	_
16-22	1852-1853	`	_	_
16-23	1853-1854	`	_	_
16-24	1855-1856	2	_	_
16-25	1856-1857	.	_	_

#Text=Install the requirements     ```bash     pip install -r requirements.txt     ``` 3.
17-1	1858-1865	Install	_	_
17-2	1866-1869	the	_	_
17-3	1870-1882	requirements	_	_
17-4	1887-1888	`	_	_
17-5	1888-1889	`	_	_
17-6	1889-1890	`	_	_
17-7	1890-1894	bash	_	_
17-8	1899-1902	pip	_	_
17-9	1903-1910	install	_	_
17-10	1911-1912	-	_	_
17-11	1912-1913	r	_	_
17-12	1914-1930	requirements.txt	_	_
17-13	1935-1936	`	_	_
17-14	1936-1937	`	_	_
17-15	1937-1938	`	_	_
17-16	1939-1940	3	_	_
17-17	1940-1941	.	_	_

#Text=Install SLR.
18-1	1942-1949	Install	_	_
18-2	1950-1953	SLR	_	_
18-3	1953-1954	.	_	_

#Text=Use the `-e` flag if you want to make changes.
19-1	1955-1958	Use	_	_
19-2	1959-1962	the	_	_
19-3	1963-1964	`	_	_
19-4	1964-1965	-	_	_
19-5	1965-1966	e	_	_
19-6	1966-1967	`	_	_
19-7	1968-1972	flag	_	_
19-8	1973-1975	if	_	_
19-9	1976-1979	you	_	_
19-10	1980-1984	want	_	_
19-11	1985-1987	to	_	_
19-12	1988-1992	make	_	_
19-13	1993-2000	changes	_	_
19-14	2000-2001	.	_	_

#Text=```bash     pip install -e .     ``` 4.
20-1	2006-2007	`	_	_
20-2	2007-2008	`	_	_
20-3	2008-2009	`	_	_
20-4	2009-2013	bash	_	_
20-5	2018-2021	pip	_	_
20-6	2022-2029	install	_	_
20-7	2030-2031	-	_	_
20-8	2031-2032	e	_	_
20-9	2033-2034	.	_	_
20-10	2039-2040	`	_	_
20-11	2040-2041	`	_	_
20-12	2041-2042	`	_	_
20-13	2043-2044	4	_	_
20-14	2044-2045	.	_	_

#Text=Link datasets directory and create an output directory.
21-1	2046-2050	Link	_	_
21-2	2051-2059	datasets	_	_
21-3	2060-2069	directory	_	_
21-4	2070-2073	and	_	_
21-5	2074-2080	create	_	_
21-6	2081-2083	an	_	_
21-7	2084-2090	output	_	_
21-8	2091-2100	directory	_	_
21-9	2100-2101	.	_	_

#Text=```bash     ln -s path/to/data data     mkdir output     ```  ### Preparing the data  1.
22-1	2106-2107	`	_	_
22-2	2107-2108	`	_	_
22-3	2108-2109	`	_	_
22-4	2109-2113	bash	_	_
22-5	2118-2120	ln	_	_
22-6	2121-2122	-	_	_
22-7	2122-2123	s	_	_
22-8	2124-2128	path	_	_
22-9	2128-2129	/	_	_
22-10	2129-2131	to	_	_
22-11	2131-2132	/	_	_
22-12	2132-2136	data	_	_
22-13	2137-2141	data	_	_
22-14	2146-2151	mkdir	_	_
22-15	2152-2158	output	_	_
22-16	2163-2164	`	_	_
22-17	2164-2165	`	_	_
22-18	2165-2166	`	_	_
22-19	2168-2169	#	_	_
22-20	2169-2170	#	_	_
22-21	2170-2171	#	_	_
22-22	2172-2181	Preparing	_	_
22-23	2182-2185	the	_	_
22-24	2186-2190	data	_	_
22-25	2192-2193	1	_	_
22-26	2193-2194	.	_	_

#Text=Download the \[MaSTr1325 dataset\](https://box.vicos.si/borja/viamaro/index.html) and corresponding \[weak annotations\](https://github.com/lojzezust/SLR/releases/download/weights\_v2/mastr\_slr.zip).
23-1	2195-2203	Download	_	_
23-2	2204-2207	the	_	_
23-3	2208-2209	\[	_	_
23-4	2209-2218	MaSTr1325	_	_
23-5	2219-2226	dataset	_	_
23-6	2226-2227	\]	_	_
23-7	2227-2228	(	_	_
23-8	2228-2233	https	_	_
23-9	2233-2234	:	_	_
23-10	2234-2235	/	_	_
23-11	2235-2236	/	_	_
23-12	2236-2248	box.vicos.si	_	_
23-13	2248-2249	/	_	_
23-14	2249-2254	borja	_	_
23-15	2254-2255	/	_	_
23-16	2255-2262	viamaro	_	_
23-17	2262-2263	/	_	_
23-18	2263-2273	index.html	_	_
23-19	2273-2274	)	_	_
23-20	2275-2278	and	_	_
23-21	2279-2292	corresponding	_	_
23-22	2293-2294	\[	_	_
23-23	2294-2298	weak	_	_
23-24	2299-2310	annotations	_	_
23-25	2310-2311	\]	_	_
23-26	2311-2312	(	_	_
23-27	2312-2317	https	_	_
23-28	2317-2318	:	_	_
23-29	2318-2319	/	_	_
23-30	2319-2320	/	_	_
23-31	2320-2330	github.com	_	_
23-32	2330-2331	/	_	_
23-33	2331-2340	lojzezust	_	_
23-34	2340-2341	/	_	_
23-35	2341-2344	SLR	_	_
23-36	2344-2345	/	_	_
23-37	2345-2353	releases	_	_
23-38	2353-2354	/	_	_
23-39	2354-2362	download	_	_
23-40	2362-2363	/	_	_
23-41	2363-2373	weights\_v2	_	_
23-42	2373-2374	/	_	_
23-43	2374-2387	mastr\_slr.zip	_	_
23-44	2387-2388	)	_	_
23-45	2388-2389	.	_	_

#Text=The weak annotation archive also includes automatically generated prior obstacle segmentation masks (i.e. using DEXTR). 2.
24-1	2390-2393	The	_	_
24-2	2394-2398	weak	_	_
24-3	2399-2409	annotation	_	_
24-4	2410-2417	archive	_	_
24-5	2418-2422	also	_	_
24-6	2423-2431	includes	_	_
24-7	2432-2445	automatically	_	_
24-8	2446-2455	generated	_	_
24-9	2456-2461	prior	_	_
24-10	2462-2470	obstacle	_	_
24-11	2471-2483	segmentation	_	_
24-12	2484-2489	masks	_	_
24-13	2490-2491	(	_	_
24-14	2491-2494	i.e	_	_
24-15	2494-2495	.	_	_
24-16	2496-2501	using	_	_
24-17	2502-2507	DEXTR	_	_
24-18	2507-2508	)	_	_
24-19	2508-2509	.	_	_
24-20	2510-2511	2	_	_
24-21	2511-2512	.	_	_

#Text=Use a script to prepare the data.
25-1	2513-2516	Use	_	_
25-2	2517-2518	a	_	_
25-3	2519-2525	script	_	_
25-4	2526-2528	to	_	_
25-5	2529-2536	prepare	_	_
25-6	2537-2540	the	_	_
25-7	2541-2545	data	_	_
25-8	2545-2546	.	_	_

#Text=```bash     python tools/prepare\_data.py     ```     The preparation script performs the following operations:     1.
26-1	2551-2552	`	_	_
26-2	2552-2553	`	_	_
26-3	2553-2554	`	_	_
26-4	2554-2558	bash	_	_
26-5	2563-2569	python	_	_
26-6	2570-2575	tools	_	_
26-7	2575-2576	/	_	_
26-8	2576-2591	prepare\_data.py	_	_
26-9	2596-2597	`	_	_
26-10	2597-2598	`	_	_
26-11	2598-2599	`	_	_
26-12	2604-2607	The	_	_
26-13	2608-2619	preparation	_	_
26-14	2620-2626	script	_	_
26-15	2627-2635	performs	_	_
26-16	2636-2639	the	_	_
26-17	2640-2649	following	_	_
26-18	2650-2660	operations	_	_
26-19	2660-2661	:	_	_
26-20	2666-2667	1	_	_
26-21	2667-2668	.	_	_

#Text=Prepares object masks - converts bounding boxes from weak annotations into masks used in training     2.
27-1	2669-2677	Prepares	_	_
27-2	2678-2684	object	_	_
27-3	2685-2690	masks	_	_
27-4	2691-2692	-	_	_
27-5	2693-2701	converts	_	_
27-6	2702-2710	bounding	_	_
27-7	2711-2716	boxes	_	_
27-8	2717-2721	from	_	_
27-9	2722-2726	weak	_	_
27-10	2727-2738	annotations	_	_
27-11	2739-2743	into	_	_
27-12	2744-2749	masks	_	_
27-13	2750-2754	used	_	_
27-14	2755-2757	in	_	_
27-15	2758-2766	training	_	_
27-16	2771-2772	2	_	_
27-17	2772-2773	.	_	_

#Text=Prepares pairwise similarity maps - pre-computes the neighbor similarities used by the pairwise loss     3.
28-1	2774-2782	Prepares	_	_
28-2	2783-2791	pairwise	_	_
28-3	2792-2802	similarity	_	_
28-4	2803-2807	maps	_	_
28-5	2808-2809	-	_	_
28-6	2810-2822	pre-computes	_	_
28-7	2823-2826	the	_	_
28-8	2827-2835	neighbor	_	_
28-9	2836-2848	similarities	_	_
28-10	2849-2853	used	_	_
28-11	2854-2856	by	_	_
28-12	2857-2860	the	_	_
28-13	2861-2869	pairwise	_	_
28-14	2870-2874	loss	_	_
28-15	2879-2880	3	_	_
28-16	2880-2881	.	_	_

#Text=Prepares partial masks - compute the partial masks used in the warm-up phase.
29-1	2882-2890	Prepares	_	_
29-2	2891-2898	partial	_	_
29-3	2899-2904	masks	_	_
29-4	2905-2906	-	_	_
29-5	2907-2914	compute	_	_
29-6	2915-2918	the	_	_
29-7	2919-2926	partial	_	_
29-8	2927-2932	masks	_	_
29-9	2933-2937	used	_	_
29-10	2938-2940	in	_	_
29-11	2941-2944	the	_	_
29-12	2945-2952	warm-up	_	_
29-13	2953-2958	phase	_	_
29-14	2958-2959	.	_	_

#Text=Partial masks are constructed from weak annotations and IMU horizon masks.     4.
30-1	2960-2967	Partial	_	_
30-2	2968-2973	masks	_	_
30-3	2974-2977	are	_	_
30-4	2978-2989	constructed	_	_
30-5	2990-2994	from	_	_
30-6	2995-2999	weak	_	_
30-7	3000-3011	annotations	_	_
30-8	3012-3015	and	_	_
30-9	3016-3019	IMU	_	_
30-10	3020-3027	horizon	_	_
30-11	3028-3033	masks	_	_
30-12	3033-3034	.	_	_
30-13	3039-3040	4	_	_
30-14	3040-3041	.	_	_

#Text=Prepares the prior obstacle segmentation masks - reads RLE encoded Dextr predictions and adds sky and water segmentation based on IMU horizon masks and partial labels.     5.
31-1	3042-3050	Prepares	_	_
31-2	3051-3054	the	_	_
31-3	3055-3060	prior	_	_
31-4	3061-3069	obstacle	_	_
31-5	3070-3082	segmentation	_	_
31-6	3083-3088	masks	_	_
31-7	3089-3090	-	_	_
31-8	3091-3096	reads	_	_
31-9	3097-3100	RLE	_	_
31-10	3101-3108	encoded	_	_
31-11	3109-3114	Dextr	_	_
31-12	3115-3126	predictions	_	_
31-13	3127-3130	and	_	_
31-14	3131-3135	adds	_	_
31-15	3136-3139	sky	_	_
31-16	3140-3143	and	_	_
31-17	3144-3149	water	_	_
31-18	3150-3162	segmentation	_	_
31-19	3163-3168	based	_	_
31-20	3169-3171	on	_	_
31-21	3172-3175	IMU	_	_
31-22	3176-3183	horizon	_	_
31-23	3184-3189	masks	_	_
31-24	3190-3193	and	_	_
31-25	3194-3201	partial	_	_
31-26	3202-3208	labels	_	_
31-27	3208-3209	.	_	_
31-28	3214-3215	5	_	_
31-29	3215-3216	.	_	_

#Text=Creates a dataset file `all\_weak.yaml`, which links the prepared dataset directories for training.  ### SLR Training  Use the utility script `tools/train\_slr.sh` to train a model using the entire SLR pipeline.
32-1	3217-3224	Creates	_	_
32-2	3225-3226	a	_	_
32-3	3227-3234	dataset	_	_
32-4	3235-3239	file	_	_
32-5	3240-3241	`	_	_
32-6	3241-3254	all\_weak.yaml	_	_
32-7	3254-3255	`	_	_
32-8	3255-3256	,	_	_
32-9	3257-3262	which	_	_
32-10	3263-3268	links	_	_
32-11	3269-3272	the	_	_
32-12	3273-3281	prepared	_	_
32-13	3282-3289	dataset	_	_
32-14	3290-3301	directories	_	_
32-15	3302-3305	for	_	_
32-16	3306-3314	training	_	_
32-17	3314-3315	.	_	_
32-18	3317-3318	#	_	_
32-19	3318-3319	#	_	_
32-20	3319-3320	#	_	_
32-21	3321-3324	SLR	_	_
32-22	3325-3333	Training	_	_
32-23	3335-3338	Use	_	_
32-24	3339-3342	the	_	_
32-25	3343-3350	utility	_	_
32-26	3351-3357	script	_	_
32-27	3358-3359	`	_	_
32-28	3359-3364	tools	_	_
32-29	3364-3365	/	_	_
32-30	3365-3377	train\_slr.sh	_	_
32-31	3377-3378	`	_	_
32-32	3379-3381	to	_	_
32-33	3382-3387	train	_	_
32-34	3388-3389	a	_	_
32-35	3390-3395	model	_	_
32-36	3396-3401	using	_	_
32-37	3402-3405	the	_	_
32-38	3406-3412	entire	_	_
32-39	3413-3416	SLR	_	_
32-40	3417-3425	pipeline	_	_
32-41	3425-3426	.	_	_

#Text=```bash chmod +x tools/train\_slr.sh tools/train\_slr.sh ```  The script contains the following variables, that can be changed to achieve the desired results
33-1	3429-3430	`	_	_
33-2	3430-3431	`	_	_
33-3	3431-3432	`	_	_
33-4	3432-3436	bash	_	_
33-5	3437-3442	chmod	_	_
33-6	3443-3444	+	_	_
33-7	3444-3445	x	_	_
33-8	3446-3451	tools	_	_
33-9	3451-3452	/	_	_
33-10	3452-3464	train\_slr.sh	_	_
33-11	3465-3470	tools	_	_
33-12	3470-3471	/	_	_
33-13	3471-3483	train\_slr.sh	_	_
33-14	3484-3485	`	_	_
33-15	3485-3486	`	_	_
33-16	3486-3487	`	_	_
33-17	3489-3492	The	_	_
33-18	3493-3499	script	_	_
33-19	3500-3508	contains	_	_
33-20	3509-3512	the	_	_
33-21	3513-3522	following	_	_
33-22	3523-3532	variables	_	_
33-23	3532-3533	,	_	_
33-24	3534-3538	that	_	_
33-25	3539-3542	can	_	_
33-26	3543-3545	be	_	_
33-27	3546-3553	changed	_	_
33-28	3554-3556	to	_	_
33-29	3557-3564	achieve	_	_
33-30	3565-3568	the	_	_
33-31	3569-3576	desired	_	_
33-32	3577-3584	results	_	_

#Text=.
34-1	3584-3585	.	_	_

#Text=- `MASTR\_DIR`: Location of the dataset used for training. - `ARCHITECTURE`: Which architecture to use (use `python tools/train.py warmup --help` for more info). - `MODEL\_NAME`: Name of the model.
35-1	3587-3588	-	_	_
35-2	3589-3590	`	_	_
35-3	3590-3599	MASTR\_DIR	_	_
35-4	3599-3600	`	_	_
35-5	3600-3601	:	_	_
35-6	3602-3610	Location	_	_
35-7	3611-3613	of	_	_
35-8	3614-3617	the	_	_
35-9	3618-3625	dataset	_	_
35-10	3626-3630	used	_	_
35-11	3631-3634	for	_	_
35-12	3635-3643	training	_	_
35-13	3643-3644	.	_	_
35-14	3645-3646	-	_	_
35-15	3647-3648	`	_	_
35-16	3648-3660	ARCHITECTURE	_	_
35-17	3660-3661	`	_	_
35-18	3661-3662	:	_	_
35-19	3663-3668	Which	_	_
35-20	3669-3681	architecture	_	_
35-21	3682-3684	to	_	_
35-22	3685-3688	use	_	_
35-23	3689-3690	(	_	_
35-24	3690-3693	use	_	_
35-25	3694-3695	`	_	_
35-26	3695-3701	python	_	_
35-27	3702-3707	tools	_	_
35-28	3707-3708	/	_	_
35-29	3708-3716	train.py	_	_
35-30	3717-3723	warmup	_	_
35-31	3724-3725	-	_	_
35-32	3725-3726	-	_	_
35-33	3726-3730	help	_	_
35-34	3730-3731	`	_	_
35-35	3732-3735	for	_	_
35-36	3736-3740	more	_	_
35-37	3741-3745	info	_	_
35-38	3745-3746	)	_	_
35-39	3746-3747	.	_	_
35-40	3748-3749	-	_	_
35-41	3750-3751	`	_	_
35-42	3751-3761	MODEL\_NAME	_	_
35-43	3761-3762	`	_	_
35-44	3762-3763	:	_	_
35-45	3764-3768	Name	_	_
35-46	3769-3771	of	_	_
35-47	3772-3775	the	_	_
35-48	3776-3781	model	_	_
35-49	3781-3782	.	_	_

#Text=Used for saving logs and weights. - `BATCH\_SIZE`: Batch size per gpu. - `WARMUP\_EPOCHS`: Number of epochs for the warm-up phase. - `FINETUNE\_EPOCHS`: Number of epochs for the fine-tuning phase. - `NUM\_ITER`: Number of iterations of the SLR pseudo label estimation and fine-tuning.  ### Individual training steps  Individual steps of the SLR pipeline can also be executed separately, with the following python scripts.  #### Step I: Feature warm-up  Train an initial model on partial labels generated from weak annotations and IMU.
36-1	3783-3787	Used	_	_
36-2	3788-3791	for	_	_
36-3	3792-3798	saving	_	_
36-4	3799-3803	logs	_	_
36-5	3804-3807	and	_	_
36-6	3808-3815	weights	_	_
36-7	3815-3816	.	_	_
36-8	3817-3818	-	_	_
36-9	3819-3820	`	_	_
36-10	3820-3830	BATCH\_SIZE	_	_
36-11	3830-3831	`	_	_
36-12	3831-3832	:	_	_
36-13	3833-3838	Batch	_	_
36-14	3839-3843	size	_	_
36-15	3844-3847	per	_	_
36-16	3848-3851	gpu	_	_
36-17	3851-3852	.	_	_
36-18	3853-3854	-	_	_
36-19	3855-3856	`	_	_
36-20	3856-3869	WARMUP\_EPOCHS	_	_
36-21	3869-3870	`	_	_
36-22	3870-3871	:	_	_
36-23	3872-3878	Number	_	_
36-24	3879-3881	of	_	_
36-25	3882-3888	epochs	_	_
36-26	3889-3892	for	_	_
36-27	3893-3896	the	_	_
36-28	3897-3904	warm-up	_	_
36-29	3905-3910	phase	_	_
36-30	3910-3911	.	_	_
36-31	3912-3913	-	_	_
36-32	3914-3915	`	_	_
36-33	3915-3930	FINETUNE\_EPOCHS	_	_
36-34	3930-3931	`	_	_
36-35	3931-3932	:	_	_
36-36	3933-3939	Number	_	_
36-37	3940-3942	of	_	_
36-38	3943-3949	epochs	_	_
36-39	3950-3953	for	_	_
36-40	3954-3957	the	_	_
36-41	3958-3969	fine-tuning	_	_
36-42	3970-3975	phase	_	_
36-43	3975-3976	.	_	_
36-44	3977-3978	-	_	_
36-45	3979-3980	`	_	_
36-46	3980-3988	NUM\_ITER	_	_
36-47	3988-3989	`	_	_
36-48	3989-3990	:	_	_
36-49	3991-3997	Number	_	_
36-50	3998-4000	of	_	_
36-51	4001-4011	iterations	_	_
36-52	4012-4014	of	_	_
36-53	4015-4018	the	_	_
36-54	4019-4022	SLR	_	_
36-55	4023-4029	pseudo	_	_
36-56	4030-4035	label	_	_
36-57	4036-4046	estimation	_	_
36-58	4047-4050	and	_	_
36-59	4051-4062	fine-tuning	_	_
36-60	4062-4063	.	_	_
36-61	4065-4066	#	_	_
36-62	4066-4067	#	_	_
36-63	4067-4068	#	_	_
36-64	4069-4079	Individual	_	_
36-65	4080-4088	training	_	_
36-66	4089-4094	steps	_	_
36-67	4096-4106	Individual	_	_
36-68	4107-4112	steps	_	_
36-69	4113-4115	of	_	_
36-70	4116-4119	the	_	_
36-71	4120-4123	SLR	_	_
36-72	4124-4132	pipeline	_	_
36-73	4133-4136	can	_	_
36-74	4137-4141	also	_	_
36-75	4142-4144	be	_	_
36-76	4145-4153	executed	_	_
36-77	4154-4164	separately	_	_
36-78	4164-4165	,	_	_
36-79	4166-4170	with	_	_
36-80	4171-4174	the	_	_
36-81	4175-4184	following	_	_
36-82	4185-4191	python	_	_
36-83	4192-4199	scripts	_	_
36-84	4199-4200	.	_	_
36-85	4202-4203	#	_	_
36-86	4203-4204	#	_	_
36-87	4204-4205	#	_	_
36-88	4205-4206	#	_	_
36-89	4207-4211	Step	_	_
36-90	4212-4213	I	_	_
36-91	4213-4214	:	_	_
36-92	4215-4222	Feature	_	_
36-93	4223-4230	warm-up	_	_
36-94	4232-4237	Train	_	_
36-95	4238-4240	an	_	_
36-96	4241-4248	initial	_	_
36-97	4249-4254	model	_	_
36-98	4255-4257	on	_	_
36-99	4258-4265	partial	_	_
36-100	4266-4272	labels	_	_
36-101	4273-4282	generated	_	_
36-102	4283-4287	from	_	_
36-103	4288-4292	weak	_	_
36-104	4293-4304	annotations	_	_
36-105	4305-4308	and	_	_
36-106	4309-4312	IMU	_	_
36-107	4312-4313	.	_	_

#Text=Uses additional object-wise losses.
37-1	4314-4318	Uses	_	_
37-2	4319-4329	additional	_	_
37-3	4330-4341	object-wise	_	_
37-4	4342-4348	losses	_	_
37-5	4348-4349	.	_	_

#Text=```bash export CUDA\_VISIBLE\_DEVICES=0,1 python tools/train.py warmup \\ --architecture wasr\_resnet101\_imu \\ --model-name wasr\_slr\_warmup \\ --batch-size 4 ```  > \[!
38-1	4350-4351	`	_	_
38-2	4351-4352	`	_	_
38-3	4352-4353	`	_	_
38-4	4353-4357	bash	_	_
38-5	4358-4364	export	_	_
38-6	4365-4385	CUDA\_VISIBLE\_DEVICES	_	_
38-7	4385-4386	=	_	_
38-8	4386-4389	0,1	_	_
38-9	4390-4396	python	_	_
38-10	4397-4402	tools	_	_
38-11	4402-4403	/	_	_
38-12	4403-4411	train.py	_	_
38-13	4412-4418	warmup	_	_
38-14	4419-4420	\\	_	_
38-15	4421-4422	-	_	_
38-16	4422-4423	-	_	_
38-17	4423-4435	architecture	_	_
38-18	4436-4450	wasr\_resnet101	_	_
38-19	4450-4451	\_	_	_
38-20	4451-4454	imu	_	_
38-21	4455-4456	\\	_	_
38-22	4457-4458	-	_	_
38-23	4458-4459	-	_	_
38-24	4459-4469	model-name	_	_
38-25	4470-4485	wasr\_slr\_warmup	_	_
38-26	4486-4487	\\	_	_
38-27	4488-4489	-	_	_
38-28	4489-4490	-	_	_
38-29	4490-4500	batch-size	_	_
38-30	4501-4502	4	_	_
38-31	4503-4504	`	_	_
38-32	4504-4505	`	_	_
38-33	4505-4506	`	_	_
38-34	4508-4509	>	_	_
38-35	4510-4511	\[	_	_
38-36	4511-4512	!	_	_

#Text=TIP\] > Use the `--help` switch for more details on all possible arguments and settings.  #### Step II: Generate pseudo labels  Generate pseudo labels by refining model predictions with learned features.
39-1	4512-4515	TIP	_	_
39-2	4515-4516	\]	_	_
39-3	4517-4518	>	_	_
39-4	4519-4522	Use	_	_
39-5	4523-4526	the	_	_
39-6	4527-4528	`	_	_
39-7	4528-4529	-	_	_
39-8	4529-4530	-	_	_
39-9	4530-4534	help	_	_
39-10	4534-4535	`	_	_
39-11	4536-4542	switch	_	_
39-12	4543-4546	for	_	_
39-13	4547-4551	more	_	_
39-14	4552-4559	details	_	_
39-15	4560-4562	on	_	_
39-16	4563-4566	all	_	_
39-17	4567-4575	possible	_	_
39-18	4576-4585	arguments	_	_
39-19	4586-4589	and	_	_
39-20	4590-4598	settings	_	_
39-21	4598-4599	.	_	_
39-22	4601-4602	#	_	_
39-23	4602-4603	#	_	_
39-24	4603-4604	#	_	_
39-25	4604-4605	#	_	_
39-26	4606-4610	Step	_	_
39-27	4611-4613	II	_	_
39-28	4613-4614	:	_	_
39-29	4615-4623	Generate	_	_
39-30	4624-4630	pseudo	_	_
39-31	4631-4637	labels	_	_
39-32	4639-4647	Generate	_	_
39-33	4648-4654	pseudo	_	_
39-34	4655-4661	labels	_	_
39-35	4662-4664	by	_	_
39-36	4665-4673	refining	_	_
39-37	4674-4679	model	_	_
39-38	4680-4691	predictions	_	_
39-39	4692-4696	with	_	_
39-40	4697-4704	learned	_	_
39-41	4705-4713	features	_	_
39-42	4713-4714	.	_	_

#Text=```bash export CUDA\_VISIBLE\_DEVICES=0,1 python tools/generate\_pseudo\_labels.py \\ --architecture wasr\_resnet101\_imu \\ --weights-file output/logs/wasr\_slr\_warmup/version\_0/checkpoints/last.ckpt \\ --output-dir output/pseudo\_labels/wasr\_slr\_warmup\_v0 ```  This creates the pseudo-labels and stores them into `output/pseudo\_labels/wasr\_slr\_warmup\_v0`
40-1	4715-4716	`	_	_
40-2	4716-4717	`	_	_
40-3	4717-4718	`	_	_
40-4	4718-4722	bash	_	_
40-5	4723-4729	export	_	_
40-6	4730-4750	CUDA\_VISIBLE\_DEVICES	_	_
40-7	4750-4751	=	_	_
40-8	4751-4754	0,1	_	_
40-9	4755-4761	python	_	_
40-10	4762-4767	tools	_	_
40-11	4767-4768	/	_	_
40-12	4768-4793	generate\_pseudo\_labels.py	_	_
40-13	4794-4795	\\	_	_
40-14	4796-4797	-	_	_
40-15	4797-4798	-	_	_
40-16	4798-4810	architecture	_	_
40-17	4811-4825	wasr\_resnet101	_	_
40-18	4825-4826	\_	_	_
40-19	4826-4829	imu	_	_
40-20	4830-4831	\\	_	_
40-21	4832-4833	-	_	_
40-22	4833-4834	-	_	_
40-23	4834-4846	weights-file	_	_
40-24	4847-4853	output	_	_
40-25	4853-4854	/	_	_
40-26	4854-4858	logs	_	_
40-27	4858-4859	/	_	_
40-28	4859-4874	wasr\_slr\_warmup	_	_
40-29	4874-4875	/	_	_
40-30	4875-4882	version	_	_
40-31	4882-4883	\_	_	_
40-32	4883-4884	0	_	_
40-33	4884-4885	/	_	_
40-34	4885-4896	checkpoints	_	_
40-35	4896-4897	/	_	_
40-36	4897-4906	last.ckpt	_	_
40-37	4907-4908	\\	_	_
40-38	4909-4910	-	_	_
40-39	4910-4911	-	_	_
40-40	4911-4921	output-dir	_	_
40-41	4922-4928	output	_	_
40-42	4928-4929	/	_	_
40-43	4929-4942	pseudo\_labels	_	_
40-44	4942-4943	/	_	_
40-45	4943-4961	wasr\_slr\_warmup\_v0	_	_
40-46	4962-4963	`	_	_
40-47	4963-4964	`	_	_
40-48	4964-4965	`	_	_
40-49	4967-4971	This	_	_
40-50	4972-4979	creates	_	_
40-51	4980-4983	the	_	_
40-52	4984-4997	pseudo-labels	_	_
40-53	4998-5001	and	_	_
40-54	5002-5008	stores	_	_
40-55	5009-5013	them	_	_
40-56	5014-5018	into	_	_
40-57	5019-5020	`	_	_
40-58	5020-5026	output	_	_
40-59	5026-5027	/	_	_
40-60	5027-5040	pseudo\_labels	_	_
40-61	5040-5041	/	_	_
40-62	5041-5059	wasr\_slr\_warmup\_v0	_	_
40-63	5059-5060	`	_	_

#Text=.
41-1	5060-5061	.	_	_

#Text=> \[!
42-1	5063-5064	>	_	_
42-2	5065-5066	\[	_	_
42-3	5066-5067	!	_	_

#Text=TIP\] > Use the `--help` switch for more details on all possible arguments and settings.  #### Step III: Fine-tune model  Fine-tune the initial model on the estimated pseudo-labels from the previous step.
43-1	5067-5070	TIP	_	_
43-2	5070-5071	\]	_	_
43-3	5072-5073	>	_	_
43-4	5074-5077	Use	_	_
43-5	5078-5081	the	_	_
43-6	5082-5083	`	_	_
43-7	5083-5084	-	_	_
43-8	5084-5085	-	_	_
43-9	5085-5089	help	_	_
43-10	5089-5090	`	_	_
43-11	5091-5097	switch	_	_
43-12	5098-5101	for	_	_
43-13	5102-5106	more	_	_
43-14	5107-5114	details	_	_
43-15	5115-5117	on	_	_
43-16	5118-5121	all	_	_
43-17	5122-5130	possible	_	_
43-18	5131-5140	arguments	_	_
43-19	5141-5144	and	_	_
43-20	5145-5153	settings	_	_
43-21	5153-5154	.	_	_
43-22	5156-5157	#	_	_
43-23	5157-5158	#	_	_
43-24	5158-5159	#	_	_
43-25	5159-5160	#	_	_
43-26	5161-5165	Step	_	_
43-27	5166-5169	III	_	_
43-28	5169-5170	:	_	_
43-29	5171-5180	Fine-tune	_	_
43-30	5181-5186	model	_	_
43-31	5188-5197	Fine-tune	_	_
43-32	5198-5201	the	_	_
43-33	5202-5209	initial	_	_
43-34	5210-5215	model	_	_
43-35	5216-5218	on	_	_
43-36	5219-5222	the	_	_
43-37	5223-5232	estimated	_	_
43-38	5233-5246	pseudo-labels	_	_
43-39	5247-5251	from	_	_
43-40	5252-5255	the	_	_
43-41	5256-5264	previous	_	_
43-42	5265-5269	step	_	_
43-43	5269-5270	.	_	_

#Text=The model is initialized with weights of the initial model.
44-1	5272-5275	The	_	_
44-2	5276-5281	model	_	_
44-3	5282-5284	is	_	_
44-4	5285-5296	initialized	_	_
44-5	5297-5301	with	_	_
44-6	5302-5309	weights	_	_
44-7	5310-5312	of	_	_
44-8	5313-5316	the	_	_
44-9	5317-5324	initial	_	_
44-10	5325-5330	model	_	_
44-11	5330-5331	.	_	_

#Text=```bash export CUDA\_VISIBLE\_DEVICES=0,1 python tools/train.py finetune \\ --architecture wasr\_resnet101\_imu \\ --model-name wasr\_slr \\ --batch-size 4 \\ --pretrained-weights output/logs/wasr\_slr\_warmup/version\_0/checkpoints/last.ckpt \\ --mask-dir output/pseudo\_labels/wasr\_slr\_warmup\_v0 ```  > \[!
45-1	5333-5334	`	_	_
45-2	5334-5335	`	_	_
45-3	5335-5336	`	_	_
45-4	5336-5340	bash	_	_
45-5	5341-5347	export	_	_
45-6	5348-5368	CUDA\_VISIBLE\_DEVICES	_	_
45-7	5368-5369	=	_	_
45-8	5369-5372	0,1	_	_
45-9	5373-5379	python	_	_
45-10	5380-5385	tools	_	_
45-11	5385-5386	/	_	_
45-12	5386-5394	train.py	_	_
45-13	5395-5403	finetune	_	_
45-14	5404-5405	\\	_	_
45-15	5406-5407	-	_	_
45-16	5407-5408	-	_	_
45-17	5408-5420	architecture	_	_
45-18	5421-5435	wasr\_resnet101	_	_
45-19	5435-5436	\_	_	_
45-20	5436-5439	imu	_	_
45-21	5440-5441	\\	_	_
45-22	5442-5443	-	_	_
45-23	5443-5444	-	_	_
45-24	5444-5454	model-name	_	_
45-25	5455-5463	wasr\_slr	_	_
45-26	5464-5465	\\	_	_
45-27	5466-5467	-	_	_
45-28	5467-5468	-	_	_
45-29	5468-5478	batch-size	_	_
45-30	5479-5480	4	_	_
45-31	5481-5482	\\	_	_
45-32	5483-5484	-	_	_
45-33	5484-5485	-	_	_
45-34	5485-5503	pretrained-weights	_	_
45-35	5504-5510	output	_	_
45-36	5510-5511	/	_	_
45-37	5511-5515	logs	_	_
45-38	5515-5516	/	_	_
45-39	5516-5531	wasr\_slr\_warmup	_	_
45-40	5531-5532	/	_	_
45-41	5532-5539	version	_	_
45-42	5539-5540	\_	_	_
45-43	5540-5541	0	_	_
45-44	5541-5542	/	_	_
45-45	5542-5553	checkpoints	_	_
45-46	5553-5554	/	_	_
45-47	5554-5563	last.ckpt	_	_
45-48	5564-5565	\\	_	_
45-49	5566-5567	-	_	_
45-50	5567-5568	-	_	_
45-51	5568-5576	mask-dir	_	_
45-52	5577-5583	output	_	_
45-53	5583-5584	/	_	_
45-54	5584-5597	pseudo\_labels	_	_
45-55	5597-5598	/	_	_
45-56	5598-5616	wasr\_slr\_warmup\_v0	_	_
45-57	5617-5618	`	_	_
45-58	5618-5619	`	_	_
45-59	5619-5620	`	_	_
45-60	5622-5623	>	_	_
45-61	5624-5625	\[	_	_
45-62	5625-5626	!	_	_

#Text=TIP\] > Use the `--help` switch for more details on all possible arguments and settings.  ### Inference  #### General inference  Run inference using a trained model.
46-1	5626-5629	TIP	_	_
46-2	5629-5630	\]	_	_
46-3	5631-5632	>	_	_
46-4	5633-5636	Use	_	_
46-5	5637-5640	the	_	_
46-6	5641-5642	`	_	_
46-7	5642-5643	-	_	_
46-8	5643-5644	-	_	_
46-9	5644-5648	help	_	_
46-10	5648-5649	`	_	_
46-11	5650-5656	switch	_	_
46-12	5657-5660	for	_	_
46-13	5661-5665	more	_	_
46-14	5666-5673	details	_	_
46-15	5674-5676	on	_	_
46-16	5677-5680	all	_	_
46-17	5681-5689	possible	_	_
46-18	5690-5699	arguments	_	_
46-19	5700-5703	and	_	_
46-20	5704-5712	settings	_	_
46-21	5712-5713	.	_	_
46-22	5715-5716	#	_	_
46-23	5716-5717	#	_	_
46-24	5717-5718	#	_	_
46-25	5719-5728	Inference	_	_
46-26	5730-5731	#	_	_
46-27	5731-5732	#	_	_
46-28	5732-5733	#	_	_
46-29	5733-5734	#	_	_
46-30	5735-5742	General	_	_
46-31	5743-5752	inference	_	_
46-32	5754-5757	Run	_	_
46-33	5758-5767	inference	_	_
46-34	5768-5773	using	_	_
46-35	5774-5775	a	_	_
46-36	5776-5783	trained	_	_
46-37	5784-5789	model	_	_
46-38	5789-5790	.	_	_

#Text=`tools/general\_inference.py` script is able to run inference on a directory of images recursively.
47-1	5791-5792	`	_	_
47-2	5792-5797	tools	_	_
47-3	5797-5798	/	_	_
47-4	5798-5818	general\_inference.py	_	_
47-5	5818-5819	`	_	_
47-6	5820-5826	script	_	_
47-7	5827-5829	is	_	_
47-8	5830-5834	able	_	_
47-9	5835-5837	to	_	_
47-10	5838-5841	run	_	_
47-11	5842-5851	inference	_	_
47-12	5852-5854	on	_	_
47-13	5855-5856	a	_	_
47-14	5857-5866	directory	_	_
47-15	5867-5869	of	_	_
47-16	5870-5876	images	_	_
47-17	5877-5888	recursively	_	_
47-18	5888-5889	.	_	_

#Text=It replicates the directory structure in the output directory.
48-1	5890-5892	It	_	_
48-2	5893-5903	replicates	_	_
48-3	5904-5907	the	_	_
48-4	5908-5917	directory	_	_
48-5	5918-5927	structure	_	_
48-6	5928-5930	in	_	_
48-7	5931-5934	the	_	_
48-8	5935-5941	output	_	_
48-9	5942-5951	directory	_	_
48-10	5951-5952	.	_	_

#Text=```bash export CUDA\_VISIBLE\_DEVICES=0,1 python tools/general\_inference.py \\ --architecture wasr\_resnet101 \\ --weights-file output/logs/wasr\_slr\_v2\_it1/version\_0/checkpoints/last.ckpt \\ --image-dir data/example\_dir \\ --output-dir output/predictions/test\_predictions ```  Additionally, `--imu-dir` can be used to supply a directory with corresponding IMU horizon masks.
49-1	5954-5955	`	_	_
49-2	5955-5956	`	_	_
49-3	5956-5957	`	_	_
49-4	5957-5961	bash	_	_
49-5	5962-5968	export	_	_
49-6	5969-5989	CUDA\_VISIBLE\_DEVICES	_	_
49-7	5989-5990	=	_	_
49-8	5990-5993	0,1	_	_
49-9	5994-6000	python	_	_
49-10	6001-6006	tools	_	_
49-11	6006-6007	/	_	_
49-12	6007-6027	general\_inference.py	_	_
49-13	6028-6029	\\	_	_
49-14	6030-6031	-	_	_
49-15	6031-6032	-	_	_
49-16	6032-6044	architecture	_	_
49-17	6045-6059	wasr\_resnet101	_	_
49-18	6060-6061	\\	_	_
49-19	6062-6063	-	_	_
49-20	6063-6064	-	_	_
49-21	6064-6076	weights-file	_	_
49-22	6077-6083	output	_	_
49-23	6083-6084	/	_	_
49-24	6084-6088	logs	_	_
49-25	6088-6089	/	_	_
49-26	6089-6100	wasr\_slr\_v2	_	_
49-27	6100-6101	\_	_	_
49-28	6101-6104	it1	_	_
49-29	6104-6105	/	_	_
49-30	6105-6112	version	_	_
49-31	6112-6113	\_	_	_
49-32	6113-6114	0	_	_
49-33	6114-6115	/	_	_
49-34	6115-6126	checkpoints	_	_
49-35	6126-6127	/	_	_
49-36	6127-6136	last.ckpt	_	_
49-37	6137-6138	\\	_	_
49-38	6139-6140	-	_	_
49-39	6140-6141	-	_	_
49-40	6141-6150	image-dir	_	_
49-41	6151-6155	data	_	_
49-42	6155-6156	/	_	_
49-43	6156-6167	example\_dir	_	_
49-44	6168-6169	\\	_	_
49-45	6170-6171	-	_	_
49-46	6171-6172	-	_	_
49-47	6172-6182	output-dir	_	_
49-48	6183-6189	output	_	_
49-49	6189-6190	/	_	_
49-50	6190-6201	predictions	_	_
49-51	6201-6202	/	_	_
49-52	6202-6218	test\_predictions	_	_
49-53	6219-6220	`	_	_
49-54	6220-6221	`	_	_
49-55	6221-6222	`	_	_
49-56	6224-6236	Additionally	_	_
49-57	6236-6237	,	_	_
49-58	6238-6239	`	_	_
49-59	6239-6240	-	_	_
49-60	6240-6241	-	_	_
49-61	6241-6248	imu-dir	_	_
49-62	6248-6249	`	_	_
49-63	6250-6253	can	_	_
49-64	6254-6256	be	_	_
49-65	6257-6261	used	_	_
49-66	6262-6264	to	_	_
49-67	6265-6271	supply	_	_
49-68	6272-6273	a	_	_
49-69	6274-6283	directory	_	_
49-70	6284-6288	with	_	_
49-71	6289-6302	corresponding	_	_
49-72	6303-6306	IMU	_	_
49-73	6307-6314	horizon	_	_
49-74	6315-6320	masks	_	_
49-75	6320-6321	.	_	_

#Text=The directory structure should match the one of image dir
50-1	6322-6325	The	_	_
50-2	6326-6335	directory	_	_
50-3	6336-6345	structure	_	_
50-4	6346-6352	should	_	_
50-5	6353-6358	match	_	_
50-6	6359-6362	the	_	_
50-7	6363-6366	one	_	_
50-8	6367-6369	of	_	_
50-9	6370-6375	image	_	_
50-10	6376-6379	dir	_	_

#Text=.
51-1	6379-6380	.	_	_

#Text=> \[!
52-1	6382-6383	>	_	_
52-2	6384-6385	\[	_	_
52-3	6385-6386	!	_	_

#Text=NOTE\] > The IMU dir has to be provided for models architectures relying on IMU data (i.e.
53-1	6386-6390	NOTE	_	_
53-2	6390-6391	\]	_	_
53-3	6392-6393	>	_	_
53-4	6394-6397	The	_	_
53-5	6398-6401	IMU	_	_
53-6	6402-6405	dir	_	_
53-7	6406-6409	has	_	_
53-8	6410-6412	to	_	_
53-9	6413-6415	be	_	_
53-10	6416-6424	provided	_	_
53-11	6425-6428	for	_	_
53-12	6429-6435	models	_	_
53-13	6436-6449	architectures	_	_
53-14	6450-6457	relying	_	_
53-15	6458-6460	on	_	_
53-16	6461-6464	IMU	_	_
53-17	6465-6469	data	_	_
53-18	6470-6471	(	_	_
53-19	6471-6474	i.e	_	_
53-20	6474-6475	.	_	_

#Text=WaSR with IMU)
54-1	6476-6480	WaSR	_	_
54-2	6481-6485	with	_	_
54-3	6486-6489	IMU	_	_
54-4	6489-6490	)	_	_

#Text=.
55-1	6490-6491	.	_	_

#Text=> \[!
56-1	6493-6494	>	_	_
56-2	6495-6496	\[	_	_
56-3	6496-6497	!	_	_

#Text=TIP\] > Use the `--help` switch for more details on all possible arguments and settings.  #### MODS inference  `tools/mods\_inference.py` can be used in a similar fashion to run inference on the MODS benchmark
57-1	6497-6500	TIP	_	_
57-2	6500-6501	\]	_	_
57-3	6502-6503	>	_	_
57-4	6504-6507	Use	_	_
57-5	6508-6511	the	_	_
57-6	6512-6513	`	_	_
57-7	6513-6514	-	_	_
57-8	6514-6515	-	_	_
57-9	6515-6519	help	_	_
57-10	6519-6520	`	_	_
57-11	6521-6527	switch	_	_
57-12	6528-6531	for	_	_
57-13	6532-6536	more	_	_
57-14	6537-6544	details	_	_
57-15	6545-6547	on	_	_
57-16	6548-6551	all	_	_
57-17	6552-6560	possible	_	_
57-18	6561-6570	arguments	_	_
57-19	6571-6574	and	_	_
57-20	6575-6583	settings	_	_
57-21	6583-6584	.	_	_
57-22	6586-6587	#	_	_
57-23	6587-6588	#	_	_
57-24	6588-6589	#	_	_
57-25	6589-6590	#	_	_
57-26	6591-6595	MODS	_	_
57-27	6596-6605	inference	_	_
57-28	6607-6608	`	_	_
57-29	6608-6613	tools	_	_
57-30	6613-6614	/	_	_
57-31	6614-6631	mods\_inference.py	_	_
57-32	6631-6632	`	_	_
57-33	6633-6636	can	_	_
57-34	6637-6639	be	_	_
57-35	6640-6644	used	_	_
57-36	6645-6647	in	_	_
57-37	6648-6649	a	_	_
57-38	6650-6657	similar	_	_
57-39	6658-6665	fashion	_	_
57-40	6666-6668	to	_	_
57-41	6669-6672	run	_	_
57-42	6673-6682	inference	_	_
57-43	6683-6685	on	_	_
57-44	6686-6689	the	_	_
57-45	6690-6694	MODS	_	_
57-46	6695-6704	benchmark	_	_

#Text=.
58-1	6704-6705	.	_	_

#Text=> \[!
59-1	6707-6708	>	_	_
59-2	6709-6710	\[	_	_
59-3	6710-6711	!	_	_

#Text=TIP\] > Use the `--help` switch for more details on all possible arguments and settings.  ## Pretrained models  Currently available pretrained model weights.
60-1	6711-6714	TIP	_	_
60-2	6714-6715	\]	_	_
60-3	6716-6717	>	_	_
60-4	6718-6721	Use	_	_
60-5	6722-6725	the	_	_
60-6	6726-6727	`	_	_
60-7	6727-6728	-	_	_
60-8	6728-6729	-	_	_
60-9	6729-6733	help	_	_
60-10	6733-6734	`	_	_
60-11	6735-6741	switch	_	_
60-12	6742-6745	for	_	_
60-13	6746-6750	more	_	_
60-14	6751-6758	details	_	_
60-15	6759-6761	on	_	_
60-16	6762-6765	all	_	_
60-17	6766-6774	possible	_	_
60-18	6775-6784	arguments	_	_
60-19	6785-6788	and	_	_
60-20	6789-6797	settings	_	_
60-21	6797-6798	.	_	_
60-22	6800-6801	#	_	_
60-23	6801-6802	#	_	_
60-24	6803-6813	Pretrained	_	_
60-25	6814-6820	models	_	_
60-26	6822-6831	Currently	_	_
60-27	6832-6841	available	_	_
60-28	6842-6852	pretrained	_	_
60-29	6853-6858	model	_	_
60-30	6859-6866	weights	_	_
60-31	6866-6867	.	_	_

#Text=All models are trained on the MaSTr1325 dataset using SLR and weak annotations and evaluated on the \[MODS benchmark\](https://github.com/bborja/mods\_evaluation).
61-1	6868-6871	All	_	_
61-2	6872-6878	models	_	_
61-3	6879-6882	are	_	_
61-4	6883-6890	trained	_	_
61-5	6891-6893	on	_	_
61-6	6894-6897	the	_	_
61-7	6898-6907	MaSTr1325	_	_
61-8	6908-6915	dataset	_	_
61-9	6916-6921	using	_	_
61-10	6922-6925	SLR	_	_
61-11	6926-6929	and	_	_
61-12	6930-6934	weak	_	_
61-13	6935-6946	annotations	_	_
61-14	6947-6950	and	_	_
61-15	6951-6960	evaluated	_	_
61-16	6961-6963	on	_	_
61-17	6964-6967	the	_	_
61-18	6968-6969	\[	_	_
61-19	6969-6973	MODS	_	_
61-20	6974-6983	benchmark	_	_
61-21	6983-6984	\]	_	_
61-22	6984-6985	(	_	_
61-23	6985-6990	https	_	_
61-24	6990-6991	:	_	_
61-25	6991-6992	/	_	_
61-26	6992-6993	/	_	_
61-27	6993-7003	github.com	_	_
61-28	7003-7004	/	_	_
61-29	7004-7010	bborja	_	_
61-30	7010-7011	/	_	_
61-31	7011-7026	mods\_evaluation	_	_
61-32	7026-7027	)	_	_
61-33	7027-7028	.	_	_

#Text=F1 obstacle detection scores are reported overall and separately within the 15m critical danger zone around the boat
62-1	7031-7033	F1	_	_
62-2	7034-7042	obstacle	_	_
62-3	7043-7052	detection	_	_
62-4	7053-7059	scores	_	_
62-5	7060-7063	are	_	_
62-6	7064-7072	reported	_	_
62-7	7073-7080	overall	_	_
62-8	7081-7084	and	_	_
62-9	7085-7095	separately	_	_
62-10	7096-7102	within	_	_
62-11	7103-7106	the	_	_
62-12	7107-7110	15m	_	_
62-13	7111-7119	critical	_	_
62-14	7120-7126	danger	_	_
62-15	7127-7131	zone	_	_
62-16	7132-7138	around	_	_
62-17	7139-7142	the	_	_
62-18	7143-7147	boat	_	_

#Text=.
63-1	7147-7148	.	_	_

#Text=\| architecture       \| backbone   \| IMU \| url                                                                                                        \| $\\mathrm{F1}$ \| $\\mathrm{F1}\_D$ \| \|--------------------\|------------\|-----\|------------------------------------------------------------------------------------------------------------\|---------------\|-----------------\| \| wasr\_resnet101     \| ResNet-101 \|     \| \[weights\](https://github.com/lojzezust/SLR/releases/download/weights\_v2/wasr\_slr\_v2\_rn101.pth)             \| 94.4          \| 92.0            \| \| wasr\_resnet101\_imu \| ResNet-101 \|  ✓  \| \[weights\](https://github.com/lojzezust/SLR/releases/download/weights\_v2/wasr\_slr\_v2\_rn101\_imu.pth)         \| 94.9          \| 93.7            \|   ## Cite  You can use the following BibTeX entry to cite this work:  ```bibtex @article{Zust2022Learning,     author = {Žust, Lojze and Kristan, Matej},     title = {Learning with Weak Annotations for Robust Maritime Obstacle Detection},     journal = {Sensors},     volume = {22},     year = {2022},     number = {23},     article-number = {9139},     url = {https://www.mdpi.com/1424-8220/22/23/9139},     issn = {1424-8220},     doi = {10.3390/s22239139} } ```
64-1	7150-7151	\|	_	_
64-2	7152-7164	architecture	_	_
64-3	7171-7172	\|	_	_
64-4	7173-7181	backbone	_	_
64-5	7184-7185	\|	_	_
64-6	7186-7189	IMU	_	_
64-7	7190-7191	\|	_	_
64-8	7192-7195	url	_	_
64-9	7299-7300	\|	_	_
64-10	7301-7302	$	_	_
64-11	7302-7303	\\	_	_
64-12	7303-7309	mathrm	_	_
64-13	7309-7310	{	_	_
64-14	7310-7312	F1	_	_
64-15	7312-7313	}	_	_
64-16	7313-7314	$	_	_
64-17	7315-7316	\|	_	_
64-18	7317-7318	$	_	_
64-19	7318-7319	\\	_	_
64-20	7319-7325	mathrm	_	_
64-21	7325-7326	{	_	_
64-22	7326-7328	F1	_	_
64-23	7328-7329	}	_	_
64-24	7329-7330	\_	_	_
64-25	7330-7331	D	_	_
64-26	7331-7332	$	_	_
64-27	7333-7334	\|	_	_
64-28	7335-7336	\|	_	_
64-29	7336-7337	-	_	_
64-30	7337-7338	-	_	_
64-31	7338-7339	-	_	_
64-32	7339-7340	-	_	_
64-33	7340-7341	-	_	_
64-34	7341-7342	-	_	_
64-35	7342-7343	-	_	_
64-36	7343-7344	-	_	_
64-37	7344-7345	-	_	_
64-38	7345-7346	-	_	_
64-39	7346-7347	-	_	_
64-40	7347-7348	-	_	_
64-41	7348-7349	-	_	_
64-42	7349-7350	-	_	_
64-43	7350-7351	-	_	_
64-44	7351-7352	-	_	_
64-45	7352-7353	-	_	_
64-46	7353-7354	-	_	_
64-47	7354-7355	-	_	_
64-48	7355-7356	-	_	_
64-49	7356-7357	\|	_	_
64-50	7357-7358	-	_	_
64-51	7358-7359	-	_	_
64-52	7359-7360	-	_	_
64-53	7360-7361	-	_	_
64-54	7361-7362	-	_	_
64-55	7362-7363	-	_	_
64-56	7363-7364	-	_	_
64-57	7364-7365	-	_	_
64-58	7365-7366	-	_	_
64-59	7366-7367	-	_	_
64-60	7367-7368	-	_	_
64-61	7368-7369	-	_	_
64-62	7369-7370	\|	_	_
64-63	7370-7371	-	_	_
64-64	7371-7372	-	_	_
64-65	7372-7373	-	_	_
64-66	7373-7374	-	_	_
64-67	7374-7375	-	_	_
64-68	7375-7376	\|	_	_
64-69	7376-7377	-	_	_
64-70	7377-7378	-	_	_
64-71	7378-7379	-	_	_
64-72	7379-7380	-	_	_
64-73	7380-7381	-	_	_
64-74	7381-7382	-	_	_
64-75	7382-7383	-	_	_
64-76	7383-7384	-	_	_
64-77	7384-7385	-	_	_
64-78	7385-7386	-	_	_
64-79	7386-7387	-	_	_
64-80	7387-7388	-	_	_
64-81	7388-7389	-	_	_
64-82	7389-7390	-	_	_
64-83	7390-7391	-	_	_
64-84	7391-7392	-	_	_
64-85	7392-7393	-	_	_
64-86	7393-7394	-	_	_
64-87	7394-7395	-	_	_
64-88	7395-7396	-	_	_
64-89	7396-7397	-	_	_
64-90	7397-7398	-	_	_
64-91	7398-7399	-	_	_
64-92	7399-7400	-	_	_
64-93	7400-7401	-	_	_
64-94	7401-7402	-	_	_
64-95	7402-7403	-	_	_
64-96	7403-7404	-	_	_
64-97	7404-7405	-	_	_
64-98	7405-7406	-	_	_
64-99	7406-7407	-	_	_
64-100	7407-7408	-	_	_
64-101	7408-7409	-	_	_
64-102	7409-7410	-	_	_
64-103	7410-7411	-	_	_
64-104	7411-7412	-	_	_
64-105	7412-7413	-	_	_
64-106	7413-7414	-	_	_
64-107	7414-7415	-	_	_
64-108	7415-7416	-	_	_
64-109	7416-7417	-	_	_
64-110	7417-7418	-	_	_
64-111	7418-7419	-	_	_
64-112	7419-7420	-	_	_
64-113	7420-7421	-	_	_
64-114	7421-7422	-	_	_
64-115	7422-7423	-	_	_
64-116	7423-7424	-	_	_
64-117	7424-7425	-	_	_
64-118	7425-7426	-	_	_
64-119	7426-7427	-	_	_
64-120	7427-7428	-	_	_
64-121	7428-7429	-	_	_
64-122	7429-7430	-	_	_
64-123	7430-7431	-	_	_
64-124	7431-7432	-	_	_
64-125	7432-7433	-	_	_
64-126	7433-7434	-	_	_
64-127	7434-7435	-	_	_
64-128	7435-7436	-	_	_
64-129	7436-7437	-	_	_
64-130	7437-7438	-	_	_
64-131	7438-7439	-	_	_
64-132	7439-7440	-	_	_
64-133	7440-7441	-	_	_
64-134	7441-7442	-	_	_
64-135	7442-7443	-	_	_
64-136	7443-7444	-	_	_
64-137	7444-7445	-	_	_
64-138	7445-7446	-	_	_
64-139	7446-7447	-	_	_
64-140	7447-7448	-	_	_
64-141	7448-7449	-	_	_
64-142	7449-7450	-	_	_
64-143	7450-7451	-	_	_
64-144	7451-7452	-	_	_
64-145	7452-7453	-	_	_
64-146	7453-7454	-	_	_
64-147	7454-7455	-	_	_
64-148	7455-7456	-	_	_
64-149	7456-7457	-	_	_
64-150	7457-7458	-	_	_
64-151	7458-7459	-	_	_
64-152	7459-7460	-	_	_
64-153	7460-7461	-	_	_
64-154	7461-7462	-	_	_
64-155	7462-7463	-	_	_
64-156	7463-7464	-	_	_
64-157	7464-7465	-	_	_
64-158	7465-7466	-	_	_
64-159	7466-7467	-	_	_
64-160	7467-7468	-	_	_
64-161	7468-7469	-	_	_
64-162	7469-7470	-	_	_
64-163	7470-7471	-	_	_
64-164	7471-7472	-	_	_
64-165	7472-7473	-	_	_
64-166	7473-7474	-	_	_
64-167	7474-7475	-	_	_
64-168	7475-7476	-	_	_
64-169	7476-7477	-	_	_
64-170	7477-7478	-	_	_
64-171	7478-7479	-	_	_
64-172	7479-7480	-	_	_
64-173	7480-7481	-	_	_
64-174	7481-7482	-	_	_
64-175	7482-7483	-	_	_
64-176	7483-7484	-	_	_
64-177	7484-7485	\|	_	_
64-178	7485-7486	-	_	_
64-179	7486-7487	-	_	_
64-180	7487-7488	-	_	_
64-181	7488-7489	-	_	_
64-182	7489-7490	-	_	_
64-183	7490-7491	-	_	_
64-184	7491-7492	-	_	_
64-185	7492-7493	-	_	_
64-186	7493-7494	-	_	_
64-187	7494-7495	-	_	_
64-188	7495-7496	-	_	_
64-189	7496-7497	-	_	_
64-190	7497-7498	-	_	_
64-191	7498-7499	-	_	_
64-192	7499-7500	-	_	_
64-193	7500-7501	\|	_	_
64-194	7501-7502	-	_	_
64-195	7502-7503	-	_	_
64-196	7503-7504	-	_	_
64-197	7504-7505	-	_	_
64-198	7505-7506	-	_	_
64-199	7506-7507	-	_	_
64-200	7507-7508	-	_	_
64-201	7508-7509	-	_	_
64-202	7509-7510	-	_	_
64-203	7510-7511	-	_	_
64-204	7511-7512	-	_	_
64-205	7512-7513	-	_	_
64-206	7513-7514	-	_	_
64-207	7514-7515	-	_	_
64-208	7515-7516	-	_	_
64-209	7516-7517	-	_	_
64-210	7517-7518	-	_	_
64-211	7518-7519	\|	_	_
64-212	7520-7521	\|	_	_
64-213	7522-7536	wasr\_resnet101	_	_
64-214	7541-7542	\|	_	_
64-215	7543-7549	ResNet	_	_
64-216	7549-7550	-	_	_
64-217	7550-7553	101	_	_
64-218	7554-7555	\|	_	_
64-219	7560-7561	\|	_	_
64-220	7562-7563	\[	_	_
64-221	7563-7570	weights	_	_
64-222	7570-7571	\]	_	_
64-223	7571-7572	(	_	_
64-224	7572-7577	https	_	_
64-225	7577-7578	:	_	_
64-226	7578-7579	/	_	_
64-227	7579-7580	/	_	_
64-228	7580-7590	github.com	_	_
64-229	7590-7591	/	_	_
64-230	7591-7600	lojzezust	_	_
64-231	7600-7601	/	_	_
64-232	7601-7604	SLR	_	_
64-233	7604-7605	/	_	_
64-234	7605-7613	releases	_	_
64-235	7613-7614	/	_	_
64-236	7614-7622	download	_	_
64-237	7622-7623	/	_	_
64-238	7623-7633	weights\_v2	_	_
64-239	7633-7634	/	_	_
64-240	7634-7645	wasr\_slr\_v2	_	_
64-241	7645-7646	\_	_	_
64-242	7646-7651	rn101	_	_
64-243	7651-7652	.	_	_
64-244	7652-7655	pth	_	_
64-245	7655-7656	)	_	_
64-246	7669-7670	\|	_	_
64-247	7671-7675	94.4	_	_
64-248	7685-7686	\|	_	_
64-249	7687-7691	92.0	_	_
64-250	7703-7704	\|	_	_
64-251	7705-7706	\|	_	_
64-252	7707-7721	wasr\_resnet101	_	_
64-253	7721-7722	\_	_	_
64-254	7722-7725	imu	_	_
64-255	7726-7727	\|	_	_
64-256	7728-7734	ResNet	_	_
64-257	7734-7735	-	_	_
64-258	7735-7738	101	_	_
64-259	7739-7740	\|	_	_
64-260	7742-7743	✓	_	_
64-261	7745-7746	\|	_	_
64-262	7747-7748	\[	_	_
64-263	7748-7755	weights	_	_
64-264	7755-7756	\]	_	_
64-265	7756-7757	(	_	_
64-266	7757-7762	https	_	_
64-267	7762-7763	:	_	_
64-268	7763-7764	/	_	_
64-269	7764-7765	/	_	_
64-270	7765-7775	github.com	_	_
64-271	7775-7776	/	_	_
64-272	7776-7785	lojzezust	_	_
64-273	7785-7786	/	_	_
64-274	7786-7789	SLR	_	_
64-275	7789-7790	/	_	_
64-276	7790-7798	releases	_	_
64-277	7798-7799	/	_	_
64-278	7799-7807	download	_	_
64-279	7807-7808	/	_	_
64-280	7808-7818	weights\_v2	_	_
64-281	7818-7819	/	_	_
64-282	7819-7830	wasr\_slr\_v2	_	_
64-283	7830-7831	\_	_	_
64-284	7831-7836	rn101	_	_
64-285	7836-7837	\_	_	_
64-286	7837-7844	imu.pth	_	_
64-287	7844-7845	)	_	_
64-288	7854-7855	\|	_	_
64-289	7856-7860	94.9	_	_
64-290	7870-7871	\|	_	_
64-291	7872-7876	93.7	_	_
64-292	7888-7889	\|	_	_
64-293	7892-7893	#	_	_
64-294	7893-7894	#	_	_
64-295	7895-7899	Cite	_	_
64-296	7901-7904	You	_	_
64-297	7905-7908	can	_	_
64-298	7909-7912	use	_	_
64-299	7913-7916	the	_	_
64-300	7917-7926	following	_	_
64-301	7927-7933	BibTeX	_	_
64-302	7934-7939	entry	_	_
64-303	7940-7942	to	_	_
64-304	7943-7947	cite	_	_
64-305	7948-7952	this	_	_
64-306	7953-7957	work	_	_
64-307	7957-7958	:	_	_
64-308	7960-7961	`	_	_
64-309	7961-7962	`	_	_
64-310	7962-7963	`	_	_
64-311	7963-7969	bibtex	_	_
64-312	7970-7971	@	_	_
64-313	7971-7978	article	_	_
64-314	7978-7979	{	_	_
64-315	7979-7995	Zust2022Learning	_	_
64-316	7995-7996	,	_	_
64-317	8001-8007	author	_	_
64-318	8008-8009	=	_	_
64-319	8010-8011	{	_	_
64-320	8011-8015	Žust	_	_
64-321	8015-8016	,	_	_
64-322	8017-8022	Lojze	_	_
64-323	8023-8026	and	_	_
64-324	8027-8034	Kristan	_	_
64-325	8034-8035	,	_	_
64-326	8036-8041	Matej	_	_
64-327	8041-8042	}	_	_
64-328	8042-8043	,	_	_
64-329	8048-8053	title	_	_
64-330	8054-8055	=	_	_
64-331	8056-8057	{	_	_
64-332	8057-8065	Learning	_	_
64-333	8066-8070	with	_	_
64-334	8071-8075	Weak	_	_
64-335	8076-8087	Annotations	_	_
64-336	8088-8091	for	_	_
64-337	8092-8098	Robust	_	_
64-338	8099-8107	Maritime	_	_
64-339	8108-8116	Obstacle	_	_
64-340	8117-8126	Detection	_	_
64-341	8126-8127	}	_	_
64-342	8127-8128	,	_	_
64-343	8133-8140	journal	_	_
64-344	8141-8142	=	_	_
64-345	8143-8144	{	_	_
64-346	8144-8151	Sensors	_	_
64-347	8151-8152	}	_	_
64-348	8152-8153	,	_	_
64-349	8158-8164	volume	_	_
64-350	8165-8166	=	_	_
64-351	8167-8168	{	_	_
64-352	8168-8170	22	_	_
64-353	8170-8171	}	_	_
64-354	8171-8172	,	_	_
64-355	8177-8181	year	_	_
64-356	8182-8183	=	_	_
64-357	8184-8185	{	_	_
64-358	8185-8189	2022	_	_
64-359	8189-8190	}	_	_
64-360	8190-8191	,	_	_
64-361	8196-8202	number	_	_
64-362	8203-8204	=	_	_
64-363	8205-8206	{	_	_
64-364	8206-8208	23	_	_
64-365	8208-8209	}	_	_
64-366	8209-8210	,	_	_
64-367	8215-8229	article-number	_	_
64-368	8230-8231	=	_	_
64-369	8232-8233	{	_	_
64-370	8233-8237	9139	_	_
64-371	8237-8238	}	_	_
64-372	8238-8239	,	_	_
64-373	8244-8247	url	_	_
64-374	8248-8249	=	_	_
64-375	8250-8251	{	_	_
64-376	8251-8256	https	_	_
64-377	8256-8257	:	_	_
64-378	8257-8258	/	_	_
64-379	8258-8259	/	_	_
64-380	8259-8271	www.mdpi.com	_	_
64-381	8271-8272	/	_	_
64-382	8272-8276	1424	_	_
64-383	8276-8277	-	_	_
64-384	8277-8281	8220	_	_
64-385	8281-8282	/	_	_
64-386	8282-8284	22	_	_
64-387	8284-8285	/	_	_
64-388	8285-8287	23	_	_
64-389	8287-8288	/	_	_
64-390	8288-8292	9139	_	_
64-391	8292-8293	}	_	_
64-392	8293-8294	,	_	_
64-393	8299-8303	issn	_	_
64-394	8304-8305	=	_	_
64-395	8306-8307	{	_	_
64-396	8307-8311	1424	_	_
64-397	8311-8312	-	_	_
64-398	8312-8316	8220	_	_
64-399	8316-8317	}	_	_
64-400	8317-8318	,	_	_
64-401	8323-8326	doi	_	_
64-402	8327-8328	=	_	_
64-403	8329-8330	{	_	_
64-404	8330-8337	10.3390	_	_
64-405	8337-8338	/	_	_
64-406	8338-8347	s22239139	_	_
64-407	8347-8348	}	_	_
64-408	8349-8350	}	_	_
64-409	8351-8352	`	_	_
64-410	8352-8353	`	_	_
64-411	8353-8354	`	_	_