#FORMAT=WebAnno TSV 3.3
#T_SP=de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity|identifier|value


#Text=# Systematic-Generalization-via-Meaningful-Learning This repository is for the paper \[Revisit Systematic Generalization via Meaningful Learning\](https://aclanthology.org/2022.blackboxnlp-1.6).
1-1	0-1	#	_	_
1-2	2-51	Systematic-Generalization-via-Meaningful-Learning	_	_
1-3	52-56	This	_	_
1-4	57-67	repository	_	_
1-5	68-70	is	_	_
1-6	71-74	for	_	_
1-7	75-78	the	_	_
1-8	79-84	paper	_	_
1-9	85-86	\[	_	_
1-10	86-93	Revisit	_	_
1-11	94-104	Systematic	_	_
1-12	105-119	Generalization	_	_
1-13	120-123	via	_	_
1-14	124-134	Meaningful	_	_
1-15	135-143	Learning	_	_
1-16	143-144	\]	_	_
1-17	144-145	(	_	_
1-18	145-150	https	_	_
1-19	150-151	:	_	_
1-20	151-152	/	_	_
1-21	152-153	/	_	_
1-22	153-169	aclanthology.org	_	_
1-23	169-170	/	_	_
1-24	170-174	2022	_	_
1-25	174-175	.	_	_
1-26	175-186	blackboxnlp	_	_
1-27	186-187	-	_	_
1-28	187-190	1.6	_	_
1-29	190-191	)	_	_
1-30	191-192	.	_	_

#Text=\*In Proceedings of the Fifth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP\*, pages 62–79, Abu Dhabi, United Arab Emirates (Hybrid).
2-1	193-194	\*	_	_
2-2	194-196	In	_	_
2-3	197-208	Proceedings	_	_
2-4	209-211	of	_	_
2-5	212-215	the	_	_
2-6	216-221	Fifth	_	_
2-7	222-233	BlackboxNLP	_	_
2-8	234-242	Workshop	_	_
2-9	243-245	on	_	_
2-10	246-255	Analyzing	_	_
2-11	256-259	and	_	_
2-12	260-272	Interpreting	_	_
2-13	273-279	Neural	_	_
2-14	280-288	Networks	_	_
2-15	289-292	for	_	_
2-16	293-296	NLP	_	_
2-17	296-297	\*	_	_
2-18	297-298	,	_	_
2-19	299-304	pages	_	_
2-20	305-307	62	_	_
2-21	307-308	–	_	_
2-22	308-310	79	_	_
2-23	310-311	,	_	_
2-24	312-315	Abu	_	_
2-25	316-321	Dhabi	_	_
2-26	321-322	,	_	_
2-27	323-329	United	_	_
2-28	330-334	Arab	_	_
2-29	335-343	Emirates	_	_
2-30	344-345	(	_	_
2-31	345-351	Hybrid	_	_
2-32	351-352	)	_	_
2-33	352-353	.	_	_

#Text=Association for Computational Linguistics.
3-1	354-365	Association	_	_
3-2	366-369	for	_	_
3-3	370-383	Computational	_	_
3-4	384-395	Linguistics	_	_
3-5	395-396	.	_	_

#Text=\[\[arXiv\](https://arxiv.org/abs/2003.06658)\] \[\[Poster\](https://www.shininglab.ai/assets/posters/Revisit%20Systematic%20Generalization%20via%20Meaningful%20Learning.pdf)\]  ## Directory + \*\*main/config.py\*\* - Configurations + \*\*main/res\*\* - Resources including model check points, datasets, experiment records, and results + \*\*main/src\*\* - Source code including model structures and utility functions ``` Systematic-Generalization-via-Meaningful-Learning ├── README.md ├── main │   ├── config.py │   ├── res │   │   ├── check\_points │   │   ├── data │   │   │   ├── scan │   │   │   ├── geography │   │   │   ├── advising │   │   │   ├── geo\_vars.txt │   │   │   ├── adv\_vars.txt │   │   │   ├── iwslt14 │   │   │   ├── iwslt15 │   │   │   ├── prepare-iwslt14.sh │   │   │   └── prepare-iwslt15.sh │   │   ├── log │   │   └── result │   ├── src │   │   ├── models │   │   └── utils │   └── train.py └── requirements.txt ```  ## Dependencies + python >= 3.10.6 + tqdm >= 4.64.1 + numpy >= 1.23.4 + torch >= 1.13.0  ## Data All datasets can be downloaded \[here\](https://drive.google.com/drive/folders/19vFBn5C-nTdjxMeuMgw-BvsPNsLF6DpV?
4-1	398-399	\[	_	_
4-2	399-400	\[	_	_
4-3	400-405	arXiv	_	_
4-4	405-406	\]	_	_
4-5	406-407	(	_	_
4-6	407-412	https	_	_
4-7	412-413	:	_	_
4-8	413-414	/	_	_
4-9	414-415	/	_	_
4-10	415-424	arxiv.org	_	_
4-11	424-425	/	_	_
4-12	425-428	abs	_	_
4-13	428-429	/	_	_
4-14	429-439	2003.06658	_	_
4-15	439-440	)	_	_
4-16	440-441	\]	_	_
4-17	442-443	\[	_	_
4-18	443-444	\[	_	_
4-19	444-450	Poster	_	_
4-20	450-451	\]	_	_
4-21	451-452	(	_	_
4-22	452-457	https	_	_
4-23	457-458	:	_	_
4-24	458-459	/	_	_
4-25	459-460	/	_	_
4-26	460-477	www.shininglab.ai	_	_
4-27	477-478	/	_	_
4-28	478-484	assets	_	_
4-29	484-485	/	_	_
4-30	485-492	posters	_	_
4-31	492-493	/	_	_
4-32	493-500	Revisit	_	_
4-33	500-501	%	_	_
4-34	501-513	20Systematic	_	_
4-35	513-514	%	_	_
4-36	514-530	20Generalization	_	_
4-37	530-531	%	_	_
4-38	531-536	20via	_	_
4-39	536-537	%	_	_
4-40	537-549	20Meaningful	_	_
4-41	549-550	%	_	_
4-42	550-564	20Learning.pdf	_	_
4-43	564-565	)	_	_
4-44	565-566	\]	_	_
4-45	568-569	#	_	_
4-46	569-570	#	_	_
4-47	571-580	Directory	_	_
4-48	581-582	+	_	_
4-49	583-584	\*	_	_
4-50	584-585	\*	_	_
4-51	585-589	main	_	_
4-52	589-590	/	_	_
4-53	590-599	config.py	_	_
4-54	599-600	\*	_	_
4-55	600-601	\*	_	_
4-56	602-603	-	_	_
4-57	604-618	Configurations	_	_
4-58	619-620	+	_	_
4-59	621-622	\*	_	_
4-60	622-623	\*	_	_
4-61	623-627	main	_	_
4-62	627-628	/	_	_
4-63	628-631	res	_	_
4-64	631-632	\*	_	_
4-65	632-633	\*	_	_
4-66	634-635	-	_	_
4-67	636-645	Resources	_	_
4-68	646-655	including	_	_
4-69	656-661	model	_	_
4-70	662-667	check	_	_
4-71	668-674	points	_	_
4-72	674-675	,	_	_
4-73	676-684	datasets	_	_
4-74	684-685	,	_	_
4-75	686-696	experiment	_	_
4-76	697-704	records	_	_
4-77	704-705	,	_	_
4-78	706-709	and	_	_
4-79	710-717	results	_	_
4-80	718-719	+	_	_
4-81	720-721	\*	_	_
4-82	721-722	\*	_	_
4-83	722-726	main	_	_
4-84	726-727	/	_	_
4-85	727-730	src	_	_
4-86	730-731	\*	_	_
4-87	731-732	\*	_	_
4-88	733-734	-	_	_
4-89	735-741	Source	_	_
4-90	742-746	code	_	_
4-91	747-756	including	_	_
4-92	757-762	model	_	_
4-93	763-773	structures	_	_
4-94	774-777	and	_	_
4-95	778-785	utility	_	_
4-96	786-795	functions	_	_
4-97	796-797	`	_	_
4-98	797-798	`	_	_
4-99	798-799	`	_	_
4-100	800-849	Systematic-Generalization-via-Meaningful-Learning	_	_
4-101	850-851	├	_	_
4-102	851-852	─	_	_
4-103	852-853	─	_	_
4-104	854-863	README.md	_	_
4-105	864-865	├	_	_
4-106	865-866	─	_	_
4-107	866-867	─	_	_
4-108	868-872	main	_	_
4-109	873-874	│	_	_
4-110	877-878	├	_	_
4-111	878-879	─	_	_
4-112	879-880	─	_	_
4-113	881-890	config.py	_	_
4-114	891-892	│	_	_
4-115	895-896	├	_	_
4-116	896-897	─	_	_
4-117	897-898	─	_	_
4-118	899-902	res	_	_
4-119	903-904	│	_	_
4-120	907-908	│	_	_
4-121	911-912	├	_	_
4-122	912-913	─	_	_
4-123	913-914	─	_	_
4-124	915-927	check\_points	_	_
4-125	928-929	│	_	_
4-126	932-933	│	_	_
4-127	936-937	├	_	_
4-128	937-938	─	_	_
4-129	938-939	─	_	_
4-130	940-944	data	_	_
4-131	945-946	│	_	_
4-132	949-950	│	_	_
4-133	953-954	│	_	_
4-134	957-958	├	_	_
4-135	958-959	─	_	_
4-136	959-960	─	_	_
4-137	961-965	scan	_	_
4-138	966-967	│	_	_
4-139	970-971	│	_	_
4-140	974-975	│	_	_
4-141	978-979	├	_	_
4-142	979-980	─	_	_
4-143	980-981	─	_	_
4-144	982-991	geography	_	_
4-145	992-993	│	_	_
4-146	996-997	│	_	_
4-147	1000-1001	│	_	_
4-148	1004-1005	├	_	_
4-149	1005-1006	─	_	_
4-150	1006-1007	─	_	_
4-151	1008-1016	advising	_	_
4-152	1017-1018	│	_	_
4-153	1021-1022	│	_	_
4-154	1025-1026	│	_	_
4-155	1029-1030	├	_	_
4-156	1030-1031	─	_	_
4-157	1031-1032	─	_	_
4-158	1033-1045	geo\_vars.txt	_	_
4-159	1046-1047	│	_	_
4-160	1050-1051	│	_	_
4-161	1054-1055	│	_	_
4-162	1058-1059	├	_	_
4-163	1059-1060	─	_	_
4-164	1060-1061	─	_	_
4-165	1062-1074	adv\_vars.txt	_	_
4-166	1075-1076	│	_	_
4-167	1079-1080	│	_	_
4-168	1083-1084	│	_	_
4-169	1087-1088	├	_	_
4-170	1088-1089	─	_	_
4-171	1089-1090	─	_	_
4-172	1091-1098	iwslt14	_	_
4-173	1099-1100	│	_	_
4-174	1103-1104	│	_	_
4-175	1107-1108	│	_	_
4-176	1111-1112	├	_	_
4-177	1112-1113	─	_	_
4-178	1113-1114	─	_	_
4-179	1115-1122	iwslt15	_	_
4-180	1123-1124	│	_	_
4-181	1127-1128	│	_	_
4-182	1131-1132	│	_	_
4-183	1135-1136	├	_	_
4-184	1136-1137	─	_	_
4-185	1137-1138	─	_	_
4-186	1139-1154	prepare-iwslt14	_	_
4-187	1154-1155	.	_	_
4-188	1155-1157	sh	_	_
4-189	1158-1159	│	_	_
4-190	1162-1163	│	_	_
4-191	1166-1167	│	_	_
4-192	1170-1171	└	_	_
4-193	1171-1172	─	_	_
4-194	1172-1173	─	_	_
4-195	1174-1189	prepare-iwslt15	_	_
4-196	1189-1190	.	_	_
4-197	1190-1192	sh	_	_
4-198	1193-1194	│	_	_
4-199	1197-1198	│	_	_
4-200	1201-1202	├	_	_
4-201	1202-1203	─	_	_
4-202	1203-1204	─	_	_
4-203	1205-1208	log	_	_
4-204	1209-1210	│	_	_
4-205	1213-1214	│	_	_
4-206	1217-1218	└	_	_
4-207	1218-1219	─	_	_
4-208	1219-1220	─	_	_
4-209	1221-1227	result	_	_
4-210	1228-1229	│	_	_
4-211	1232-1233	├	_	_
4-212	1233-1234	─	_	_
4-213	1234-1235	─	_	_
4-214	1236-1239	src	_	_
4-215	1240-1241	│	_	_
4-216	1244-1245	│	_	_
4-217	1248-1249	├	_	_
4-218	1249-1250	─	_	_
4-219	1250-1251	─	_	_
4-220	1252-1258	models	_	_
4-221	1259-1260	│	_	_
4-222	1263-1264	│	_	_
4-223	1267-1268	└	_	_
4-224	1268-1269	─	_	_
4-225	1269-1270	─	_	_
4-226	1271-1276	utils	_	_
4-227	1277-1278	│	_	_
4-228	1281-1282	└	_	_
4-229	1282-1283	─	_	_
4-230	1283-1284	─	_	_
4-231	1285-1293	train.py	_	_
4-232	1294-1295	└	_	_
4-233	1295-1296	─	_	_
4-234	1296-1297	─	_	_
4-235	1298-1314	requirements.txt	_	_
4-236	1315-1316	`	_	_
4-237	1316-1317	`	_	_
4-238	1317-1318	`	_	_
4-239	1320-1321	#	_	_
4-240	1321-1322	#	_	_
4-241	1323-1335	Dependencies	_	_
4-242	1336-1337	+	_	_
4-243	1338-1344	python	_	_
4-244	1345-1346	>	_	_
4-245	1346-1347	=	_	_
4-246	1348-1354	3.10.6	_	_
4-247	1355-1356	+	_	_
4-248	1357-1361	tqdm	_	_
4-249	1362-1363	>	_	_
4-250	1363-1364	=	_	_
4-251	1365-1371	4.64.1	_	_
4-252	1372-1373	+	_	_
4-253	1374-1379	numpy	_	_
4-254	1380-1381	>	_	_
4-255	1381-1382	=	_	_
4-256	1383-1389	1.23.4	_	_
4-257	1390-1391	+	_	_
4-258	1392-1397	torch	_	_
4-259	1398-1399	>	_	_
4-260	1399-1400	=	_	_
4-261	1401-1407	1.13.0	_	_
4-262	1409-1410	#	_	_
4-263	1410-1411	#	_	_
4-264	1412-1416	Data	_	_
4-265	1417-1420	All	_	_
4-266	1421-1429	datasets	_	_
4-267	1430-1433	can	_	_
4-268	1434-1436	be	_	_
4-269	1437-1447	downloaded	_	_
4-270	1448-1449	\[	_	_
4-271	1449-1453	here	_	_
4-272	1453-1454	\]	_	_
4-273	1454-1455	(	_	_
4-274	1455-1460	https	_	_
4-275	1460-1461	:	_	_
4-276	1461-1462	/	_	_
4-277	1462-1463	/	_	_
4-278	1463-1479	drive.google.com	_	_
4-279	1479-1480	/	_	_
4-280	1480-1485	drive	_	_
4-281	1485-1486	/	_	_
4-282	1486-1493	folders	_	_
4-283	1493-1494	/	_	_
4-284	1494-1527	19vFBn5C-nTdjxMeuMgw-BvsPNsLF6DpV	_	_
4-285	1527-1528	?	_	_

#Text=usp=sharing) and should be placed under \*\*main/res/data\*\* according to specific tasks.
5-1	1528-1531	usp	_	_
5-2	1531-1532	=	_	_
5-3	1532-1539	sharing	_	_
5-4	1539-1540	)	_	_
5-5	1541-1544	and	_	_
5-6	1545-1551	should	_	_
5-7	1552-1554	be	_	_
5-8	1555-1561	placed	_	_
5-9	1562-1567	under	_	_
5-10	1568-1569	\*	_	_
5-11	1569-1570	\*	_	_
5-12	1570-1574	main	_	_
5-13	1574-1575	/	_	_
5-14	1575-1578	res	_	_
5-15	1578-1579	/	_	_
5-16	1579-1583	data	_	_
5-17	1583-1584	\*	_	_
5-18	1584-1585	\*	_	_
5-19	1586-1595	according	_	_
5-20	1596-1598	to	_	_
5-21	1599-1607	specific	_	_
5-22	1608-1613	tasks	_	_
5-23	1613-1614	.	_	_

#Text=Please refer to \[text2sql-data\](https://github.com/jkkummerfeld/text2sql-data/tree/master/data) for details. \* main/res/data/scan \* main/res/data/geography \* main/res/data/advising  ### Notes + main/res/data/iwslt14 - both vocabulary augmentation set and the entire dataset for IWSLT14 + main/res/data/iwslt15 - both vocabulary augmentation set and the entire dataset for IWSLT15 + main/res/data/prepare-iwslt14.sh - \[fairseq\](https://github.com/facebookresearch/fairseq) preprocess script for IWSLT14 + main/res/data/prepare-iwslt15.sh - \[fairseq\](https://github.com/facebookresearch/fairseq) preprocess script for IWSLT15 + main/res/data/geo\_vars.txt - the entity augmentation set for Grography + main/res/data/adv\_vars.txt - the entity augmentation set for Advising  ## Setup Please ensure required packages are already installed.
6-1	1615-1621	Please	_	_
6-2	1622-1627	refer	_	_
6-3	1628-1630	to	_	_
6-4	1631-1632	\[	_	_
6-5	1632-1645	text2sql-data	_	_
6-6	1645-1646	\]	_	_
6-7	1646-1647	(	_	_
6-8	1647-1652	https	_	_
6-9	1652-1653	:	_	_
6-10	1653-1654	/	_	_
6-11	1654-1655	/	_	_
6-12	1655-1665	github.com	_	_
6-13	1665-1666	/	_	_
6-14	1666-1678	jkkummerfeld	_	_
6-15	1678-1679	/	_	_
6-16	1679-1692	text2sql-data	_	_
6-17	1692-1693	/	_	_
6-18	1693-1697	tree	_	_
6-19	1697-1698	/	_	_
6-20	1698-1704	master	_	_
6-21	1704-1705	/	_	_
6-22	1705-1709	data	_	_
6-23	1709-1710	)	_	_
6-24	1711-1714	for	_	_
6-25	1715-1722	details	_	_
6-26	1722-1723	.	_	_
6-27	1724-1725	\*	_	_
6-28	1726-1730	main	_	_
6-29	1730-1731	/	_	_
6-30	1731-1734	res	_	_
6-31	1734-1735	/	_	_
6-32	1735-1739	data	_	_
6-33	1739-1740	/	_	_
6-34	1740-1744	scan	_	_
6-35	1745-1746	\*	_	_
6-36	1747-1751	main	_	_
6-37	1751-1752	/	_	_
6-38	1752-1755	res	_	_
6-39	1755-1756	/	_	_
6-40	1756-1760	data	_	_
6-41	1760-1761	/	_	_
6-42	1761-1770	geography	_	_
6-43	1771-1772	\*	_	_
6-44	1773-1777	main	_	_
6-45	1777-1778	/	_	_
6-46	1778-1781	res	_	_
6-47	1781-1782	/	_	_
6-48	1782-1786	data	_	_
6-49	1786-1787	/	_	_
6-50	1787-1795	advising	_	_
6-51	1797-1798	#	_	_
6-52	1798-1799	#	_	_
6-53	1799-1800	#	_	_
6-54	1801-1806	Notes	_	_
6-55	1807-1808	+	_	_
6-56	1809-1813	main	_	_
6-57	1813-1814	/	_	_
6-58	1814-1817	res	_	_
6-59	1817-1818	/	_	_
6-60	1818-1822	data	_	_
6-61	1822-1823	/	_	_
6-62	1823-1830	iwslt14	_	_
6-63	1831-1832	-	_	_
6-64	1833-1837	both	_	_
6-65	1838-1848	vocabulary	_	_
6-66	1849-1861	augmentation	_	_
6-67	1862-1865	set	_	_
6-68	1866-1869	and	_	_
6-69	1870-1873	the	_	_
6-70	1874-1880	entire	_	_
6-71	1881-1888	dataset	_	_
6-72	1889-1892	for	_	_
6-73	1893-1900	IWSLT14	_	_
6-74	1901-1902	+	_	_
6-75	1903-1907	main	_	_
6-76	1907-1908	/	_	_
6-77	1908-1911	res	_	_
6-78	1911-1912	/	_	_
6-79	1912-1916	data	_	_
6-80	1916-1917	/	_	_
6-81	1917-1924	iwslt15	_	_
6-82	1925-1926	-	_	_
6-83	1927-1931	both	_	_
6-84	1932-1942	vocabulary	_	_
6-85	1943-1955	augmentation	_	_
6-86	1956-1959	set	_	_
6-87	1960-1963	and	_	_
6-88	1964-1967	the	_	_
6-89	1968-1974	entire	_	_
6-90	1975-1982	dataset	_	_
6-91	1983-1986	for	_	_
6-92	1987-1994	IWSLT15	_	_
6-93	1995-1996	+	_	_
6-94	1997-2001	main	_	_
6-95	2001-2002	/	_	_
6-96	2002-2005	res	_	_
6-97	2005-2006	/	_	_
6-98	2006-2010	data	_	_
6-99	2010-2011	/	_	_
6-100	2011-2026	prepare-iwslt14	_	_
6-101	2026-2027	.	_	_
6-102	2027-2029	sh	_	_
6-103	2030-2031	-	_	_
6-104	2032-2033	\[	_	_
6-105	2033-2040	fairseq	_	_
6-106	2040-2041	\]	_	_
6-107	2041-2042	(	_	_
6-108	2042-2047	https	_	_
6-109	2047-2048	:	_	_
6-110	2048-2049	/	_	_
6-111	2049-2050	/	_	_
6-112	2050-2060	github.com	_	_
6-113	2060-2061	/	_	_
6-114	2061-2077	facebookresearch	_	_
6-115	2077-2078	/	_	_
6-116	2078-2085	fairseq	_	_
6-117	2085-2086	)	_	_
6-118	2087-2097	preprocess	_	_
6-119	2098-2104	script	_	_
6-120	2105-2108	for	_	_
6-121	2109-2116	IWSLT14	_	_
6-122	2117-2118	+	_	_
6-123	2119-2123	main	_	_
6-124	2123-2124	/	_	_
6-125	2124-2127	res	_	_
6-126	2127-2128	/	_	_
6-127	2128-2132	data	_	_
6-128	2132-2133	/	_	_
6-129	2133-2148	prepare-iwslt15	_	_
6-130	2148-2149	.	_	_
6-131	2149-2151	sh	_	_
6-132	2152-2153	-	_	_
6-133	2154-2155	\[	_	_
6-134	2155-2162	fairseq	_	_
6-135	2162-2163	\]	_	_
6-136	2163-2164	(	_	_
6-137	2164-2169	https	_	_
6-138	2169-2170	:	_	_
6-139	2170-2171	/	_	_
6-140	2171-2172	/	_	_
6-141	2172-2182	github.com	_	_
6-142	2182-2183	/	_	_
6-143	2183-2199	facebookresearch	_	_
6-144	2199-2200	/	_	_
6-145	2200-2207	fairseq	_	_
6-146	2207-2208	)	_	_
6-147	2209-2219	preprocess	_	_
6-148	2220-2226	script	_	_
6-149	2227-2230	for	_	_
6-150	2231-2238	IWSLT15	_	_
6-151	2239-2240	+	_	_
6-152	2241-2245	main	_	_
6-153	2245-2246	/	_	_
6-154	2246-2249	res	_	_
6-155	2249-2250	/	_	_
6-156	2250-2254	data	_	_
6-157	2254-2255	/	_	_
6-158	2255-2267	geo\_vars.txt	_	_
6-159	2268-2269	-	_	_
6-160	2270-2273	the	_	_
6-161	2274-2280	entity	_	_
6-162	2281-2293	augmentation	_	_
6-163	2294-2297	set	_	_
6-164	2298-2301	for	_	_
6-165	2302-2311	Grography	_	_
6-166	2312-2313	+	_	_
6-167	2314-2318	main	_	_
6-168	2318-2319	/	_	_
6-169	2319-2322	res	_	_
6-170	2322-2323	/	_	_
6-171	2323-2327	data	_	_
6-172	2327-2328	/	_	_
6-173	2328-2340	adv\_vars.txt	_	_
6-174	2341-2342	-	_	_
6-175	2343-2346	the	_	_
6-176	2347-2353	entity	_	_
6-177	2354-2366	augmentation	_	_
6-178	2367-2370	set	_	_
6-179	2371-2374	for	_	_
6-180	2375-2383	Advising	_	_
6-181	2385-2386	#	_	_
6-182	2386-2387	#	_	_
6-183	2388-2393	Setup	_	_
6-184	2394-2400	Please	_	_
6-185	2401-2407	ensure	_	_
6-186	2408-2416	required	_	_
6-187	2417-2425	packages	_	_
6-188	2426-2429	are	_	_
6-189	2430-2437	already	_	_
6-190	2438-2447	installed	_	_
6-191	2447-2448	.	_	_

#Text=A virtual environment is recommended. ``` $ cd Systematic-Generalization-via-Meaningful-Learning $ cd main $ pip install pip --upgrade $ pip install -r requirements.txt ```  ## Run Before training, please double check \*\*config.py\*\* to ensure training configurations. ``` $ vim config.py $ python train.py ```  ## Outputs If everything goes well, there should be a similar progressing shown as below. ``` Initialize...
7-1	2449-2450	A	_	_
7-2	2451-2458	virtual	_	_
7-3	2459-2470	environment	_	_
7-4	2471-2473	is	_	_
7-5	2474-2485	recommended	_	_
7-6	2485-2486	.	_	_
7-7	2487-2488	`	_	_
7-8	2488-2489	`	_	_
7-9	2489-2490	`	_	_
7-10	2491-2492	$	_	_
7-11	2493-2495	cd	_	_
7-12	2496-2545	Systematic-Generalization-via-Meaningful-Learning	_	_
7-13	2546-2547	$	_	_
7-14	2548-2550	cd	_	_
7-15	2551-2555	main	_	_
7-16	2556-2557	$	_	_
7-17	2558-2561	pip	_	_
7-18	2562-2569	install	_	_
7-19	2570-2573	pip	_	_
7-20	2574-2575	-	_	_
7-21	2575-2576	-	_	_
7-22	2576-2583	upgrade	_	_
7-23	2584-2585	$	_	_
7-24	2586-2589	pip	_	_
7-25	2590-2597	install	_	_
7-26	2598-2599	-	_	_
7-27	2599-2600	r	_	_
7-28	2601-2617	requirements.txt	_	_
7-29	2618-2619	`	_	_
7-30	2619-2620	`	_	_
7-31	2620-2621	`	_	_
7-32	2623-2624	#	_	_
7-33	2624-2625	#	_	_
7-34	2626-2629	Run	_	_
7-35	2630-2636	Before	_	_
7-36	2637-2645	training	_	_
7-37	2645-2646	,	_	_
7-38	2647-2653	please	_	_
7-39	2654-2660	double	_	_
7-40	2661-2666	check	_	_
7-41	2667-2668	\*	_	_
7-42	2668-2669	\*	_	_
7-43	2669-2678	config.py	_	_
7-44	2678-2679	\*	_	_
7-45	2679-2680	\*	_	_
7-46	2681-2683	to	_	_
7-47	2684-2690	ensure	_	_
7-48	2691-2699	training	_	_
7-49	2700-2714	configurations	_	_
7-50	2714-2715	.	_	_
7-51	2716-2717	`	_	_
7-52	2717-2718	`	_	_
7-53	2718-2719	`	_	_
7-54	2720-2721	$	_	_
7-55	2722-2725	vim	_	_
7-56	2726-2735	config.py	_	_
7-57	2736-2737	$	_	_
7-58	2738-2744	python	_	_
7-59	2745-2753	train.py	_	_
7-60	2754-2755	`	_	_
7-61	2755-2756	`	_	_
7-62	2756-2757	`	_	_
7-63	2759-2760	#	_	_
7-64	2760-2761	#	_	_
7-65	2762-2769	Outputs	_	_
7-66	2770-2772	If	_	_
7-67	2773-2783	everything	_	_
7-68	2784-2788	goes	_	_
7-69	2789-2793	well	_	_
7-70	2793-2794	,	_	_
7-71	2795-2800	there	_	_
7-72	2801-2807	should	_	_
7-73	2808-2810	be	_	_
7-74	2811-2812	a	_	_
7-75	2813-2820	similar	_	_
7-76	2821-2832	progressing	_	_
7-77	2833-2838	shown	_	_
7-78	2839-2841	as	_	_
7-79	2842-2847	below	_	_
7-80	2847-2848	.	_	_
7-81	2849-2850	`	_	_
7-82	2850-2851	`	_	_
7-83	2851-2852	`	_	_
7-84	2853-2863	Initialize	_	_
7-85	2863-2864	.	_	_
7-86	2864-2865	.	_	_
7-87	2865-2866	.	_	_

#Text=\*Configuration\* model name: bi\_lstm\_rnn\_att trainable parameters:5,027,337 ...
8-1	2867-2868	\*	_	_
8-2	2868-2881	Configuration	_	_
8-3	2881-2882	\*	_	_
8-4	2883-2888	model	_	_
8-5	2889-2893	name	_	_
8-6	2893-2894	:	_	_
8-7	2895-2910	bi\_lstm\_rnn\_att	_	_
8-8	2911-2920	trainable	_	_
8-9	2921-2931	parameters	_	_
8-10	2931-2932	:	_	_
8-11	2932-2941	5,027,337	_	_
8-12	2942-2943	.	_	_
8-13	2943-2944	.	_	_
8-14	2944-2945	.	_	_

#Text=Training...
9-1	2946-2954	Training	_	_
9-2	2954-2955	.	_	_
9-3	2955-2956	.	_	_
9-4	2956-2957	.	_	_

#Text=Loss:1.7061: 100%\|██████████\| 132/132 \[00:14<00:00,  9.37it/s\] Train Epoch 0 Total Step 132 Loss:1.9179 ... ```  ## NMT We use \[fairseq\](https://github.com/facebookresearch/fairseq) for NMT tasks in Section 4.1.
10-1	2958-2962	Loss	_	_
10-2	2962-2963	:	_	_
10-3	2963-2969	1.7061	_	_
10-4	2969-2970	:	_	_
10-5	2971-2975	100%	_	_
10-6	2975-2976	\|	_	_
10-7	2976-2977	█	_	_
10-8	2977-2978	█	_	_
10-9	2978-2979	█	_	_
10-10	2979-2980	█	_	_
10-11	2980-2981	█	_	_
10-12	2981-2982	█	_	_
10-13	2982-2983	█	_	_
10-14	2983-2984	█	_	_
10-15	2984-2985	█	_	_
10-16	2985-2986	█	_	_
10-17	2986-2987	\|	_	_
10-18	2988-2991	132	_	_
10-19	2991-2992	/	_	_
10-20	2992-2995	132	_	_
10-21	2996-2997	\[	_	_
10-22	2997-2999	00	_	_
10-23	2999-3000	:	_	_
10-24	3000-3002	14	_	_
10-25	3002-3003	<	_	_
10-26	3003-3005	00	_	_
10-27	3005-3006	:	_	_
10-28	3006-3008	00	_	_
10-29	3008-3009	,	_	_
10-30	3011-3017	9.37it	_	_
10-31	3017-3018	/	_	_
10-32	3018-3019	s	_	_
10-33	3019-3020	\]	_	_
10-34	3021-3026	Train	_	_
10-35	3027-3032	Epoch	_	_
10-36	3033-3034	0	_	_
10-37	3035-3040	Total	_	_
10-38	3041-3045	Step	_	_
10-39	3046-3049	132	_	_
10-40	3050-3054	Loss	_	_
10-41	3054-3055	:	_	_
10-42	3055-3061	1.9179	_	_
10-43	3062-3063	.	_	_
10-44	3063-3064	.	_	_
10-45	3064-3065	.	_	_
10-46	3066-3067	`	_	_
10-47	3067-3068	`	_	_
10-48	3068-3069	`	_	_
10-49	3071-3072	#	_	_
10-50	3072-3073	#	_	_
10-51	3074-3077	NMT	_	_
10-52	3078-3080	We	_	_
10-53	3081-3084	use	_	_
10-54	3085-3086	\[	_	_
10-55	3086-3093	fairseq	_	_
10-56	3093-3094	\]	_	_
10-57	3094-3095	(	_	_
10-58	3095-3100	https	_	_
10-59	3100-3101	:	_	_
10-60	3101-3102	/	_	_
10-61	3102-3103	/	_	_
10-62	3103-3113	github.com	_	_
10-63	3113-3114	/	_	_
10-64	3114-3130	facebookresearch	_	_
10-65	3130-3131	/	_	_
10-66	3131-3138	fairseq	_	_
10-67	3138-3139	)	_	_
10-68	3140-3143	for	_	_
10-69	3144-3147	NMT	_	_
10-70	3148-3153	tasks	_	_
10-71	3154-3156	in	_	_
10-72	3157-3164	Section	_	_
10-73	3165-3168	4.1	_	_
10-74	3168-3169	.	_	_

#Text=Please find the example pipeline shown below.  ### Models + LSTM - lstm\_luong\_wmt\_en\_de + Transformer - transformer\_iwslt\_de\_en + Dynamic Conv. - lightconv\_iwslt\_de\_en  ### BPE ``` examples/translation/subword-nmt/apply\_bpe.py -c iwslt14.tokenized.de-en/code <iwslt14.tokenized.de-en/iwslt14.vocab.en> iwslt14.tokenized.de-en/iwslt14.vocab.en.bpe ```  ### Preprocessing ``` TEXT=examples/translation/iwslt14.tokenized.de-en fairseq-preprocess --source-lang en --target-lang de \\     --trainpref $TEXT/train --validpref $TEXT/valid --testpref $TEXT/test \\     --destdir data-bin/iwslt14.tokenized.de-en \\     --workers 20 ```  ### Training LSTM ``` fairseq-train \\     data-bin/iwslt14.tokenized.de-en \\     -s en -t de \\     --arch lstm\_luong\_wmt\_en\_de --share-decoder-input-output-embed \\     --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\     --lr 0.001 --lr-scheduler inverse\_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 \\     --dropout 0.2 --weight-decay 0.0 \\     --encoder-dropout-out 0.2 --decoder-dropout-out 0.2 \\     --criterion label\_smoothed\_cross\_entropy --label-smoothing 0.1 \\     --max-tokens 32768 \\     --fp16 --no-epoch-checkpoints >train.log 2>&1 & ``` Transformer ``` fairseq-train \\     data-bin/iwslt14.tokenized.de-en \\     -s en -t de \\     --arch transformer\_iwslt\_de\_en --share-decoder-input-output-embed \\     --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\     --lr 0.001 --lr-scheduler inverse\_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 \\     --dropout 0.3 --attention-dropout 0.1 --weight-decay 0.0 \\     --criterion label\_smoothed\_cross\_entropy --label-smoothing 0.1 \\     --max-tokens 32768 \\     --fp16 --no-epoch-checkpoints >train.log 2>&1 & ``` Dynamic Conv. ``` fairseq-train \\     data-bin/iwslt14.tokenized.de-en \\     -s en -t de \\     --arch lightconv\_iwslt\_de\_en \\     --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\     --lr 0.001 --lr-scheduler inverse\_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 \\     --dropout 0.1 --weight-decay 0.0 \\     --criterion label\_smoothed\_cross\_entropy --label-smoothing 0.1 \\     --max-tokens 32768 \\     --fp16 --no-epoch-checkpoints >train.log 2>&1 & ```  ### Evaluation BLEU ``` fairseq-generate data-bin/iwslt14.tokenized.de-en \\     --path checkpoints/checkpoint\_best.pt \\     -s en -t de \\     --batch-size 128 --beam 5 --lenpen 0.6 \\     --scoring bleu --remove-bpe --cpu >bleu.log 2>&1 & ``` ScareBLEU ``` fairseq-generate data-bin/iwslt14.tokenized.de-en \\     --path checkpoints/checkpoint\_best.pt \\     -s en -t de \\     --batch-size 128 --beam 5 --lenpen 0.6 \\     --scoring sacrebleu --remove-bpe --cpu >sacrebleu.log 2>&1 & ```  ## Authors \* \*\*Ning Shi\*\* - mrshininnnnn@gmail.com  ## BibTex ``` @inproceedings{shi-etal-2022-revisit,     title = "Revisit Systematic Generalization via Meaningful Learning",     author = "Shi, Ning  and       Wang, Boxin  and       Wang, Wei  and       Liu, Xiangyu  and       Lin, Zhouhan",     booktitle = "Proceedings of the Fifth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP",     month = dec,     year = "2022",     address = "Abu Dhabi, United Arab Emirates (Hybrid)",     publisher = "Association for Computational Linguistics",     url = "https://aclanthology.org/2022.blackboxnlp-1.6",     pages = "62--79",     abstract = "Humans can systematically generalize to novel compositions of existing concepts.
11-1	3170-3176	Please	_	_
11-2	3177-3181	find	_	_
11-3	3182-3185	the	_	_
11-4	3186-3193	example	_	_
11-5	3194-3202	pipeline	_	_
11-6	3203-3208	shown	_	_
11-7	3209-3214	below	_	_
11-8	3214-3215	.	_	_
11-9	3217-3218	#	_	_
11-10	3218-3219	#	_	_
11-11	3219-3220	#	_	_
11-12	3221-3227	Models	_	_
11-13	3228-3229	+	_	_
11-14	3230-3234	LSTM	_	_
11-15	3235-3236	-	_	_
11-16	3237-3257	lstm\_luong\_wmt\_en\_de	_	_
11-17	3258-3259	+	_	_
11-18	3260-3271	Transformer	_	_
11-19	3272-3273	-	_	_
11-20	3274-3297	transformer\_iwslt\_de\_en	_	_
11-21	3298-3299	+	_	_
11-22	3300-3307	Dynamic	_	_
11-23	3308-3312	Conv	_	_
11-24	3312-3313	.	_	_
11-25	3314-3315	-	_	_
11-26	3316-3337	lightconv\_iwslt\_de\_en	_	_
11-27	3339-3340	#	_	_
11-28	3340-3341	#	_	_
11-29	3341-3342	#	_	_
11-30	3343-3346	BPE	_	_
11-31	3347-3348	`	_	_
11-32	3348-3349	`	_	_
11-33	3349-3350	`	_	_
11-34	3351-3359	examples	_	_
11-35	3359-3360	/	_	_
11-36	3360-3371	translation	_	_
11-37	3371-3372	/	_	_
11-38	3372-3383	subword-nmt	_	_
11-39	3383-3384	/	_	_
11-40	3384-3396	apply\_bpe.py	_	_
11-41	3397-3398	-	_	_
11-42	3398-3399	c	_	_
11-43	3400-3407	iwslt14	_	_
11-44	3407-3408	.	_	_
11-45	3408-3423	tokenized.de-en	_	_
11-46	3423-3424	/	_	_
11-47	3424-3428	code	_	_
11-48	3429-3430	<	_	_
11-49	3430-3437	iwslt14	_	_
11-50	3437-3438	.	_	_
11-51	3438-3453	tokenized.de-en	_	_
11-52	3453-3454	/	_	_
11-53	3454-3461	iwslt14	_	_
11-54	3461-3462	.	_	_
11-55	3462-3470	vocab.en	_	_
11-56	3470-3471	>	_	_
11-57	3472-3479	iwslt14	_	_
11-58	3479-3480	.	_	_
11-59	3480-3495	tokenized.de-en	_	_
11-60	3495-3496	/	_	_
11-61	3496-3503	iwslt14	_	_
11-62	3503-3504	.	_	_
11-63	3504-3516	vocab.en.bpe	_	_
11-64	3517-3518	`	_	_
11-65	3518-3519	`	_	_
11-66	3519-3520	`	_	_
11-67	3522-3523	#	_	_
11-68	3523-3524	#	_	_
11-69	3524-3525	#	_	_
11-70	3526-3539	Preprocessing	_	_
11-71	3540-3541	`	_	_
11-72	3541-3542	`	_	_
11-73	3542-3543	`	_	_
11-74	3544-3548	TEXT	_	_
11-75	3548-3549	=	_	_
11-76	3549-3557	examples	_	_
11-77	3557-3558	/	_	_
11-78	3558-3569	translation	_	_
11-79	3569-3570	/	_	_
11-80	3570-3577	iwslt14	_	_
11-81	3577-3578	.	_	_
11-82	3578-3593	tokenized.de-en	_	_
11-83	3594-3612	fairseq-preprocess	_	_
11-84	3613-3614	-	_	_
11-85	3614-3615	-	_	_
11-86	3615-3626	source-lang	_	_
11-87	3627-3629	en	_	_
11-88	3630-3631	-	_	_
11-89	3631-3632	-	_	_
11-90	3632-3643	target-lang	_	_
11-91	3644-3646	de	_	_
11-92	3647-3648	\\	_	_
11-93	3653-3654	-	_	_
11-94	3654-3655	-	_	_
11-95	3655-3664	trainpref	_	_
11-96	3665-3666	$	_	_
11-97	3666-3670	TEXT	_	_
11-98	3670-3671	/	_	_
11-99	3671-3676	train	_	_
11-100	3677-3678	-	_	_
11-101	3678-3679	-	_	_
11-102	3679-3688	validpref	_	_
11-103	3689-3690	$	_	_
11-104	3690-3694	TEXT	_	_
11-105	3694-3695	/	_	_
11-106	3695-3700	valid	_	_
11-107	3701-3702	-	_	_
11-108	3702-3703	-	_	_
11-109	3703-3711	testpref	_	_
11-110	3712-3713	$	_	_
11-111	3713-3717	TEXT	_	_
11-112	3717-3718	/	_	_
11-113	3718-3722	test	_	_
11-114	3723-3724	\\	_	_
11-115	3729-3730	-	_	_
11-116	3730-3731	-	_	_
11-117	3731-3738	destdir	_	_
11-118	3739-3747	data-bin	_	_
11-119	3747-3748	/	_	_
11-120	3748-3755	iwslt14	_	_
11-121	3755-3756	.	_	_
11-122	3756-3771	tokenized.de-en	_	_
11-123	3772-3773	\\	_	_
11-124	3778-3779	-	_	_
11-125	3779-3780	-	_	_
11-126	3780-3787	workers	_	_
11-127	3788-3790	20	_	_
11-128	3791-3792	`	_	_
11-129	3792-3793	`	_	_
11-130	3793-3794	`	_	_
11-131	3796-3797	#	_	_
11-132	3797-3798	#	_	_
11-133	3798-3799	#	_	_
11-134	3800-3808	Training	_	_
11-135	3809-3813	LSTM	_	_
11-136	3814-3815	`	_	_
11-137	3815-3816	`	_	_
11-138	3816-3817	`	_	_
11-139	3818-3831	fairseq-train	_	_
11-140	3832-3833	\\	_	_
11-141	3838-3846	data-bin	_	_
11-142	3846-3847	/	_	_
11-143	3847-3854	iwslt14	_	_
11-144	3854-3855	.	_	_
11-145	3855-3870	tokenized.de-en	_	_
11-146	3871-3872	\\	_	_
11-147	3877-3878	-	_	_
11-148	3878-3879	s	_	_
11-149	3880-3882	en	_	_
11-150	3883-3884	-	_	_
11-151	3884-3885	t	_	_
11-152	3886-3888	de	_	_
11-153	3889-3890	\\	_	_
11-154	3895-3896	-	_	_
11-155	3896-3897	-	_	_
11-156	3897-3901	arch	_	_
11-157	3902-3922	lstm\_luong\_wmt\_en\_de	_	_
11-158	3923-3924	-	_	_
11-159	3924-3925	-	_	_
11-160	3925-3957	share-decoder-input-output-embed	_	_
11-161	3958-3959	\\	_	_
11-162	3964-3965	-	_	_
11-163	3965-3966	-	_	_
11-164	3966-3975	optimizer	_	_
11-165	3976-3980	adam	_	_
11-166	3981-3982	-	_	_
11-167	3982-3983	-	_	_
11-168	3983-3993	adam-betas	_	_
11-169	3994-3995	'	_	_
11-170	3995-3996	(	_	_
11-171	3996-3999	0.9	_	_
11-172	3999-4000	,	_	_
11-173	4001-4005	0.98	_	_
11-174	4005-4006	)	_	_
11-175	4006-4007	'	_	_
11-176	4008-4009	-	_	_
11-177	4009-4010	-	_	_
11-178	4010-4019	clip-norm	_	_
11-179	4020-4023	0.0	_	_
11-180	4024-4025	\\	_	_
11-181	4030-4031	-	_	_
11-182	4031-4032	-	_	_
11-183	4032-4034	lr	_	_
11-184	4035-4040	0.001	_	_
11-185	4041-4042	-	_	_
11-186	4042-4043	-	_	_
11-187	4043-4055	lr-scheduler	_	_
11-188	4056-4068	inverse\_sqrt	_	_
11-189	4069-4070	-	_	_
11-190	4070-4071	-	_	_
11-191	4071-4085	warmup-updates	_	_
11-192	4086-4090	4000	_	_
11-193	4091-4092	-	_	_
11-194	4092-4093	-	_	_
11-195	4093-4107	warmup-init-lr	_	_
11-196	4108-4110	1e	_	_
11-197	4110-4111	-	_	_
11-198	4111-4113	07	_	_
11-199	4114-4115	\\	_	_
11-200	4120-4121	-	_	_
11-201	4121-4122	-	_	_
11-202	4122-4129	dropout	_	_
11-203	4130-4133	0.2	_	_
11-204	4134-4135	-	_	_
11-205	4135-4136	-	_	_
11-206	4136-4148	weight-decay	_	_
11-207	4149-4152	0.0	_	_
11-208	4153-4154	\\	_	_
11-209	4159-4160	-	_	_
11-210	4160-4161	-	_	_
11-211	4161-4180	encoder-dropout-out	_	_
11-212	4181-4184	0.2	_	_
11-213	4185-4186	-	_	_
11-214	4186-4187	-	_	_
11-215	4187-4206	decoder-dropout-out	_	_
11-216	4207-4210	0.2	_	_
11-217	4211-4212	\\	_	_
11-218	4217-4218	-	_	_
11-219	4218-4219	-	_	_
11-220	4219-4228	criterion	_	_
11-221	4229-4257	label\_smoothed\_cross\_entropy	_	_
11-222	4258-4259	-	_	_
11-223	4259-4260	-	_	_
11-224	4260-4275	label-smoothing	_	_
11-225	4276-4279	0.1	_	_
11-226	4280-4281	\\	_	_
11-227	4286-4287	-	_	_
11-228	4287-4288	-	_	_
11-229	4288-4298	max-tokens	_	_
11-230	4299-4304	32768	_	_
11-231	4305-4306	\\	_	_
11-232	4311-4312	-	_	_
11-233	4312-4313	-	_	_
11-234	4313-4317	fp16	_	_
11-235	4318-4319	-	_	_
11-236	4319-4320	-	_	_
11-237	4320-4340	no-epoch-checkpoints	_	_
11-238	4341-4342	>	_	_
11-239	4342-4351	train.log	_	_
11-240	4352-4353	2	_	_
11-241	4353-4354	>	_	_
11-242	4354-4355	&	_	_
11-243	4355-4356	1	_	_
11-244	4357-4358	&	_	_
11-245	4359-4360	`	_	_
11-246	4360-4361	`	_	_
11-247	4361-4362	`	_	_
11-248	4363-4374	Transformer	_	_
11-249	4375-4376	`	_	_
11-250	4376-4377	`	_	_
11-251	4377-4378	`	_	_
11-252	4379-4392	fairseq-train	_	_
11-253	4393-4394	\\	_	_
11-254	4399-4407	data-bin	_	_
11-255	4407-4408	/	_	_
11-256	4408-4415	iwslt14	_	_
11-257	4415-4416	.	_	_
11-258	4416-4431	tokenized.de-en	_	_
11-259	4432-4433	\\	_	_
11-260	4438-4439	-	_	_
11-261	4439-4440	s	_	_
11-262	4441-4443	en	_	_
11-263	4444-4445	-	_	_
11-264	4445-4446	t	_	_
11-265	4447-4449	de	_	_
11-266	4450-4451	\\	_	_
11-267	4456-4457	-	_	_
11-268	4457-4458	-	_	_
11-269	4458-4462	arch	_	_
11-270	4463-4486	transformer\_iwslt\_de\_en	_	_
11-271	4487-4488	-	_	_
11-272	4488-4489	-	_	_
11-273	4489-4521	share-decoder-input-output-embed	_	_
11-274	4522-4523	\\	_	_
11-275	4528-4529	-	_	_
11-276	4529-4530	-	_	_
11-277	4530-4539	optimizer	_	_
11-278	4540-4544	adam	_	_
11-279	4545-4546	-	_	_
11-280	4546-4547	-	_	_
11-281	4547-4557	adam-betas	_	_
11-282	4558-4559	'	_	_
11-283	4559-4560	(	_	_
11-284	4560-4563	0.9	_	_
11-285	4563-4564	,	_	_
11-286	4565-4569	0.98	_	_
11-287	4569-4570	)	_	_
11-288	4570-4571	'	_	_
11-289	4572-4573	-	_	_
11-290	4573-4574	-	_	_
11-291	4574-4583	clip-norm	_	_
11-292	4584-4587	0.0	_	_
11-293	4588-4589	\\	_	_
11-294	4594-4595	-	_	_
11-295	4595-4596	-	_	_
11-296	4596-4598	lr	_	_
11-297	4599-4604	0.001	_	_
11-298	4605-4606	-	_	_
11-299	4606-4607	-	_	_
11-300	4607-4619	lr-scheduler	_	_
11-301	4620-4632	inverse\_sqrt	_	_
11-302	4633-4634	-	_	_
11-303	4634-4635	-	_	_
11-304	4635-4649	warmup-updates	_	_
11-305	4650-4654	4000	_	_
11-306	4655-4656	-	_	_
11-307	4656-4657	-	_	_
11-308	4657-4671	warmup-init-lr	_	_
11-309	4672-4674	1e	_	_
11-310	4674-4675	-	_	_
11-311	4675-4677	07	_	_
11-312	4678-4679	\\	_	_
11-313	4684-4685	-	_	_
11-314	4685-4686	-	_	_
11-315	4686-4693	dropout	_	_
11-316	4694-4697	0.3	_	_
11-317	4698-4699	-	_	_
11-318	4699-4700	-	_	_
11-319	4700-4717	attention-dropout	_	_
11-320	4718-4721	0.1	_	_
11-321	4722-4723	-	_	_
11-322	4723-4724	-	_	_
11-323	4724-4736	weight-decay	_	_
11-324	4737-4740	0.0	_	_
11-325	4741-4742	\\	_	_
11-326	4747-4748	-	_	_
11-327	4748-4749	-	_	_
11-328	4749-4758	criterion	_	_
11-329	4759-4787	label\_smoothed\_cross\_entropy	_	_
11-330	4788-4789	-	_	_
11-331	4789-4790	-	_	_
11-332	4790-4805	label-smoothing	_	_
11-333	4806-4809	0.1	_	_
11-334	4810-4811	\\	_	_
11-335	4816-4817	-	_	_
11-336	4817-4818	-	_	_
11-337	4818-4828	max-tokens	_	_
11-338	4829-4834	32768	_	_
11-339	4835-4836	\\	_	_
11-340	4841-4842	-	_	_
11-341	4842-4843	-	_	_
11-342	4843-4847	fp16	_	_
11-343	4848-4849	-	_	_
11-344	4849-4850	-	_	_
11-345	4850-4870	no-epoch-checkpoints	_	_
11-346	4871-4872	>	_	_
11-347	4872-4881	train.log	_	_
11-348	4882-4883	2	_	_
11-349	4883-4884	>	_	_
11-350	4884-4885	&	_	_
11-351	4885-4886	1	_	_
11-352	4887-4888	&	_	_
11-353	4889-4890	`	_	_
11-354	4890-4891	`	_	_
11-355	4891-4892	`	_	_
11-356	4893-4900	Dynamic	_	_
11-357	4901-4905	Conv	_	_
11-358	4905-4906	.	_	_
11-359	4907-4908	`	_	_
11-360	4908-4909	`	_	_
11-361	4909-4910	`	_	_
11-362	4911-4924	fairseq-train	_	_
11-363	4925-4926	\\	_	_
11-364	4931-4939	data-bin	_	_
11-365	4939-4940	/	_	_
11-366	4940-4947	iwslt14	_	_
11-367	4947-4948	.	_	_
11-368	4948-4963	tokenized.de-en	_	_
11-369	4964-4965	\\	_	_
11-370	4970-4971	-	_	_
11-371	4971-4972	s	_	_
11-372	4973-4975	en	_	_
11-373	4976-4977	-	_	_
11-374	4977-4978	t	_	_
11-375	4979-4981	de	_	_
11-376	4982-4983	\\	_	_
11-377	4988-4989	-	_	_
11-378	4989-4990	-	_	_
11-379	4990-4994	arch	_	_
11-380	4995-5016	lightconv\_iwslt\_de\_en	_	_
11-381	5017-5018	\\	_	_
11-382	5023-5024	-	_	_
11-383	5024-5025	-	_	_
11-384	5025-5034	optimizer	_	_
11-385	5035-5039	adam	_	_
11-386	5040-5041	-	_	_
11-387	5041-5042	-	_	_
11-388	5042-5052	adam-betas	_	_
11-389	5053-5054	'	_	_
11-390	5054-5055	(	_	_
11-391	5055-5058	0.9	_	_
11-392	5058-5059	,	_	_
11-393	5060-5064	0.98	_	_
11-394	5064-5065	)	_	_
11-395	5065-5066	'	_	_
11-396	5067-5068	-	_	_
11-397	5068-5069	-	_	_
11-398	5069-5078	clip-norm	_	_
11-399	5079-5082	0.0	_	_
11-400	5083-5084	\\	_	_
11-401	5089-5090	-	_	_
11-402	5090-5091	-	_	_
11-403	5091-5093	lr	_	_
11-404	5094-5099	0.001	_	_
11-405	5100-5101	-	_	_
11-406	5101-5102	-	_	_
11-407	5102-5114	lr-scheduler	_	_
11-408	5115-5127	inverse\_sqrt	_	_
11-409	5128-5129	-	_	_
11-410	5129-5130	-	_	_
11-411	5130-5144	warmup-updates	_	_
11-412	5145-5149	4000	_	_
11-413	5150-5151	-	_	_
11-414	5151-5152	-	_	_
11-415	5152-5166	warmup-init-lr	_	_
11-416	5167-5169	1e	_	_
11-417	5169-5170	-	_	_
11-418	5170-5172	07	_	_
11-419	5173-5174	\\	_	_
11-420	5179-5180	-	_	_
11-421	5180-5181	-	_	_
11-422	5181-5188	dropout	_	_
11-423	5189-5192	0.1	_	_
11-424	5193-5194	-	_	_
11-425	5194-5195	-	_	_
11-426	5195-5207	weight-decay	_	_
11-427	5208-5211	0.0	_	_
11-428	5212-5213	\\	_	_
11-429	5218-5219	-	_	_
11-430	5219-5220	-	_	_
11-431	5220-5229	criterion	_	_
11-432	5230-5258	label\_smoothed\_cross\_entropy	_	_
11-433	5259-5260	-	_	_
11-434	5260-5261	-	_	_
11-435	5261-5276	label-smoothing	_	_
11-436	5277-5280	0.1	_	_
11-437	5281-5282	\\	_	_
11-438	5287-5288	-	_	_
11-439	5288-5289	-	_	_
11-440	5289-5299	max-tokens	_	_
11-441	5300-5305	32768	_	_
11-442	5306-5307	\\	_	_
11-443	5312-5313	-	_	_
11-444	5313-5314	-	_	_
11-445	5314-5318	fp16	_	_
11-446	5319-5320	-	_	_
11-447	5320-5321	-	_	_
11-448	5321-5341	no-epoch-checkpoints	_	_
11-449	5342-5343	>	_	_
11-450	5343-5352	train.log	_	_
11-451	5353-5354	2	_	_
11-452	5354-5355	>	_	_
11-453	5355-5356	&	_	_
11-454	5356-5357	1	_	_
11-455	5358-5359	&	_	_
11-456	5360-5361	`	_	_
11-457	5361-5362	`	_	_
11-458	5362-5363	`	_	_
11-459	5365-5366	#	_	_
11-460	5366-5367	#	_	_
11-461	5367-5368	#	_	_
11-462	5369-5379	Evaluation	_	_
11-463	5380-5384	BLEU	_	_
11-464	5385-5386	`	_	_
11-465	5386-5387	`	_	_
11-466	5387-5388	`	_	_
11-467	5389-5405	fairseq-generate	_	_
11-468	5406-5414	data-bin	_	_
11-469	5414-5415	/	_	_
11-470	5415-5422	iwslt14	_	_
11-471	5422-5423	.	_	_
11-472	5423-5438	tokenized.de-en	_	_
11-473	5439-5440	\\	_	_
11-474	5445-5446	-	_	_
11-475	5446-5447	-	_	_
11-476	5447-5451	path	_	_
11-477	5452-5463	checkpoints	_	_
11-478	5463-5464	/	_	_
11-479	5464-5482	checkpoint\_best.pt	_	_
11-480	5483-5484	\\	_	_
11-481	5489-5490	-	_	_
11-482	5490-5491	s	_	_
11-483	5492-5494	en	_	_
11-484	5495-5496	-	_	_
11-485	5496-5497	t	_	_
11-486	5498-5500	de	_	_
11-487	5501-5502	\\	_	_
11-488	5507-5508	-	_	_
11-489	5508-5509	-	_	_
11-490	5509-5519	batch-size	_	_
11-491	5520-5523	128	_	_
11-492	5524-5525	-	_	_
11-493	5525-5526	-	_	_
11-494	5526-5530	beam	_	_
11-495	5531-5532	5	_	_
11-496	5533-5534	-	_	_
11-497	5534-5535	-	_	_
11-498	5535-5541	lenpen	_	_
11-499	5542-5545	0.6	_	_
11-500	5546-5547	\\	_	_
11-501	5552-5553	-	_	_
11-502	5553-5554	-	_	_
11-503	5554-5561	scoring	_	_
11-504	5562-5566	bleu	_	_
11-505	5567-5568	-	_	_
11-506	5568-5569	-	_	_
11-507	5569-5579	remove-bpe	_	_
11-508	5580-5581	-	_	_
11-509	5581-5582	-	_	_
11-510	5582-5585	cpu	_	_
11-511	5586-5587	>	_	_
11-512	5587-5595	bleu.log	_	_
11-513	5596-5597	2	_	_
11-514	5597-5598	>	_	_
11-515	5598-5599	&	_	_
11-516	5599-5600	1	_	_
11-517	5601-5602	&	_	_
11-518	5603-5604	`	_	_
11-519	5604-5605	`	_	_
11-520	5605-5606	`	_	_
11-521	5607-5616	ScareBLEU	_	_
11-522	5617-5618	`	_	_
11-523	5618-5619	`	_	_
11-524	5619-5620	`	_	_
11-525	5621-5637	fairseq-generate	_	_
11-526	5638-5646	data-bin	_	_
11-527	5646-5647	/	_	_
11-528	5647-5654	iwslt14	_	_
11-529	5654-5655	.	_	_
11-530	5655-5670	tokenized.de-en	_	_
11-531	5671-5672	\\	_	_
11-532	5677-5678	-	_	_
11-533	5678-5679	-	_	_
11-534	5679-5683	path	_	_
11-535	5684-5695	checkpoints	_	_
11-536	5695-5696	/	_	_
11-537	5696-5714	checkpoint\_best.pt	_	_
11-538	5715-5716	\\	_	_
11-539	5721-5722	-	_	_
11-540	5722-5723	s	_	_
11-541	5724-5726	en	_	_
11-542	5727-5728	-	_	_
11-543	5728-5729	t	_	_
11-544	5730-5732	de	_	_
11-545	5733-5734	\\	_	_
11-546	5739-5740	-	_	_
11-547	5740-5741	-	_	_
11-548	5741-5751	batch-size	_	_
11-549	5752-5755	128	_	_
11-550	5756-5757	-	_	_
11-551	5757-5758	-	_	_
11-552	5758-5762	beam	_	_
11-553	5763-5764	5	_	_
11-554	5765-5766	-	_	_
11-555	5766-5767	-	_	_
11-556	5767-5773	lenpen	_	_
11-557	5774-5777	0.6	_	_
11-558	5778-5779	\\	_	_
11-559	5784-5785	-	_	_
11-560	5785-5786	-	_	_
11-561	5786-5793	scoring	_	_
11-562	5794-5803	sacrebleu	_	_
11-563	5804-5805	-	_	_
11-564	5805-5806	-	_	_
11-565	5806-5816	remove-bpe	_	_
11-566	5817-5818	-	_	_
11-567	5818-5819	-	_	_
11-568	5819-5822	cpu	_	_
11-569	5823-5824	>	_	_
11-570	5824-5837	sacrebleu.log	_	_
11-571	5838-5839	2	_	_
11-572	5839-5840	>	_	_
11-573	5840-5841	&	_	_
11-574	5841-5842	1	_	_
11-575	5843-5844	&	_	_
11-576	5845-5846	`	_	_
11-577	5846-5847	`	_	_
11-578	5847-5848	`	_	_
11-579	5850-5851	#	_	_
11-580	5851-5852	#	_	_
11-581	5853-5860	Authors	_	_
11-582	5861-5862	\*	_	_
11-583	5863-5864	\*	_	_
11-584	5864-5865	\*	_	_
11-585	5865-5869	Ning	_	_
11-586	5870-5873	Shi	_	_
11-587	5873-5874	\*	_	_
11-588	5874-5875	\*	_	_
11-589	5876-5877	-	_	_
11-590	5878-5890	mrshininnnnn	_	_
11-591	5890-5891	@	_	_
11-592	5891-5900	gmail.com	_	_
11-593	5902-5903	#	_	_
11-594	5903-5904	#	_	_
11-595	5905-5911	BibTex	_	_
11-596	5912-5913	`	_	_
11-597	5913-5914	`	_	_
11-598	5914-5915	`	_	_
11-599	5916-5917	@	_	_
11-600	5917-5930	inproceedings	_	_
11-601	5930-5931	{	_	_
11-602	5931-5939	shi-etal	_	_
11-603	5939-5940	-	_	_
11-604	5940-5944	2022	_	_
11-605	5944-5945	-	_	_
11-606	5945-5952	revisit	_	_
11-607	5952-5953	,	_	_
11-608	5958-5963	title	_	_
11-609	5964-5965	=	_	_
11-610	5966-5967	"	_	_
11-611	5967-5974	Revisit	_	_
11-612	5975-5985	Systematic	_	_
11-613	5986-6000	Generalization	_	_
11-614	6001-6004	via	_	_
11-615	6005-6015	Meaningful	_	_
11-616	6016-6024	Learning	_	_
11-617	6024-6025	"	_	_
11-618	6025-6026	,	_	_
11-619	6031-6037	author	_	_
11-620	6038-6039	=	_	_
11-621	6040-6041	"	_	_
11-622	6041-6044	Shi	_	_
11-623	6044-6045	,	_	_
11-624	6046-6050	Ning	_	_
11-625	6052-6055	and	_	_
11-626	6062-6066	Wang	_	_
11-627	6066-6067	,	_	_
11-628	6068-6073	Boxin	_	_
11-629	6075-6078	and	_	_
11-630	6085-6089	Wang	_	_
11-631	6089-6090	,	_	_
11-632	6091-6094	Wei	_	_
11-633	6096-6099	and	_	_
11-634	6106-6109	Liu	_	_
11-635	6109-6110	,	_	_
11-636	6111-6118	Xiangyu	_	_
11-637	6120-6123	and	_	_
11-638	6130-6133	Lin	_	_
11-639	6133-6134	,	_	_
11-640	6135-6142	Zhouhan	_	_
11-641	6142-6143	"	_	_
11-642	6143-6144	,	_	_
11-643	6149-6158	booktitle	_	_
11-644	6159-6160	=	_	_
11-645	6161-6162	"	_	_
11-646	6162-6173	Proceedings	_	_
11-647	6174-6176	of	_	_
11-648	6177-6180	the	_	_
11-649	6181-6186	Fifth	_	_
11-650	6187-6198	BlackboxNLP	_	_
11-651	6199-6207	Workshop	_	_
11-652	6208-6210	on	_	_
11-653	6211-6220	Analyzing	_	_
11-654	6221-6224	and	_	_
11-655	6225-6237	Interpreting	_	_
11-656	6238-6244	Neural	_	_
11-657	6245-6253	Networks	_	_
11-658	6254-6257	for	_	_
11-659	6258-6261	NLP	_	_
11-660	6261-6262	"	_	_
11-661	6262-6263	,	_	_
11-662	6268-6273	month	_	_
11-663	6274-6275	=	_	_
11-664	6276-6279	dec	_	_
11-665	6279-6280	,	_	_
11-666	6285-6289	year	_	_
11-667	6290-6291	=	_	_
11-668	6292-6293	"	_	_
11-669	6293-6297	2022	_	_
11-670	6297-6298	"	_	_
11-671	6298-6299	,	_	_
11-672	6304-6311	address	_	_
11-673	6312-6313	=	_	_
11-674	6314-6315	"	_	_
11-675	6315-6318	Abu	_	_
11-676	6319-6324	Dhabi	_	_
11-677	6324-6325	,	_	_
11-678	6326-6332	United	_	_
11-679	6333-6337	Arab	_	_
11-680	6338-6346	Emirates	_	_
11-681	6347-6348	(	_	_
11-682	6348-6354	Hybrid	_	_
11-683	6354-6355	)	_	_
11-684	6355-6356	"	_	_
11-685	6356-6357	,	_	_
11-686	6362-6371	publisher	_	_
11-687	6372-6373	=	_	_
11-688	6374-6375	"	_	_
11-689	6375-6386	Association	_	_
11-690	6387-6390	for	_	_
11-691	6391-6404	Computational	_	_
11-692	6405-6416	Linguistics	_	_
11-693	6416-6417	"	_	_
11-694	6417-6418	,	_	_
11-695	6423-6426	url	_	_
11-696	6427-6428	=	_	_
11-697	6429-6430	"	_	_
11-698	6430-6435	https	_	_
11-699	6435-6436	:	_	_
11-700	6436-6437	/	_	_
11-701	6437-6438	/	_	_
11-702	6438-6454	aclanthology.org	_	_
11-703	6454-6455	/	_	_
11-704	6455-6459	2022	_	_
11-705	6459-6460	.	_	_
11-706	6460-6471	blackboxnlp	_	_
11-707	6471-6472	-	_	_
11-708	6472-6475	1.6	_	_
11-709	6475-6476	"	_	_
11-710	6476-6477	,	_	_
11-711	6482-6487	pages	_	_
11-712	6488-6489	=	_	_
11-713	6490-6491	"	_	_
11-714	6491-6493	62	_	_
11-715	6493-6494	-	_	_
11-716	6494-6495	-	_	_
11-717	6495-6497	79	_	_
11-718	6497-6498	"	_	_
11-719	6498-6499	,	_	_
11-720	6504-6512	abstract	_	_
11-721	6513-6514	=	_	_
11-722	6515-6516	"	_	_
11-723	6516-6522	Humans	_	_
11-724	6523-6526	can	_	_
11-725	6527-6541	systematically	_	_
11-726	6542-6552	generalize	_	_
11-727	6553-6555	to	_	_
11-728	6556-6561	novel	_	_
11-729	6562-6574	compositions	_	_
11-730	6575-6577	of	_	_
11-731	6578-6586	existing	_	_
11-732	6587-6595	concepts	_	_
11-733	6595-6596	.	_	_

#Text=Recent studies argue that neural networks appear inherently ineffective in such cognitive capacity, leading to a pessimistic view and a lack of attention to optimistic results.
12-1	6597-6603	Recent	_	_
12-2	6604-6611	studies	_	_
12-3	6612-6617	argue	_	_
12-4	6618-6622	that	_	_
12-5	6623-6629	neural	_	_
12-6	6630-6638	networks	_	_
12-7	6639-6645	appear	_	_
12-8	6646-6656	inherently	_	_
12-9	6657-6668	ineffective	_	_
12-10	6669-6671	in	_	_
12-11	6672-6676	such	_	_
12-12	6677-6686	cognitive	_	_
12-13	6687-6695	capacity	_	_
12-14	6695-6696	,	_	_
12-15	6697-6704	leading	_	_
12-16	6705-6707	to	_	_
12-17	6708-6709	a	_	_
12-18	6710-6721	pessimistic	_	_
12-19	6722-6726	view	_	_
12-20	6727-6730	and	_	_
12-21	6731-6732	a	_	_
12-22	6733-6737	lack	_	_
12-23	6738-6740	of	_	_
12-24	6741-6750	attention	_	_
12-25	6751-6753	to	_	_
12-26	6754-6764	optimistic	_	_
12-27	6765-6772	results	_	_
12-28	6772-6773	.	_	_

#Text=We revisit this controversial topic from the perspective of meaningful learning, an exceptional capability of humans to learn novel concepts by connecting them with known ones.
13-1	6774-6776	We	_	_
13-2	6777-6784	revisit	_	_
13-3	6785-6789	this	_	_
13-4	6790-6803	controversial	_	_
13-5	6804-6809	topic	_	_
13-6	6810-6814	from	_	_
13-7	6815-6818	the	_	_
13-8	6819-6830	perspective	_	_
13-9	6831-6833	of	_	_
13-10	6834-6844	meaningful	_	_
13-11	6845-6853	learning	_	_
13-12	6853-6854	,	_	_
13-13	6855-6857	an	_	_
13-14	6858-6869	exceptional	_	_
13-15	6870-6880	capability	_	_
13-16	6881-6883	of	_	_
13-17	6884-6890	humans	_	_
13-18	6891-6893	to	_	_
13-19	6894-6899	learn	_	_
13-20	6900-6905	novel	_	_
13-21	6906-6914	concepts	_	_
13-22	6915-6917	by	_	_
13-23	6918-6928	connecting	_	_
13-24	6929-6933	them	_	_
13-25	6934-6938	with	_	_
13-26	6939-6944	known	_	_
13-27	6945-6949	ones	_	_
13-28	6949-6950	.	_	_

#Text=We reassess the compositional skills of sequence-to-sequence models conditioned on the semantic links between new and old concepts.
14-1	6951-6953	We	_	_
14-2	6954-6962	reassess	_	_
14-3	6963-6966	the	_	_
14-4	6967-6980	compositional	_	_
14-5	6981-6987	skills	_	_
14-6	6988-6990	of	_	_
14-7	6991-7011	sequence-to-sequence	_	_
14-8	7012-7018	models	_	_
14-9	7019-7030	conditioned	_	_
14-10	7031-7033	on	_	_
14-11	7034-7037	the	_	_
14-12	7038-7046	semantic	_	_
14-13	7047-7052	links	_	_
14-14	7053-7060	between	_	_
14-15	7061-7064	new	_	_
14-16	7065-7068	and	_	_
14-17	7069-7072	old	_	_
14-18	7073-7081	concepts	_	_
14-19	7081-7082	.	_	_

#Text=Our observations suggest that models can successfully one-shot generalize to novel concepts and compositions through semantic linking, either inductively or deductively.
15-1	7083-7086	Our	_	_
15-2	7087-7099	observations	_	_
15-3	7100-7107	suggest	_	_
15-4	7108-7112	that	_	_
15-5	7113-7119	models	_	_
15-6	7120-7123	can	_	_
15-7	7124-7136	successfully	_	_
15-8	7137-7145	one-shot	_	_
15-9	7146-7156	generalize	_	_
15-10	7157-7159	to	_	_
15-11	7160-7165	novel	_	_
15-12	7166-7174	concepts	_	_
15-13	7175-7178	and	_	_
15-14	7179-7191	compositions	_	_
15-15	7192-7199	through	_	_
15-16	7200-7208	semantic	_	_
15-17	7209-7216	linking	_	_
15-18	7216-7217	,	_	_
15-19	7218-7224	either	_	_
15-20	7225-7236	inductively	_	_
15-21	7237-7239	or	_	_
15-22	7240-7251	deductively	_	_
15-23	7251-7252	.	_	_

#Text=We demonstrate that prior knowledge plays a key role as well.
16-1	7253-7255	We	_	_
16-2	7256-7267	demonstrate	_	_
16-3	7268-7272	that	_	_
16-4	7273-7278	prior	_	_
16-5	7279-7288	knowledge	_	_
16-6	7289-7294	plays	_	_
16-7	7295-7296	a	_	_
16-8	7297-7300	key	_	_
16-9	7301-7305	role	_	_
16-10	7306-7308	as	_	_
16-11	7309-7313	well	_	_
16-12	7313-7314	.	_	_

#Text=In addition to synthetic tests, we further conduct proof-of-concept experiments in machine translation and semantic parsing, showing the benefits of meaningful learning in applications.
17-1	7315-7317	In	_	_
17-2	7318-7326	addition	_	_
17-3	7327-7329	to	_	_
17-4	7330-7339	synthetic	_	_
17-5	7340-7345	tests	_	_
17-6	7345-7346	,	_	_
17-7	7347-7349	we	_	_
17-8	7350-7357	further	_	_
17-9	7358-7365	conduct	_	_
17-10	7366-7382	proof-of-concept	_	_
17-11	7383-7394	experiments	_	_
17-12	7395-7397	in	_	_
17-13	7398-7405	machine	_	_
17-14	7406-7417	translation	_	_
17-15	7418-7421	and	_	_
17-16	7422-7430	semantic	_	_
17-17	7431-7438	parsing	_	_
17-18	7438-7439	,	_	_
17-19	7440-7447	showing	_	_
17-20	7448-7451	the	_	_
17-21	7452-7460	benefits	_	_
17-22	7461-7463	of	_	_
17-23	7464-7474	meaningful	_	_
17-24	7475-7483	learning	_	_
17-25	7484-7486	in	_	_
17-26	7487-7499	applications	_	_
17-27	7499-7500	.	_	_

#Text=We hope our positive findings will encourage excavating modern neural networks{'} potential in systematic generalization through more advanced learning schemes.", } ```
18-1	7501-7503	We	_	_
18-2	7504-7508	hope	_	_
18-3	7509-7512	our	_	_
18-4	7513-7521	positive	_	_
18-5	7522-7530	findings	_	_
18-6	7531-7535	will	_	_
18-7	7536-7545	encourage	_	_
18-8	7546-7556	excavating	_	_
18-9	7557-7563	modern	_	_
18-10	7564-7570	neural	_	_
18-11	7571-7579	networks	_	_
18-12	7579-7580	{	_	_
18-13	7580-7581	'	_	_
18-14	7581-7582	}	_	_
18-15	7583-7592	potential	_	_
18-16	7593-7595	in	_	_
18-17	7596-7606	systematic	_	_
18-18	7607-7621	generalization	_	_
18-19	7622-7629	through	_	_
18-20	7630-7634	more	_	_
18-21	7635-7643	advanced	_	_
18-22	7644-7652	learning	_	_
18-23	7653-7660	schemes	_	_
18-24	7660-7661	.	_	_
18-25	7661-7662	"	_	_
18-26	7662-7663	,	_	_
18-27	7664-7665	}	_	_
18-28	7666-7667	`	_	_
18-29	7667-7668	`	_	_
18-30	7668-7669	`	_	_