#FORMAT=WebAnno TSV 3.3
#T_SP=de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity|identifier|value


#Text=<p align="center">     <img src="assets/emoji.png" alt="earthPT" width="150"/> </p>  # EarthPT  <p align="center">     <img src="assets/timeseries.png" alt="prediction" width="600"/> </p>  A simple repository for training time series large observation models.
1-1	0-1	<	_	_
1-2	1-2	p	_	_
1-3	3-8	align	_	_
1-4	8-9	=	_	_
1-5	9-10	"	_	_
1-6	10-16	center	_	_
1-7	16-17	"	_	_
1-8	17-18	>	_	_
1-9	23-24	<	_	_
1-10	24-27	img	_	_
1-11	28-31	src	_	_
1-12	31-32	=	_	_
1-13	32-33	"	_	_
1-14	33-39	assets	_	_
1-15	39-40	/	_	_
1-16	40-49	emoji.png	_	_
1-17	49-50	"	_	_
1-18	51-54	alt	_	_
1-19	54-55	=	_	_
1-20	55-56	"	_	_
1-21	56-63	earthPT	_	_
1-22	63-64	"	_	_
1-23	65-70	width	_	_
1-24	70-71	=	_	_
1-25	71-72	"	_	_
1-26	72-75	150	_	_
1-27	75-76	"	_	_
1-28	76-77	/	_	_
1-29	77-78	>	_	_
1-30	79-80	<	_	_
1-31	80-81	/	_	_
1-32	81-82	p	_	_
1-33	82-83	>	_	_
1-34	85-86	#	_	_
1-35	87-94	EarthPT	_	_
1-36	96-97	<	_	_
1-37	97-98	p	_	_
1-38	99-104	align	_	_
1-39	104-105	=	_	_
1-40	105-106	"	_	_
1-41	106-112	center	_	_
1-42	112-113	"	_	_
1-43	113-114	>	_	_
1-44	119-120	<	_	_
1-45	120-123	img	_	_
1-46	124-127	src	_	_
1-47	127-128	=	_	_
1-48	128-129	"	_	_
1-49	129-135	assets	_	_
1-50	135-136	/	_	_
1-51	136-150	timeseries.png	_	_
1-52	150-151	"	_	_
1-53	152-155	alt	_	_
1-54	155-156	=	_	_
1-55	156-157	"	_	_
1-56	157-167	prediction	_	_
1-57	167-168	"	_	_
1-58	169-174	width	_	_
1-59	174-175	=	_	_
1-60	175-176	"	_	_
1-61	176-179	600	_	_
1-62	179-180	"	_	_
1-63	180-181	/	_	_
1-64	181-182	>	_	_
1-65	183-184	<	_	_
1-66	184-185	/	_	_
1-67	185-186	p	_	_
1-68	186-187	>	_	_
1-69	189-190	A	_	_
1-70	191-197	simple	_	_
1-71	198-208	repository	_	_
1-72	209-212	for	_	_
1-73	213-221	training	_	_
1-74	222-226	time	_	_
1-75	227-233	series	_	_
1-76	234-239	large	_	_
1-77	240-251	observation	_	_
1-78	252-258	models	_	_
1-79	258-259	.	_	_

#Text=This repository began its life as Andrej Karpathy's \[nanoGPT\](https://github.com/karpathy/nanoGPT), and has been altered so that it is usable for time series data.
2-1	260-264	This	_	_
2-2	265-275	repository	_	_
2-3	276-281	began	_	_
2-4	282-285	its	_	_
2-5	286-290	life	_	_
2-6	291-293	as	_	_
2-7	294-300	Andrej	_	_
2-8	301-311	Karpathy's	_	_
2-9	312-313	\[	_	_
2-10	313-320	nanoGPT	_	_
2-11	320-321	\]	_	_
2-12	321-322	(	_	_
2-13	322-327	https	_	_
2-14	327-328	:	_	_
2-15	328-329	/	_	_
2-16	329-330	/	_	_
2-17	330-340	github.com	_	_
2-18	340-341	/	_	_
2-19	341-349	karpathy	_	_
2-20	349-350	/	_	_
2-21	350-357	nanoGPT	_	_
2-22	357-358	)	_	_
2-23	358-359	,	_	_
2-24	360-363	and	_	_
2-25	364-367	has	_	_
2-26	368-372	been	_	_
2-27	373-380	altered	_	_
2-28	381-383	so	_	_
2-29	384-388	that	_	_
2-30	389-391	it	_	_
2-31	392-394	is	_	_
2-32	395-401	usable	_	_
2-33	402-405	for	_	_
2-34	406-410	time	_	_
2-35	411-417	series	_	_
2-36	418-422	data	_	_
2-37	422-423	.	_	_

#Text=`train.py` reproduces \[EarthPT-700M\](https://arxiv.org/abs/2309.07207) when trained on 14B time series 'tokens' of ClearSky EO data within the TL UK National Grid tile.
3-1	424-425	`	_	_
3-2	425-433	train.py	_	_
3-3	433-434	`	_	_
3-4	435-445	reproduces	_	_
3-5	446-447	\[	_	_
3-6	447-454	EarthPT	_	_
3-7	454-455	-	_	_
3-8	455-459	700M	_	_
3-9	459-460	\]	_	_
3-10	460-461	(	_	_
3-11	461-466	https	_	_
3-12	466-467	:	_	_
3-13	467-468	/	_	_
3-14	468-469	/	_	_
3-15	469-478	arxiv.org	_	_
3-16	478-479	/	_	_
3-17	479-482	abs	_	_
3-18	482-483	/	_	_
3-19	483-493	2309.07207	_	_
3-20	493-494	)	_	_
3-21	495-499	when	_	_
3-22	500-507	trained	_	_
3-23	508-510	on	_	_
3-24	511-514	14B	_	_
3-25	515-519	time	_	_
3-26	520-526	series	_	_
3-27	527-528	'	_	_
3-28	528-534	tokens	_	_
3-29	534-535	'	_	_
3-30	536-538	of	_	_
3-31	539-547	ClearSky	_	_
3-32	548-550	EO	_	_
3-33	551-555	data	_	_
3-34	556-562	within	_	_
3-35	563-566	the	_	_
3-36	567-569	TL	_	_
3-37	570-572	UK	_	_
3-38	573-581	National	_	_
3-39	582-586	Grid	_	_
3-40	587-591	tile	_	_
3-41	591-592	.	_	_

#Text=When run, `train.py` takes ~5 days to achieve Chinchilla üê≠  completion on a single 8xA100 40GB node.
4-1	593-597	When	_	_
4-2	598-601	run	_	_
4-3	601-602	,	_	_
4-4	603-604	`	_	_
4-5	604-612	train.py	_	_
4-6	612-613	`	_	_
4-7	614-619	takes	_	_
4-8	620-621	~	_	_
4-9	621-622	5	_	_
4-10	623-627	days	_	_
4-11	628-630	to	_	_
4-12	631-638	achieve	_	_
4-13	639-649	Chinchilla	_	_
4-14	650-652	üê≠	_	_
4-15	653-663	completion	_	_
4-16	664-666	on	_	_
4-17	667-668	a	_	_
4-18	669-675	single	_	_
4-19	676-682	8xA100	_	_
4-20	683-687	40GB	_	_
4-21	688-692	node	_	_
4-22	692-693	.	_	_

#Text=Within `train.py` you will find a ~300-line boilerplate training loop and within `model.py` you will find a ~300-line GPT model definition with an MLP tokeniser and a regressive loss.
5-1	695-701	Within	_	_
5-2	702-703	`	_	_
5-3	703-711	train.py	_	_
5-4	711-712	`	_	_
5-5	713-716	you	_	_
5-6	717-721	will	_	_
5-7	722-726	find	_	_
5-8	727-728	a	_	_
5-9	729-730	~	_	_
5-10	730-733	300	_	_
5-11	733-734	-	_	_
5-12	734-738	line	_	_
5-13	739-750	boilerplate	_	_
5-14	751-759	training	_	_
5-15	760-764	loop	_	_
5-16	765-768	and	_	_
5-17	769-775	within	_	_
5-18	776-777	`	_	_
5-19	777-785	model.py	_	_
5-20	785-786	`	_	_
5-21	787-790	you	_	_
5-22	791-795	will	_	_
5-23	796-800	find	_	_
5-24	801-802	a	_	_
5-25	803-804	~	_	_
5-26	804-807	300	_	_
5-27	807-808	-	_	_
5-28	808-812	line	_	_
5-29	813-816	GPT	_	_
5-30	817-822	model	_	_
5-31	823-833	definition	_	_
5-32	834-838	with	_	_
5-33	839-841	an	_	_
5-34	842-845	MLP	_	_
5-35	846-855	tokeniser	_	_
5-36	856-859	and	_	_
5-37	860-861	a	_	_
5-38	862-872	regressive	_	_
5-39	873-877	loss	_	_
5-40	877-878	.	_	_

#Text=We have purposefully kept the code as simple and hackable as possible so that it is easy for all to hack this base to their needs.
6-1	880-882	We	_	_
6-2	883-887	have	_	_
6-3	888-900	purposefully	_	_
6-4	901-905	kept	_	_
6-5	906-909	the	_	_
6-6	910-914	code	_	_
6-7	915-917	as	_	_
6-8	918-924	simple	_	_
6-9	925-928	and	_	_
6-10	929-937	hackable	_	_
6-11	938-940	as	_	_
6-12	941-949	possible	_	_
6-13	950-952	so	_	_
6-14	953-957	that	_	_
6-15	958-960	it	_	_
6-16	961-963	is	_	_
6-17	964-968	easy	_	_
6-18	969-972	for	_	_
6-19	973-976	all	_	_
6-20	977-979	to	_	_
6-21	980-984	hack	_	_
6-22	985-989	this	_	_
6-23	990-994	base	_	_
6-24	995-997	to	_	_
6-25	998-1003	their	_	_
6-26	1004-1009	needs	_	_
6-27	1009-1010	.	_	_

#Text=We release this code under the MIT licence in the hope that it will prove useful to others working on EO and timeseries large observation models.  ## install  Dependencies:  - `pip install -r requirements.txt`  ## results  Our EarthPT-700M model is able to predict future satellite passes well into the future, and also learns semantically meaningful information about the timeseries that it is fed:  <p align="center">     <img src="assets/3d.gif" alt="embeddings" width="400"/> </p>  You can find a plot with less angular momentum and further results in our paper \[here\](https://arxiv.org/abs/2309.07207).  ## pretrained weights  You can find our weights for all the EarthPT models on \[HuggingFace\](https://doi.org/10.57967/hf/1598) ü§ó .  ## citation  If you find EarthPT useful in your work please do drop us a cite:  ```bibtex @article{ref\_smith2023,     author = {Smith, M.
7-1	1011-1013	We	_	_
7-2	1014-1021	release	_	_
7-3	1022-1026	this	_	_
7-4	1027-1031	code	_	_
7-5	1032-1037	under	_	_
7-6	1038-1041	the	_	_
7-7	1042-1045	MIT	_	_
7-8	1046-1053	licence	_	_
7-9	1054-1056	in	_	_
7-10	1057-1060	the	_	_
7-11	1061-1065	hope	_	_
7-12	1066-1070	that	_	_
7-13	1071-1073	it	_	_
7-14	1074-1078	will	_	_
7-15	1079-1084	prove	_	_
7-16	1085-1091	useful	_	_
7-17	1092-1094	to	_	_
7-18	1095-1101	others	_	_
7-19	1102-1109	working	_	_
7-20	1110-1112	on	_	_
7-21	1113-1115	EO	_	_
7-22	1116-1119	and	_	_
7-23	1120-1130	timeseries	_	_
7-24	1131-1136	large	_	_
7-25	1137-1148	observation	_	_
7-26	1149-1155	models	_	_
7-27	1155-1156	.	_	_
7-28	1158-1159	#	_	_
7-29	1159-1160	#	_	_
7-30	1161-1168	install	_	_
7-31	1170-1182	Dependencies	_	_
7-32	1182-1183	:	_	_
7-33	1185-1186	-	_	_
7-34	1187-1188	`	_	_
7-35	1188-1191	pip	_	_
7-36	1192-1199	install	_	_
7-37	1200-1201	-	_	_
7-38	1201-1202	r	_	_
7-39	1203-1219	requirements.txt	_	_
7-40	1219-1220	`	_	_
7-41	1222-1223	#	_	_
7-42	1223-1224	#	_	_
7-43	1225-1232	results	_	_
7-44	1234-1237	Our	_	_
7-45	1238-1245	EarthPT	_	_
7-46	1245-1246	-	_	_
7-47	1246-1250	700M	_	_
7-48	1251-1256	model	_	_
7-49	1257-1259	is	_	_
7-50	1260-1264	able	_	_
7-51	1265-1267	to	_	_
7-52	1268-1275	predict	_	_
7-53	1276-1282	future	_	_
7-54	1283-1292	satellite	_	_
7-55	1293-1299	passes	_	_
7-56	1300-1304	well	_	_
7-57	1305-1309	into	_	_
7-58	1310-1313	the	_	_
7-59	1314-1320	future	_	_
7-60	1320-1321	,	_	_
7-61	1322-1325	and	_	_
7-62	1326-1330	also	_	_
7-63	1331-1337	learns	_	_
7-64	1338-1350	semantically	_	_
7-65	1351-1361	meaningful	_	_
7-66	1362-1373	information	_	_
7-67	1374-1379	about	_	_
7-68	1380-1383	the	_	_
7-69	1384-1394	timeseries	_	_
7-70	1395-1399	that	_	_
7-71	1400-1402	it	_	_
7-72	1403-1405	is	_	_
7-73	1406-1409	fed	_	_
7-74	1409-1410	:	_	_
7-75	1412-1413	<	_	_
7-76	1413-1414	p	_	_
7-77	1415-1420	align	_	_
7-78	1420-1421	=	_	_
7-79	1421-1422	"	_	_
7-80	1422-1428	center	_	_
7-81	1428-1429	"	_	_
7-82	1429-1430	>	_	_
7-83	1435-1436	<	_	_
7-84	1436-1439	img	_	_
7-85	1440-1443	src	_	_
7-86	1443-1444	=	_	_
7-87	1444-1445	"	_	_
7-88	1445-1451	assets	_	_
7-89	1451-1452	/	_	_
7-90	1452-1458	3d.gif	_	_
7-91	1458-1459	"	_	_
7-92	1460-1463	alt	_	_
7-93	1463-1464	=	_	_
7-94	1464-1465	"	_	_
7-95	1465-1475	embeddings	_	_
7-96	1475-1476	"	_	_
7-97	1477-1482	width	_	_
7-98	1482-1483	=	_	_
7-99	1483-1484	"	_	_
7-100	1484-1487	400	_	_
7-101	1487-1488	"	_	_
7-102	1488-1489	/	_	_
7-103	1489-1490	>	_	_
7-104	1491-1492	<	_	_
7-105	1492-1493	/	_	_
7-106	1493-1494	p	_	_
7-107	1494-1495	>	_	_
7-108	1497-1500	You	_	_
7-109	1501-1504	can	_	_
7-110	1505-1509	find	_	_
7-111	1510-1511	a	_	_
7-112	1512-1516	plot	_	_
7-113	1517-1521	with	_	_
7-114	1522-1526	less	_	_
7-115	1527-1534	angular	_	_
7-116	1535-1543	momentum	_	_
7-117	1544-1547	and	_	_
7-118	1548-1555	further	_	_
7-119	1556-1563	results	_	_
7-120	1564-1566	in	_	_
7-121	1567-1570	our	_	_
7-122	1571-1576	paper	_	_
7-123	1577-1578	\[	_	_
7-124	1578-1582	here	_	_
7-125	1582-1583	\]	_	_
7-126	1583-1584	(	_	_
7-127	1584-1589	https	_	_
7-128	1589-1590	:	_	_
7-129	1590-1591	/	_	_
7-130	1591-1592	/	_	_
7-131	1592-1601	arxiv.org	_	_
7-132	1601-1602	/	_	_
7-133	1602-1605	abs	_	_
7-134	1605-1606	/	_	_
7-135	1606-1616	2309.07207	_	_
7-136	1616-1617	)	_	_
7-137	1617-1618	.	_	_
7-138	1620-1621	#	_	_
7-139	1621-1622	#	_	_
7-140	1623-1633	pretrained	_	_
7-141	1634-1641	weights	_	_
7-142	1643-1646	You	_	_
7-143	1647-1650	can	_	_
7-144	1651-1655	find	_	_
7-145	1656-1659	our	_	_
7-146	1660-1667	weights	_	_
7-147	1668-1671	for	_	_
7-148	1672-1675	all	_	_
7-149	1676-1679	the	_	_
7-150	1680-1687	EarthPT	_	_
7-151	1688-1694	models	_	_
7-152	1695-1697	on	_	_
7-153	1698-1699	\[	_	_
7-154	1699-1710	HuggingFace	_	_
7-155	1710-1711	\]	_	_
7-156	1711-1712	(	_	_
7-157	1712-1717	https	_	_
7-158	1717-1718	:	_	_
7-159	1718-1719	/	_	_
7-160	1719-1720	/	_	_
7-161	1720-1727	doi.org	_	_
7-162	1727-1728	/	_	_
7-163	1728-1736	10.57967	_	_
7-164	1736-1737	/	_	_
7-165	1737-1739	hf	_	_
7-166	1739-1740	/	_	_
7-167	1740-1744	1598	_	_
7-168	1744-1745	)	_	_
7-169	1746-1748	ü§ó	_	_
7-170	1748-1749	.	_	_
7-171	1751-1752	#	_	_
7-172	1752-1753	#	_	_
7-173	1754-1762	citation	_	_
7-174	1764-1766	If	_	_
7-175	1767-1770	you	_	_
7-176	1771-1775	find	_	_
7-177	1776-1783	EarthPT	_	_
7-178	1784-1790	useful	_	_
7-179	1791-1793	in	_	_
7-180	1794-1798	your	_	_
7-181	1799-1803	work	_	_
7-182	1804-1810	please	_	_
7-183	1811-1813	do	_	_
7-184	1814-1818	drop	_	_
7-185	1819-1821	us	_	_
7-186	1822-1823	a	_	_
7-187	1824-1828	cite	_	_
7-188	1828-1829	:	_	_
7-189	1831-1832	`	_	_
7-190	1832-1833	`	_	_
7-191	1833-1834	`	_	_
7-192	1834-1840	bibtex	_	_
7-193	1841-1842	@	_	_
7-194	1842-1849	article	_	_
7-195	1849-1850	{	_	_
7-196	1850-1863	ref\_smith2023	_	_
7-197	1863-1864	,	_	_
7-198	1869-1875	author	_	_
7-199	1876-1877	=	_	_
7-200	1878-1879	{	_	_
7-201	1879-1884	Smith	_	_
7-202	1884-1885	,	_	_
7-203	1886-1887	M	_	_
7-204	1887-1888	.	_	_

#Text=J. and Fleming, L. and Geach, J.
8-1	1889-1890	J	_	_
8-2	1890-1891	.	_	_
8-3	1892-1895	and	_	_
8-4	1896-1903	Fleming	_	_
8-5	1903-1904	,	_	_
8-6	1905-1906	L	_	_
8-7	1906-1907	.	_	_
8-8	1908-1911	and	_	_
8-9	1912-1917	Geach	_	_
8-10	1917-1918	,	_	_
8-11	1919-1920	J	_	_
8-12	1920-1921	.	_	_

#Text=E.},     title = {{EarthPT: a time series foundation model for Earth Observation}},     journal = {arXiv},     year = {2023},     eprint = {2309.07207},     doi = {10.48550/arXiv.2309.07207} } ```  This work is also in the \[proceedings\](https://www.climatechange.ai/papers/neurips2023/2) of the 2023 CCAI NeurIPS workshop.
9-1	1922-1923	E	_	_
9-2	1923-1924	.	_	_
9-3	1924-1925	}	_	_
9-4	1925-1926	,	_	_
9-5	1931-1936	title	_	_
9-6	1937-1938	=	_	_
9-7	1939-1940	{	_	_
9-8	1940-1941	{	_	_
9-9	1941-1948	EarthPT	_	_
9-10	1948-1949	:	_	_
9-11	1950-1951	a	_	_
9-12	1952-1956	time	_	_
9-13	1957-1963	series	_	_
9-14	1964-1974	foundation	_	_
9-15	1975-1980	model	_	_
9-16	1981-1984	for	_	_
9-17	1985-1990	Earth	_	_
9-18	1991-2002	Observation	_	_
9-19	2002-2003	}	_	_
9-20	2003-2004	}	_	_
9-21	2004-2005	,	_	_
9-22	2010-2017	journal	_	_
9-23	2018-2019	=	_	_
9-24	2020-2021	{	_	_
9-25	2021-2026	arXiv	_	_
9-26	2026-2027	}	_	_
9-27	2027-2028	,	_	_
9-28	2033-2037	year	_	_
9-29	2038-2039	=	_	_
9-30	2040-2041	{	_	_
9-31	2041-2045	2023	_	_
9-32	2045-2046	}	_	_
9-33	2046-2047	,	_	_
9-34	2052-2058	eprint	_	_
9-35	2059-2060	=	_	_
9-36	2061-2062	{	_	_
9-37	2062-2072	2309.07207	_	_
9-38	2072-2073	}	_	_
9-39	2073-2074	,	_	_
9-40	2079-2082	doi	_	_
9-41	2083-2084	=	_	_
9-42	2085-2086	{	_	_
9-43	2086-2094	10.48550	_	_
9-44	2094-2095	/	_	_
9-45	2095-2100	arXiv	_	_
9-46	2100-2111	.2309.07207	_	_
9-47	2111-2112	}	_	_
9-48	2113-2114	}	_	_
9-49	2115-2116	`	_	_
9-50	2116-2117	`	_	_
9-51	2117-2118	`	_	_
9-52	2120-2124	This	_	_
9-53	2125-2129	work	_	_
9-54	2130-2132	is	_	_
9-55	2133-2137	also	_	_
9-56	2138-2140	in	_	_
9-57	2141-2144	the	_	_
9-58	2145-2146	\[	_	_
9-59	2146-2157	proceedings	_	_
9-60	2157-2158	\]	_	_
9-61	2158-2159	(	_	_
9-62	2159-2164	https	_	_
9-63	2164-2165	:	_	_
9-64	2165-2166	/	_	_
9-65	2166-2167	/	_	_
9-66	2167-2187	www.climatechange.ai	_	_
9-67	2187-2188	/	_	_
9-68	2188-2194	papers	_	_
9-69	2194-2195	/	_	_
9-70	2195-2206	neurips2023	_	_
9-71	2206-2207	/	_	_
9-72	2207-2208	2	_	_
9-73	2208-2209	)	_	_
9-74	2210-2212	of	_	_
9-75	2213-2216	the	_	_
9-76	2217-2221	2023	_	_
9-77	2222-2226	CCAI	_	_
9-78	2227-2234	NeurIPS	_	_
9-79	2235-2243	workshop	_	_
9-80	2243-2244	.	_	_