#FORMAT=WebAnno TSV 3.3
#T_SP=de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity|identifier|value


#Text=# Improving Deep Metric Learning by Divide and Conquer ## About  PyTorch implementation for the paper \_Improving Deep Metric  Learning by Divide and Conquer\_ accepted to \*\*TPAMI\*\* (Sep. 2021), which is our follow-up paper of \[\_Divide and Conquer the Embedding Space for Metric Learning (CVPR 2019)\_\](https://github.com/CompVis/metric-learning-divide-and-conquer)  \*\*Links\*\*: \* arxiv: https://arxiv.org/abs/2109.04003 or \* TPAMI early access: https://ieeexplore.ieee.org/document/9540303   ## Requirements  \* PyTorch 1.1.0 \* Faiss-GPU >= 1.5.0, \[Link\](https://github.com/facebookresearch/faiss) \* albumentations >= 0.4.5, \[Link\](https://github.com/albumentations-team/albumentations)   ## Usage ### Training:  Training is done by calling `python train.py` and setting the respective params, all of which are listed and explained  in `/experiment/margin\_loss\_resnet50.py` (the default setup for all our experiments).
1-1	0-1	#	_	_
1-2	2-11	Improving	_	_
1-3	12-16	Deep	_	_
1-4	17-23	Metric	_	_
1-5	24-32	Learning	_	_
1-6	33-35	by	_	_
1-7	36-42	Divide	_	_
1-8	43-46	and	_	_
1-9	47-54	Conquer	_	_
1-10	55-56	#	_	_
1-11	56-57	#	_	_
1-12	58-63	About	_	_
1-13	65-72	PyTorch	_	_
1-14	73-87	implementation	_	_
1-15	88-91	for	_	_
1-16	92-95	the	_	_
1-17	96-101	paper	_	_
1-18	102-103	\_	_	_
1-19	103-112	Improving	_	_
1-20	113-117	Deep	_	_
1-21	118-124	Metric	_	_
1-22	126-134	Learning	_	_
1-23	135-137	by	_	_
1-24	138-144	Divide	_	_
1-25	145-148	and	_	_
1-26	149-156	Conquer	_	_
1-27	156-157	\_	_	_
1-28	158-166	accepted	_	_
1-29	167-169	to	_	_
1-30	170-171	\*	_	_
1-31	171-172	\*	_	_
1-32	172-177	TPAMI	_	_
1-33	177-178	\*	_	_
1-34	178-179	\*	_	_
1-35	180-181	(	_	_
1-36	181-184	Sep	_	_
1-37	184-185	.	_	_
1-38	186-190	2021	_	_
1-39	190-191	)	_	_
1-40	191-192	,	_	_
1-41	193-198	which	_	_
1-42	199-201	is	_	_
1-43	202-205	our	_	_
1-44	206-215	follow-up	_	_
1-45	216-221	paper	_	_
1-46	222-224	of	_	_
1-47	225-226	\[	_	_
1-48	226-227	\_	_	_
1-49	227-233	Divide	_	_
1-50	234-237	and	_	_
1-51	238-245	Conquer	_	_
1-52	246-249	the	_	_
1-53	250-259	Embedding	_	_
1-54	260-265	Space	_	_
1-55	266-269	for	_	_
1-56	270-276	Metric	_	_
1-57	277-285	Learning	_	_
1-58	286-287	(	_	_
1-59	287-291	CVPR	_	_
1-60	292-296	2019	_	_
1-61	296-297	)	_	_
1-62	297-298	\_	_	_
1-63	298-299	\]	_	_
1-64	299-300	(	_	_
1-65	300-305	https	_	_
1-66	305-306	:	_	_
1-67	306-307	/	_	_
1-68	307-308	/	_	_
1-69	308-318	github.com	_	_
1-70	318-319	/	_	_
1-71	319-326	CompVis	_	_
1-72	326-327	/	_	_
1-73	327-361	metric-learning-divide-and-conquer	_	_
1-74	361-362	)	_	_
1-75	364-365	\*	_	_
1-76	365-366	\*	_	_
1-77	366-371	Links	_	_
1-78	371-372	\*	_	_
1-79	372-373	\*	_	_
1-80	373-374	:	_	_
1-81	375-376	\*	_	_
1-82	377-382	arxiv	_	_
1-83	382-383	:	_	_
1-84	384-389	https	_	_
1-85	389-390	:	_	_
1-86	390-391	/	_	_
1-87	391-392	/	_	_
1-88	392-401	arxiv.org	_	_
1-89	401-402	/	_	_
1-90	402-405	abs	_	_
1-91	405-406	/	_	_
1-92	406-416	2109.04003	_	_
1-93	417-419	or	_	_
1-94	420-421	\*	_	_
1-95	422-427	TPAMI	_	_
1-96	428-433	early	_	_
1-97	434-440	access	_	_
1-98	440-441	:	_	_
1-99	442-447	https	_	_
1-100	447-448	:	_	_
1-101	448-449	/	_	_
1-102	449-450	/	_	_
1-103	450-469	ieeexplore.ieee.org	_	_
1-104	469-470	/	_	_
1-105	470-478	document	_	_
1-106	478-479	/	_	_
1-107	479-486	9540303	_	_
1-108	489-490	#	_	_
1-109	490-491	#	_	_
1-110	492-504	Requirements	_	_
1-111	506-507	\*	_	_
1-112	508-515	PyTorch	_	_
1-113	516-521	1.1.0	_	_
1-114	522-523	\*	_	_
1-115	524-533	Faiss-GPU	_	_
1-116	534-535	>	_	_
1-117	535-536	=	_	_
1-118	537-542	1.5.0	_	_
1-119	542-543	,	_	_
1-120	544-545	\[	_	_
1-121	545-549	Link	_	_
1-122	549-550	\]	_	_
1-123	550-551	(	_	_
1-124	551-556	https	_	_
1-125	556-557	:	_	_
1-126	557-558	/	_	_
1-127	558-559	/	_	_
1-128	559-569	github.com	_	_
1-129	569-570	/	_	_
1-130	570-586	facebookresearch	_	_
1-131	586-587	/	_	_
1-132	587-592	faiss	_	_
1-133	592-593	)	_	_
1-134	594-595	\*	_	_
1-135	596-610	albumentations	_	_
1-136	611-612	>	_	_
1-137	612-613	=	_	_
1-138	614-619	0.4.5	_	_
1-139	619-620	,	_	_
1-140	621-622	\[	_	_
1-141	622-626	Link	_	_
1-142	626-627	\]	_	_
1-143	627-628	(	_	_
1-144	628-633	https	_	_
1-145	633-634	:	_	_
1-146	634-635	/	_	_
1-147	635-636	/	_	_
1-148	636-646	github.com	_	_
1-149	646-647	/	_	_
1-150	647-666	albumentations-team	_	_
1-151	666-667	/	_	_
1-152	667-681	albumentations	_	_
1-153	681-682	)	_	_
1-154	685-686	#	_	_
1-155	686-687	#	_	_
1-156	688-693	Usage	_	_
1-157	694-695	#	_	_
1-158	695-696	#	_	_
1-159	696-697	#	_	_
1-160	698-706	Training	_	_
1-161	706-707	:	_	_
1-162	709-717	Training	_	_
1-163	718-720	is	_	_
1-164	721-725	done	_	_
1-165	726-728	by	_	_
1-166	729-736	calling	_	_
1-167	737-738	`	_	_
1-168	738-744	python	_	_
1-169	745-753	train.py	_	_
1-170	753-754	`	_	_
1-171	755-758	and	_	_
1-172	759-766	setting	_	_
1-173	767-770	the	_	_
1-174	771-781	respective	_	_
1-175	782-788	params	_	_
1-176	788-789	,	_	_
1-177	790-793	all	_	_
1-178	794-796	of	_	_
1-179	797-802	which	_	_
1-180	803-806	are	_	_
1-181	807-813	listed	_	_
1-182	814-817	and	_	_
1-183	818-827	explained	_	_
1-184	829-831	in	_	_
1-185	832-833	`	_	_
1-186	833-834	/	_	_
1-187	834-844	experiment	_	_
1-188	844-845	/	_	_
1-189	845-865	margin\_loss\_resnet50	_	_
1-190	865-866	.	_	_
1-191	866-868	py	_	_
1-192	868-869	`	_	_
1-193	870-871	(	_	_
1-194	871-874	the	_	_
1-195	875-882	default	_	_
1-196	883-888	setup	_	_
1-197	889-892	for	_	_
1-198	893-896	all	_	_
1-199	897-900	our	_	_
1-200	901-912	experiments	_	_
1-201	912-913	)	_	_
1-202	913-914	.	_	_

#Text=The params provided in command line will override those default ones.
2-1	915-918	The	_	_
2-2	919-925	params	_	_
2-3	926-934	provided	_	_
2-4	935-937	in	_	_
2-5	938-945	command	_	_
2-6	946-950	line	_	_
2-7	951-955	will	_	_
2-8	956-964	override	_	_
2-9	965-970	those	_	_
2-10	971-978	default	_	_
2-11	979-983	ones	_	_
2-12	983-984	.	_	_

#Text=\*\*A basic sample run using default parameters would like this\*\*:  ``` python train.py --experiment margin\_loss\_resnet50 \\                 --dataset=sop -i=$NAME -seed=4 \\                 --sz-embedding=512 --mod-epoch=2 --nb-clusters=32 --nb-epochs=180 \\                 --batch-size=80 --num-samples-per-class=2 --backend=faiss-gpu \\                 --lr-gamma=0.3 --mod-epoch-freeze=1 --sampler=distanceweighted \\                 --weight-decay=1e-4 --batch-sampler=adaptbalanced \\                 --force-full-embedding-epoch=80 --mask-lr-mult=100 \\                 --masking-lambda=0.01 --mask-wd-mult=1 --dataset-dir=$datadir ```  - \*\*--experiment margin\_loss\_resnet50\*\* please keep this untouched, otherwise the args won't be read correctly. - \*\*--dataset\*\* specify the dataset that you want to train the model for, choose one of `--dataset=cub` (CUB200-2011), `cars` (CARS196), `sop` (Standford Online Porducts), `inshop` (In-Shop cloths retireval) or `vid` (PKU Vehicle id). - \*\*--nb\_clusters\*\*: could be maximumly possible set to 16.
3-1	986-987	\*	_	_
3-2	987-988	\*	_	_
3-3	988-989	A	_	_
3-4	990-995	basic	_	_
3-5	996-1002	sample	_	_
3-6	1003-1006	run	_	_
3-7	1007-1012	using	_	_
3-8	1013-1020	default	_	_
3-9	1021-1031	parameters	_	_
3-10	1032-1037	would	_	_
3-11	1038-1042	like	_	_
3-12	1043-1047	this	_	_
3-13	1047-1048	\*	_	_
3-14	1048-1049	\*	_	_
3-15	1049-1050	:	_	_
3-16	1052-1053	`	_	_
3-17	1053-1054	`	_	_
3-18	1054-1055	`	_	_
3-19	1056-1062	python	_	_
3-20	1063-1071	train.py	_	_
3-21	1072-1073	-	_	_
3-22	1073-1074	-	_	_
3-23	1074-1084	experiment	_	_
3-24	1085-1105	margin\_loss\_resnet50	_	_
3-25	1106-1107	\\	_	_
3-26	1124-1125	-	_	_
3-27	1125-1126	-	_	_
3-28	1126-1133	dataset	_	_
3-29	1133-1134	=	_	_
3-30	1134-1137	sop	_	_
3-31	1138-1139	-	_	_
3-32	1139-1140	i	_	_
3-33	1140-1141	=	_	_
3-34	1141-1142	$	_	_
3-35	1142-1146	NAME	_	_
3-36	1147-1148	-	_	_
3-37	1148-1152	seed	_	_
3-38	1152-1153	=	_	_
3-39	1153-1154	4	_	_
3-40	1155-1156	\\	_	_
3-41	1173-1174	-	_	_
3-42	1174-1175	-	_	_
3-43	1175-1187	sz-embedding	_	_
3-44	1187-1188	=	_	_
3-45	1188-1191	512	_	_
3-46	1192-1193	-	_	_
3-47	1193-1194	-	_	_
3-48	1194-1203	mod-epoch	_	_
3-49	1203-1204	=	_	_
3-50	1204-1205	2	_	_
3-51	1206-1207	-	_	_
3-52	1207-1208	-	_	_
3-53	1208-1219	nb-clusters	_	_
3-54	1219-1220	=	_	_
3-55	1220-1222	32	_	_
3-56	1223-1224	-	_	_
3-57	1224-1225	-	_	_
3-58	1225-1234	nb-epochs	_	_
3-59	1234-1235	=	_	_
3-60	1235-1238	180	_	_
3-61	1239-1240	\\	_	_
3-62	1257-1258	-	_	_
3-63	1258-1259	-	_	_
3-64	1259-1269	batch-size	_	_
3-65	1269-1270	=	_	_
3-66	1270-1272	80	_	_
3-67	1273-1274	-	_	_
3-68	1274-1275	-	_	_
3-69	1275-1296	num-samples-per-class	_	_
3-70	1296-1297	=	_	_
3-71	1297-1298	2	_	_
3-72	1299-1300	-	_	_
3-73	1300-1301	-	_	_
3-74	1301-1308	backend	_	_
3-75	1308-1309	=	_	_
3-76	1309-1318	faiss-gpu	_	_
3-77	1319-1320	\\	_	_
3-78	1337-1338	-	_	_
3-79	1338-1339	-	_	_
3-80	1339-1347	lr-gamma	_	_
3-81	1347-1348	=	_	_
3-82	1348-1351	0.3	_	_
3-83	1352-1353	-	_	_
3-84	1353-1354	-	_	_
3-85	1354-1370	mod-epoch-freeze	_	_
3-86	1370-1371	=	_	_
3-87	1371-1372	1	_	_
3-88	1373-1374	-	_	_
3-89	1374-1375	-	_	_
3-90	1375-1382	sampler	_	_
3-91	1382-1383	=	_	_
3-92	1383-1399	distanceweighted	_	_
3-93	1400-1401	\\	_	_
3-94	1418-1419	-	_	_
3-95	1419-1420	-	_	_
3-96	1420-1432	weight-decay	_	_
3-97	1432-1433	=	_	_
3-98	1433-1435	1e	_	_
3-99	1435-1436	-	_	_
3-100	1436-1437	4	_	_
3-101	1438-1439	-	_	_
3-102	1439-1440	-	_	_
3-103	1440-1453	batch-sampler	_	_
3-104	1453-1454	=	_	_
3-105	1454-1467	adaptbalanced	_	_
3-106	1468-1469	\\	_	_
3-107	1486-1487	-	_	_
3-108	1487-1488	-	_	_
3-109	1488-1514	force-full-embedding-epoch	_	_
3-110	1514-1515	=	_	_
3-111	1515-1517	80	_	_
3-112	1518-1519	-	_	_
3-113	1519-1520	-	_	_
3-114	1520-1532	mask-lr-mult	_	_
3-115	1532-1533	=	_	_
3-116	1533-1536	100	_	_
3-117	1537-1538	\\	_	_
3-118	1555-1556	-	_	_
3-119	1556-1557	-	_	_
3-120	1557-1571	masking-lambda	_	_
3-121	1571-1572	=	_	_
3-122	1572-1576	0.01	_	_
3-123	1577-1578	-	_	_
3-124	1578-1579	-	_	_
3-125	1579-1591	mask-wd-mult	_	_
3-126	1591-1592	=	_	_
3-127	1592-1593	1	_	_
3-128	1594-1595	-	_	_
3-129	1595-1596	-	_	_
3-130	1596-1607	dataset-dir	_	_
3-131	1607-1608	=	_	_
3-132	1608-1609	$	_	_
3-133	1609-1616	datadir	_	_
3-134	1617-1618	`	_	_
3-135	1618-1619	`	_	_
3-136	1619-1620	`	_	_
3-137	1622-1623	-	_	_
3-138	1624-1625	\*	_	_
3-139	1625-1626	\*	_	_
3-140	1626-1627	-	_	_
3-141	1627-1628	-	_	_
3-142	1628-1638	experiment	_	_
3-143	1639-1659	margin\_loss\_resnet50	_	_
3-144	1659-1660	\*	_	_
3-145	1660-1661	\*	_	_
3-146	1662-1668	please	_	_
3-147	1669-1673	keep	_	_
3-148	1674-1678	this	_	_
3-149	1679-1688	untouched	_	_
3-150	1688-1689	,	_	_
3-151	1690-1699	otherwise	_	_
3-152	1700-1703	the	_	_
3-153	1704-1708	args	_	_
3-154	1709-1714	won't	_	_
3-155	1715-1717	be	_	_
3-156	1718-1722	read	_	_
3-157	1723-1732	correctly	_	_
3-158	1732-1733	.	_	_
3-159	1734-1735	-	_	_
3-160	1736-1737	\*	_	_
3-161	1737-1738	\*	_	_
3-162	1738-1739	-	_	_
3-163	1739-1740	-	_	_
3-164	1740-1747	dataset	_	_
3-165	1747-1748	\*	_	_
3-166	1748-1749	\*	_	_
3-167	1750-1757	specify	_	_
3-168	1758-1761	the	_	_
3-169	1762-1769	dataset	_	_
3-170	1770-1774	that	_	_
3-171	1775-1778	you	_	_
3-172	1779-1783	want	_	_
3-173	1784-1786	to	_	_
3-174	1787-1792	train	_	_
3-175	1793-1796	the	_	_
3-176	1797-1802	model	_	_
3-177	1803-1806	for	_	_
3-178	1806-1807	,	_	_
3-179	1808-1814	choose	_	_
3-180	1815-1818	one	_	_
3-181	1819-1821	of	_	_
3-182	1822-1823	`	_	_
3-183	1823-1824	-	_	_
3-184	1824-1825	-	_	_
3-185	1825-1832	dataset	_	_
3-186	1832-1833	=	_	_
3-187	1833-1836	cub	_	_
3-188	1836-1837	`	_	_
3-189	1838-1839	(	_	_
3-190	1839-1845	CUB200	_	_
3-191	1845-1846	-	_	_
3-192	1846-1850	2011	_	_
3-193	1850-1851	)	_	_
3-194	1851-1852	,	_	_
3-195	1853-1854	`	_	_
3-196	1854-1858	cars	_	_
3-197	1858-1859	`	_	_
3-198	1860-1861	(	_	_
3-199	1861-1868	CARS196	_	_
3-200	1868-1869	)	_	_
3-201	1869-1870	,	_	_
3-202	1871-1872	`	_	_
3-203	1872-1875	sop	_	_
3-204	1875-1876	`	_	_
3-205	1877-1878	(	_	_
3-206	1878-1887	Standford	_	_
3-207	1888-1894	Online	_	_
3-208	1895-1903	Porducts	_	_
3-209	1903-1904	)	_	_
3-210	1904-1905	,	_	_
3-211	1906-1907	`	_	_
3-212	1907-1913	inshop	_	_
3-213	1913-1914	`	_	_
3-214	1915-1916	(	_	_
3-215	1916-1923	In-Shop	_	_
3-216	1924-1930	cloths	_	_
3-217	1931-1940	retireval	_	_
3-218	1940-1941	)	_	_
3-219	1942-1944	or	_	_
3-220	1945-1946	`	_	_
3-221	1946-1949	vid	_	_
3-222	1949-1950	`	_	_
3-223	1951-1952	(	_	_
3-224	1952-1955	PKU	_	_
3-225	1956-1963	Vehicle	_	_
3-226	1964-1966	id	_	_
3-227	1966-1967	)	_	_
3-228	1967-1968	.	_	_
3-229	1969-1970	-	_	_
3-230	1971-1972	\*	_	_
3-231	1972-1973	\*	_	_
3-232	1973-1974	-	_	_
3-233	1974-1975	-	_	_
3-234	1975-1986	nb\_clusters	_	_
3-235	1986-1987	\*	_	_
3-236	1987-1988	\*	_	_
3-237	1988-1989	:	_	_
3-238	1990-1995	could	_	_
3-239	1996-1998	be	_	_
3-240	1999-2008	maximumly	_	_
3-241	2009-2017	possible	_	_
3-242	2018-2021	set	_	_
3-243	2022-2024	to	_	_
3-244	2025-2027	16	_	_
3-245	2027-2028	.	_	_

#Text=For larger number of clusters, you may need to change the default  limit of opened files allowed for each process.
4-1	2029-2032	For	_	_
4-2	2033-2039	larger	_	_
4-3	2040-2046	number	_	_
4-4	2047-2049	of	_	_
4-5	2050-2058	clusters	_	_
4-6	2058-2059	,	_	_
4-7	2060-2063	you	_	_
4-8	2064-2067	may	_	_
4-9	2068-2072	need	_	_
4-10	2073-2075	to	_	_
4-11	2076-2082	change	_	_
4-12	2083-2086	the	_	_
4-13	2087-2094	default	_	_
4-14	2096-2101	limit	_	_
4-15	2102-2104	of	_	_
4-16	2105-2111	opened	_	_
4-17	2112-2117	files	_	_
4-18	2118-2125	allowed	_	_
4-19	2126-2129	for	_	_
4-20	2130-2134	each	_	_
4-21	2135-2142	process	_	_
4-22	2142-2143	.	_	_

#Text=For example, if you are a ubuntu user, `ulimit -n <twice the number of the default>` usually will do the trick.
5-1	2144-2147	For	_	_
5-2	2148-2155	example	_	_
5-3	2155-2156	,	_	_
5-4	2157-2159	if	_	_
5-5	2160-2163	you	_	_
5-6	2164-2167	are	_	_
5-7	2168-2169	a	_	_
5-8	2170-2176	ubuntu	_	_
5-9	2177-2181	user	_	_
5-10	2181-2182	,	_	_
5-11	2183-2184	`	_	_
5-12	2184-2190	ulimit	_	_
5-13	2191-2192	-	_	_
5-14	2192-2193	n	_	_
5-15	2194-2195	<	_	_
5-16	2195-2200	twice	_	_
5-17	2201-2204	the	_	_
5-18	2205-2211	number	_	_
5-19	2212-2214	of	_	_
5-20	2215-2218	the	_	_
5-21	2219-2226	default	_	_
5-22	2226-2227	>	_	_
5-23	2227-2228	`	_	_
5-24	2229-2236	usually	_	_
5-25	2237-2241	will	_	_
5-26	2242-2244	do	_	_
5-27	2245-2248	the	_	_
5-28	2249-2254	trick	_	_
5-29	2254-2255	.	_	_

#Text=Besides, please take the total number of different classes in the dataset and the sampling strategy used into account when you setting this value. - \*\*--dataset-dir\*\*: the path to the datasets, check the \*Datasets\* section below. - \*\*--sampler\*\*: batchminer used to sample pairs or triplets (in embedding space) to create learning signal, check `/metriclearning/sampler` for details. - \*\*--batch-sampler\*\*: data sampler used to generate training batches, check `/dataset/sampler.py` for details. - \*\*--nb-epochs\*\*: the maximum training epochs. - \*\*--mod-epoch\*\*: division frequency in the paper - the number of training epochs between consecutive divisions. - \*\*--wandb-enabled\*\*: by setting this flag, you will enable the \[Weights&Biases\](https://wandb.ai/site) logging.
6-1	2256-2263	Besides	_	_
6-2	2263-2264	,	_	_
6-3	2265-2271	please	_	_
6-4	2272-2276	take	_	_
6-5	2277-2280	the	_	_
6-6	2281-2286	total	_	_
6-7	2287-2293	number	_	_
6-8	2294-2296	of	_	_
6-9	2297-2306	different	_	_
6-10	2307-2314	classes	_	_
6-11	2315-2317	in	_	_
6-12	2318-2321	the	_	_
6-13	2322-2329	dataset	_	_
6-14	2330-2333	and	_	_
6-15	2334-2337	the	_	_
6-16	2338-2346	sampling	_	_
6-17	2347-2355	strategy	_	_
6-18	2356-2360	used	_	_
6-19	2361-2365	into	_	_
6-20	2366-2373	account	_	_
6-21	2374-2378	when	_	_
6-22	2379-2382	you	_	_
6-23	2383-2390	setting	_	_
6-24	2391-2395	this	_	_
6-25	2396-2401	value	_	_
6-26	2401-2402	.	_	_
6-27	2403-2404	-	_	_
6-28	2405-2406	\*	_	_
6-29	2406-2407	\*	_	_
6-30	2407-2408	-	_	_
6-31	2408-2409	-	_	_
6-32	2409-2420	dataset-dir	_	_
6-33	2420-2421	\*	_	_
6-34	2421-2422	\*	_	_
6-35	2422-2423	:	_	_
6-36	2424-2427	the	_	_
6-37	2428-2432	path	_	_
6-38	2433-2435	to	_	_
6-39	2436-2439	the	_	_
6-40	2440-2448	datasets	_	_
6-41	2448-2449	,	_	_
6-42	2450-2455	check	_	_
6-43	2456-2459	the	_	_
6-44	2460-2461	\*	_	_
6-45	2461-2469	Datasets	_	_
6-46	2469-2470	\*	_	_
6-47	2471-2478	section	_	_
6-48	2479-2484	below	_	_
6-49	2484-2485	.	_	_
6-50	2486-2487	-	_	_
6-51	2488-2489	\*	_	_
6-52	2489-2490	\*	_	_
6-53	2490-2491	-	_	_
6-54	2491-2492	-	_	_
6-55	2492-2499	sampler	_	_
6-56	2499-2500	\*	_	_
6-57	2500-2501	\*	_	_
6-58	2501-2502	:	_	_
6-59	2503-2513	batchminer	_	_
6-60	2514-2518	used	_	_
6-61	2519-2521	to	_	_
6-62	2522-2528	sample	_	_
6-63	2529-2534	pairs	_	_
6-64	2535-2537	or	_	_
6-65	2538-2546	triplets	_	_
6-66	2547-2548	(	_	_
6-67	2548-2550	in	_	_
6-68	2551-2560	embedding	_	_
6-69	2561-2566	space	_	_
6-70	2566-2567	)	_	_
6-71	2568-2570	to	_	_
6-72	2571-2577	create	_	_
6-73	2578-2586	learning	_	_
6-74	2587-2593	signal	_	_
6-75	2593-2594	,	_	_
6-76	2595-2600	check	_	_
6-77	2601-2602	`	_	_
6-78	2602-2603	/	_	_
6-79	2603-2617	metriclearning	_	_
6-80	2617-2618	/	_	_
6-81	2618-2625	sampler	_	_
6-82	2625-2626	`	_	_
6-83	2627-2630	for	_	_
6-84	2631-2638	details	_	_
6-85	2638-2639	.	_	_
6-86	2640-2641	-	_	_
6-87	2642-2643	\*	_	_
6-88	2643-2644	\*	_	_
6-89	2644-2645	-	_	_
6-90	2645-2646	-	_	_
6-91	2646-2659	batch-sampler	_	_
6-92	2659-2660	\*	_	_
6-93	2660-2661	\*	_	_
6-94	2661-2662	:	_	_
6-95	2663-2667	data	_	_
6-96	2668-2675	sampler	_	_
6-97	2676-2680	used	_	_
6-98	2681-2683	to	_	_
6-99	2684-2692	generate	_	_
6-100	2693-2701	training	_	_
6-101	2702-2709	batches	_	_
6-102	2709-2710	,	_	_
6-103	2711-2716	check	_	_
6-104	2717-2718	`	_	_
6-105	2718-2719	/	_	_
6-106	2719-2726	dataset	_	_
6-107	2726-2727	/	_	_
6-108	2727-2737	sampler.py	_	_
6-109	2737-2738	`	_	_
6-110	2739-2742	for	_	_
6-111	2743-2750	details	_	_
6-112	2750-2751	.	_	_
6-113	2752-2753	-	_	_
6-114	2754-2755	\*	_	_
6-115	2755-2756	\*	_	_
6-116	2756-2757	-	_	_
6-117	2757-2758	-	_	_
6-118	2758-2767	nb-epochs	_	_
6-119	2767-2768	\*	_	_
6-120	2768-2769	\*	_	_
6-121	2769-2770	:	_	_
6-122	2771-2774	the	_	_
6-123	2775-2782	maximum	_	_
6-124	2783-2791	training	_	_
6-125	2792-2798	epochs	_	_
6-126	2798-2799	.	_	_
6-127	2800-2801	-	_	_
6-128	2802-2803	\*	_	_
6-129	2803-2804	\*	_	_
6-130	2804-2805	-	_	_
6-131	2805-2806	-	_	_
6-132	2806-2815	mod-epoch	_	_
6-133	2815-2816	\*	_	_
6-134	2816-2817	\*	_	_
6-135	2817-2818	:	_	_
6-136	2819-2827	division	_	_
6-137	2828-2837	frequency	_	_
6-138	2838-2840	in	_	_
6-139	2841-2844	the	_	_
6-140	2845-2850	paper	_	_
6-141	2851-2852	-	_	_
6-142	2853-2856	the	_	_
6-143	2857-2863	number	_	_
6-144	2864-2866	of	_	_
6-145	2867-2875	training	_	_
6-146	2876-2882	epochs	_	_
6-147	2883-2890	between	_	_
6-148	2891-2902	consecutive	_	_
6-149	2903-2912	divisions	_	_
6-150	2912-2913	.	_	_
6-151	2914-2915	-	_	_
6-152	2916-2917	\*	_	_
6-153	2917-2918	\*	_	_
6-154	2918-2919	-	_	_
6-155	2919-2920	-	_	_
6-156	2920-2933	wandb-enabled	_	_
6-156	2920-2925	wandb	_	_
6-157	2933-2934	\*	_	_
6-158	2934-2935	\*	_	_
6-159	2935-2936	:	_	_
6-160	2937-2939	by	_	_
6-161	2940-2947	setting	_	_
6-162	2948-2952	this	_	_
6-163	2953-2957	flag	_	_
6-164	2957-2958	,	_	_
6-165	2959-2962	you	_	_
6-166	2963-2967	will	_	_
6-167	2968-2974	enable	_	_
6-168	2975-2978	the	_	_
6-169	2979-2980	\[	_	_
6-170	2980-2987	Weights	_	_
6-171	2987-2988	&	_	_
6-172	2988-2994	Biases	_	_
6-173	2994-2995	\]	_	_
6-174	2995-2996	(	_	_
6-175	2996-3001	https	_	_
6-176	3001-3002	:	_	_
6-177	3002-3003	/	_	_
6-178	3003-3004	/	_	_
6-179	3004-3012	wandb.ai	_	_
6-179	3004-3009	wandb	_	_
6-180	3012-3013	/	_	_
6-181	3013-3017	site	_	_
6-182	3017-3018	)	_	_
6-183	3019-3026	logging	_	_
6-184	3026-3027	.	_	_

#Text=Please change the w&b initial setting at the last part of `/experiment/margin\_loss\_resnet50.py` accordingly.
7-1	3028-3034	Please	_	_
7-2	3035-3041	change	_	_
7-3	3042-3045	the	_	_
7-4	3046-3047	w	_	_
7-5	3047-3048	&	_	_
7-6	3048-3049	b	_	_
7-7	3050-3057	initial	_	_
7-8	3058-3065	setting	_	_
7-9	3066-3068	at	_	_
7-10	3069-3072	the	_	_
7-11	3073-3077	last	_	_
7-12	3078-3082	part	_	_
7-13	3083-3085	of	_	_
7-14	3086-3087	`	_	_
7-15	3087-3088	/	_	_
7-16	3088-3098	experiment	_	_
7-17	3098-3099	/	_	_
7-18	3099-3119	margin\_loss\_resnet50	_	_
7-19	3119-3120	.	_	_
7-20	3120-3122	py	_	_
7-21	3122-3123	`	_	_
7-22	3124-3135	accordingly	_	_
7-23	3135-3136	.	_	_

#Text=\*\*\_Note:\_\*\* For exact settings for different datasets, please check the original paper.
8-1	3138-3139	\*	_	_
8-2	3139-3140	\*	_	_
8-3	3140-3141	\_	_	_
8-4	3141-3145	Note	_	_
8-5	3145-3146	:	_	_
8-6	3146-3147	\_	_	_
8-7	3147-3148	\*	_	_
8-8	3148-3149	\*	_	_
8-9	3150-3153	For	_	_
8-10	3154-3159	exact	_	_
8-11	3160-3168	settings	_	_
8-12	3169-3172	for	_	_
8-13	3173-3182	different	_	_
8-14	3183-3191	datasets	_	_
8-15	3191-3192	,	_	_
8-16	3193-3199	please	_	_
8-17	3200-3205	check	_	_
8-18	3206-3209	the	_	_
8-19	3210-3218	original	_	_
8-20	3219-3224	paper	_	_
8-21	3224-3225	.	_	_

#Text=For arguments not mentioned above,  please check `/experiment/margin\_loss\_resnet50.py` for explanation.   ### Evaluate or check results during:  \* \*\*evaluate a trained model\*\*: `eval\_model.py <log and model checkpoint path>`.
9-1	3226-3229	For	_	_
9-2	3230-3239	arguments	_	_
9-3	3240-3243	not	_	_
9-4	3244-3253	mentioned	_	_
9-5	3254-3259	above	_	_
9-6	3259-3260	,	_	_
9-7	3262-3268	please	_	_
9-8	3269-3274	check	_	_
9-9	3275-3276	`	_	_
9-10	3276-3277	/	_	_
9-11	3277-3287	experiment	_	_
9-12	3287-3288	/	_	_
9-13	3288-3308	margin\_loss\_resnet50	_	_
9-14	3308-3309	.	_	_
9-15	3309-3311	py	_	_
9-16	3311-3312	`	_	_
9-17	3313-3316	for	_	_
9-18	3317-3328	explanation	_	_
9-19	3328-3329	.	_	_
9-20	3332-3333	#	_	_
9-21	3333-3334	#	_	_
9-22	3334-3335	#	_	_
9-23	3336-3344	Evaluate	_	_
9-24	3345-3347	or	_	_
9-25	3348-3353	check	_	_
9-26	3354-3361	results	_	_
9-27	3362-3368	during	_	_
9-28	3368-3369	:	_	_
9-29	3371-3372	\*	_	_
9-30	3373-3374	\*	_	_
9-31	3374-3375	\*	_	_
9-32	3375-3383	evaluate	_	_
9-33	3384-3385	a	_	_
9-34	3386-3393	trained	_	_
9-35	3394-3399	model	_	_
9-36	3399-3400	\*	_	_
9-37	3400-3401	\*	_	_
9-38	3401-3402	:	_	_
9-39	3403-3404	`	_	_
9-40	3404-3417	eval\_model.py	_	_
9-41	3418-3419	<	_	_
9-42	3419-3422	log	_	_
9-43	3423-3426	and	_	_
9-44	3427-3432	model	_	_
9-45	3433-3443	checkpoint	_	_
9-46	3444-3448	path	_	_
9-47	3448-3449	>	_	_
9-48	3449-3450	`	_	_
9-49	3450-3451	.	_	_

#Text=It is suggested to put only those models (checkpoints and logs) you want to eval into one folder otherwise it will evaluate all the models ind the folder  \* \*\*check intermediate results\*\*: the model checkpoints and log files are saved in the selected log-directory (by default: `/log`).
10-1	3452-3454	It	_	_
10-2	3455-3457	is	_	_
10-3	3458-3467	suggested	_	_
10-4	3468-3470	to	_	_
10-5	3471-3474	put	_	_
10-6	3475-3479	only	_	_
10-7	3480-3485	those	_	_
10-8	3486-3492	models	_	_
10-9	3493-3494	(	_	_
10-10	3494-3505	checkpoints	_	_
10-11	3506-3509	and	_	_
10-12	3510-3514	logs	_	_
10-13	3514-3515	)	_	_
10-14	3516-3519	you	_	_
10-15	3520-3524	want	_	_
10-16	3525-3527	to	_	_
10-17	3528-3532	eval	_	_
10-18	3533-3537	into	_	_
10-19	3538-3541	one	_	_
10-20	3542-3548	folder	_	_
10-21	3549-3558	otherwise	_	_
10-22	3559-3561	it	_	_
10-23	3562-3566	will	_	_
10-24	3567-3575	evaluate	_	_
10-25	3576-3579	all	_	_
10-26	3580-3583	the	_	_
10-27	3584-3590	models	_	_
10-28	3591-3594	ind	_	_
10-29	3595-3598	the	_	_
10-30	3599-3605	folder	_	_
10-31	3607-3608	\*	_	_
10-32	3609-3610	\*	_	_
10-33	3610-3611	\*	_	_
10-34	3611-3616	check	_	_
10-35	3617-3629	intermediate	_	_
10-36	3630-3637	results	_	_
10-37	3637-3638	\*	_	_
10-38	3638-3639	\*	_	_
10-39	3639-3640	:	_	_
10-40	3641-3644	the	_	_
10-41	3645-3650	model	_	_
10-42	3651-3662	checkpoints	_	_
10-43	3663-3666	and	_	_
10-44	3667-3670	log	_	_
10-45	3671-3676	files	_	_
10-46	3677-3680	are	_	_
10-47	3681-3686	saved	_	_
10-48	3687-3689	in	_	_
10-49	3690-3693	the	_	_
10-50	3694-3702	selected	_	_
10-51	3703-3716	log-directory	_	_
10-52	3717-3718	(	_	_
10-53	3718-3720	by	_	_
10-54	3721-3728	default	_	_
10-55	3728-3729	:	_	_
10-56	3730-3731	`	_	_
10-57	3731-3732	/	_	_
10-58	3732-3735	log	_	_
10-59	3735-3736	`	_	_
10-60	3736-3737	)	_	_
10-61	3737-3738	.	_	_

#Text=You can print a summary of the results with `python browse\_results <log path>`.     ### Datasets:  The method is tested on the following datasets:  \* CUB200-2011 (http://www.vision.caltech.edu/visipedia/CUB-200.html) \* CARS196 (https://ai.stanford.edu/~jkrause/cars/car\_dataset.html) \* Stanford Online Products (http://cvgl.stanford.edu/projects/lifted\_struct/) \* In-shop Clothes Retrieval Benchmark (http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion.html) \* PKU VehicleID (https://www.pkuml.org/resources/pku-vehicleid.html)  Assuming your folder is placed in e.g.
11-1	3740-3743	You	_	_
11-2	3744-3747	can	_	_
11-3	3748-3753	print	_	_
11-4	3754-3755	a	_	_
11-5	3756-3763	summary	_	_
11-6	3764-3766	of	_	_
11-7	3767-3770	the	_	_
11-8	3771-3778	results	_	_
11-9	3779-3783	with	_	_
11-10	3784-3785	`	_	_
11-11	3785-3791	python	_	_
11-12	3792-3806	browse\_results	_	_
11-13	3807-3808	<	_	_
11-14	3808-3811	log	_	_
11-15	3812-3816	path	_	_
11-16	3816-3817	>	_	_
11-17	3817-3818	`	_	_
11-18	3818-3819	.	_	_
11-19	3824-3825	#	_	_
11-20	3825-3826	#	_	_
11-21	3826-3827	#	_	_
11-22	3828-3836	Datasets	_	_
11-23	3836-3837	:	_	_
11-24	3839-3842	The	_	_
11-25	3843-3849	method	_	_
11-26	3850-3852	is	_	_
11-27	3853-3859	tested	_	_
11-28	3860-3862	on	_	_
11-29	3863-3866	the	_	_
11-30	3867-3876	following	_	_
11-31	3877-3885	datasets	_	_
11-32	3885-3886	:	_	_
11-33	3888-3889	\*	_	_
11-34	3890-3896	CUB200	_	_
11-35	3896-3897	-	_	_
11-36	3897-3901	2011	_	_
11-37	3902-3903	(	_	_
11-38	3903-3907	http	_	_
11-39	3907-3908	:	_	_
11-40	3908-3909	/	_	_
11-41	3909-3910	/	_	_
11-42	3910-3932	www.vision.caltech.edu	_	_
11-43	3932-3933	/	_	_
11-44	3933-3942	visipedia	_	_
11-45	3942-3943	/	_	_
11-46	3943-3946	CUB	_	_
11-47	3946-3947	-	_	_
11-48	3947-3950	200	_	_
11-49	3950-3951	.	_	_
11-50	3951-3955	html	_	_
11-51	3955-3956	)	_	_
11-52	3957-3958	\*	_	_
11-53	3959-3966	CARS196	_	_
11-54	3967-3968	(	_	_
11-55	3968-3973	https	_	_
11-56	3973-3974	:	_	_
11-57	3974-3975	/	_	_
11-58	3975-3976	/	_	_
11-59	3976-3991	ai.stanford.edu	_	_
11-60	3991-3992	/	_	_
11-61	3992-3993	~	_	_
11-62	3993-4000	jkrause	_	_
11-63	4000-4001	/	_	_
11-64	4001-4005	cars	_	_
11-65	4005-4006	/	_	_
11-66	4006-4022	car\_dataset.html	_	_
11-67	4022-4023	)	_	_
11-68	4024-4025	\*	_	_
11-69	4026-4034	Stanford	_	_
11-70	4035-4041	Online	_	_
11-71	4042-4050	Products	_	_
11-72	4051-4052	(	_	_
11-73	4052-4056	http	_	_
11-74	4056-4057	:	_	_
11-75	4057-4058	/	_	_
11-76	4058-4059	/	_	_
11-77	4059-4076	cvgl.stanford.edu	_	_
11-78	4076-4077	/	_	_
11-79	4077-4085	projects	_	_
11-80	4085-4086	/	_	_
11-81	4086-4099	lifted\_struct	_	_
11-82	4099-4100	/	_	_
11-83	4100-4101	)	_	_
11-84	4102-4103	\*	_	_
11-85	4104-4111	In-shop	_	_
11-86	4112-4119	Clothes	_	_
11-87	4120-4129	Retrieval	_	_
11-88	4130-4139	Benchmark	_	_
11-89	4140-4141	(	_	_
11-90	4141-4145	http	_	_
11-91	4145-4146	:	_	_
11-92	4146-4147	/	_	_
11-93	4147-4148	/	_	_
11-94	4148-4168	mmlab.ie.cuhk.edu.hk	_	_
11-95	4168-4169	/	_	_
11-96	4169-4177	projects	_	_
11-97	4177-4178	/	_	_
11-98	4178-4194	DeepFashion.html	_	_
11-99	4194-4195	)	_	_
11-100	4196-4197	\*	_	_
11-101	4198-4201	PKU	_	_
11-102	4202-4211	VehicleID	_	_
11-103	4212-4213	(	_	_
11-104	4213-4218	https	_	_
11-105	4218-4219	:	_	_
11-106	4219-4220	/	_	_
11-107	4220-4221	/	_	_
11-108	4221-4234	www.pkuml.org	_	_
11-109	4234-4235	/	_	_
11-110	4235-4244	resources	_	_
11-111	4244-4245	/	_	_
11-112	4245-4263	pku-vehicleid.html	_	_
11-112	4245-4258	pku-vehicleid	_	_
11-113	4263-4264	)	_	_
11-114	4266-4274	Assuming	_	_
11-115	4275-4279	your	_	_
11-116	4280-4286	folder	_	_
11-117	4287-4289	is	_	_
11-118	4290-4296	placed	_	_
11-119	4297-4299	in	_	_
11-120	4300-4303	e.g	_	_
11-121	4303-4304	.	_	_

#Text=`<$datadir/cars196>`, pass `$datadir` as input to `--dataset-dir`, by default.
12-1	4305-4306	`	_	_
12-2	4306-4307	<	_	_
12-3	4307-4308	$	_	_
12-4	4308-4315	datadir	_	_
12-5	4315-4316	/	_	_
12-6	4316-4323	cars196	_	_
12-7	4323-4324	>	_	_
12-8	4324-4325	`	_	_
12-9	4325-4326	,	_	_
12-10	4327-4331	pass	_	_
12-11	4332-4333	`	_	_
12-12	4333-4334	$	_	_
12-13	4334-4341	datadir	_	_
12-14	4341-4342	`	_	_
12-15	4343-4345	as	_	_
12-16	4346-4351	input	_	_
12-17	4352-4354	to	_	_
12-18	4355-4356	`	_	_
12-19	4356-4357	-	_	_
12-20	4357-4358	-	_	_
12-21	4358-4369	dataset-dir	_	_
12-22	4369-4370	`	_	_
12-23	4370-4371	,	_	_
12-24	4372-4374	by	_	_
12-25	4375-4382	default	_	_
12-26	4382-4383	.	_	_

#Text=To avoid conflicts between the folder structure and our pipeline, please make sure that the datasets  have the following internal structure:  \* For CUB200-2011, ``` cub-200-2011 └───images \|    └───001.Black\_footed\_Albatross \|           │   Black\_Footed\_Albatross\_0001\_796111 \|           │   ... \|    ... ``` \* For Cars196, please download the tar of all images, all bounding boxes, labels for both training and test  \[here\](http://ai.stanford.edu/~jkrause/cars/car\_dataset.html) and unzip them, which is consistent with our dataloader. ``` cars196 └───car\_ims \|    │016180.jpg \|    │   ... \|    │016185.jpg └───cars\_train \|    │08092.jpg \|    │   ... \|    │08144.jpg └───cars\_annos.mat  ```  \* For Stanford Online Products: ``` sop └───bicycle\_final \|   │   111085122871\_0.jpg \|           ... \|...
13-1	4384-4386	To	_	_
13-2	4387-4392	avoid	_	_
13-3	4393-4402	conflicts	_	_
13-4	4403-4410	between	_	_
13-5	4411-4414	the	_	_
13-6	4415-4421	folder	_	_
13-7	4422-4431	structure	_	_
13-8	4432-4435	and	_	_
13-9	4436-4439	our	_	_
13-10	4440-4448	pipeline	_	_
13-11	4448-4449	,	_	_
13-12	4450-4456	please	_	_
13-13	4457-4461	make	_	_
13-14	4462-4466	sure	_	_
13-15	4467-4471	that	_	_
13-16	4472-4475	the	_	_
13-17	4476-4484	datasets	_	_
13-18	4486-4490	have	_	_
13-19	4491-4494	the	_	_
13-20	4495-4504	following	_	_
13-21	4505-4513	internal	_	_
13-22	4514-4523	structure	_	_
13-23	4523-4524	:	_	_
13-24	4526-4527	\*	_	_
13-25	4528-4531	For	_	_
13-26	4532-4538	CUB200	_	_
13-27	4538-4539	-	_	_
13-28	4539-4543	2011	_	_
13-29	4543-4544	,	_	_
13-30	4545-4546	`	_	_
13-31	4546-4547	`	_	_
13-32	4547-4548	`	_	_
13-33	4549-4552	cub	_	_
13-34	4552-4553	-	_	_
13-35	4553-4556	200	_	_
13-36	4556-4557	-	_	_
13-37	4557-4561	2011	_	_
13-38	4562-4563	└	_	_
13-39	4563-4564	─	_	_
13-40	4564-4565	─	_	_
13-41	4565-4566	─	_	_
13-42	4566-4572	images	_	_
13-43	4573-4574	\|	_	_
13-44	4578-4579	└	_	_
13-45	4579-4580	─	_	_
13-46	4580-4581	─	_	_
13-47	4581-4582	─	_	_
13-48	4582-4585	001	_	_
13-49	4585-4586	.	_	_
13-50	4586-4608	Black\_footed\_Albatross	_	_
13-51	4609-4610	\|	_	_
13-52	4621-4622	│	_	_
13-53	4625-4647	Black\_Footed\_Albatross	_	_
13-54	4647-4648	\_	_	_
13-55	4648-4652	0001	_	_
13-56	4652-4653	\_	_	_
13-57	4653-4659	796111	_	_
13-58	4660-4661	\|	_	_
13-59	4672-4673	│	_	_
13-60	4676-4677	.	_	_
13-61	4677-4678	.	_	_
13-62	4678-4679	.	_	_
13-63	4680-4681	\|	_	_
13-64	4685-4686	.	_	_
13-65	4686-4687	.	_	_
13-66	4687-4688	.	_	_
13-67	4689-4690	`	_	_
13-68	4690-4691	`	_	_
13-69	4691-4692	`	_	_
13-70	4693-4694	\*	_	_
13-71	4695-4698	For	_	_
13-72	4699-4706	Cars196	_	_
13-73	4706-4707	,	_	_
13-74	4708-4714	please	_	_
13-75	4715-4723	download	_	_
13-76	4724-4727	the	_	_
13-77	4728-4731	tar	_	_
13-78	4732-4734	of	_	_
13-79	4735-4738	all	_	_
13-80	4739-4745	images	_	_
13-81	4745-4746	,	_	_
13-82	4747-4750	all	_	_
13-83	4751-4759	bounding	_	_
13-84	4760-4765	boxes	_	_
13-85	4765-4766	,	_	_
13-86	4767-4773	labels	_	_
13-87	4774-4777	for	_	_
13-88	4778-4782	both	_	_
13-89	4783-4791	training	_	_
13-90	4792-4795	and	_	_
13-91	4796-4800	test	_	_
13-92	4802-4803	\[	_	_
13-93	4803-4807	here	_	_
13-94	4807-4808	\]	_	_
13-95	4808-4809	(	_	_
13-96	4809-4813	http	_	_
13-97	4813-4814	:	_	_
13-98	4814-4815	/	_	_
13-99	4815-4816	/	_	_
13-100	4816-4831	ai.stanford.edu	_	_
13-101	4831-4832	/	_	_
13-102	4832-4833	~	_	_
13-103	4833-4840	jkrause	_	_
13-104	4840-4841	/	_	_
13-105	4841-4845	cars	_	_
13-106	4845-4846	/	_	_
13-107	4846-4862	car\_dataset.html	_	_
13-108	4862-4863	)	_	_
13-109	4864-4867	and	_	_
13-110	4868-4873	unzip	_	_
13-111	4874-4878	them	_	_
13-112	4878-4879	,	_	_
13-113	4880-4885	which	_	_
13-114	4886-4888	is	_	_
13-115	4889-4899	consistent	_	_
13-116	4900-4904	with	_	_
13-117	4905-4908	our	_	_
13-118	4909-4919	dataloader	_	_
13-119	4919-4920	.	_	_
13-120	4921-4922	`	_	_
13-121	4922-4923	`	_	_
13-122	4923-4924	`	_	_
13-123	4925-4932	cars196	_	_
13-124	4933-4934	└	_	_
13-125	4934-4935	─	_	_
13-126	4935-4936	─	_	_
13-127	4936-4937	─	_	_
13-128	4937-4944	car\_ims	_	_
13-129	4945-4946	\|	_	_
13-130	4950-4951	│	_	_
13-131	4951-4957	016180	_	_
13-132	4957-4958	.	_	_
13-133	4958-4961	jpg	_	_
13-134	4962-4963	\|	_	_
13-135	4967-4968	│	_	_
13-136	4971-4972	.	_	_
13-137	4972-4973	.	_	_
13-138	4973-4974	.	_	_
13-139	4975-4976	\|	_	_
13-140	4980-4981	│	_	_
13-141	4981-4987	016185	_	_
13-142	4987-4988	.	_	_
13-143	4988-4991	jpg	_	_
13-144	4992-4993	└	_	_
13-145	4993-4994	─	_	_
13-146	4994-4995	─	_	_
13-147	4995-4996	─	_	_
13-148	4996-5006	cars\_train	_	_
13-149	5007-5008	\|	_	_
13-150	5012-5013	│	_	_
13-151	5013-5018	08092	_	_
13-152	5018-5019	.	_	_
13-153	5019-5022	jpg	_	_
13-154	5023-5024	\|	_	_
13-155	5028-5029	│	_	_
13-156	5032-5033	.	_	_
13-157	5033-5034	.	_	_
13-158	5034-5035	.	_	_
13-159	5036-5037	\|	_	_
13-160	5041-5042	│	_	_
13-161	5042-5047	08144	_	_
13-162	5047-5048	.	_	_
13-163	5048-5051	jpg	_	_
13-164	5052-5053	└	_	_
13-165	5053-5054	─	_	_
13-166	5054-5055	─	_	_
13-167	5055-5056	─	_	_
13-168	5056-5070	cars\_annos.mat	_	_
13-169	5072-5073	`	_	_
13-170	5073-5074	`	_	_
13-171	5074-5075	`	_	_
13-172	5077-5078	\*	_	_
13-173	5079-5082	For	_	_
13-174	5083-5091	Stanford	_	_
13-175	5092-5098	Online	_	_
13-176	5099-5107	Products	_	_
13-177	5107-5108	:	_	_
13-178	5109-5110	`	_	_
13-179	5110-5111	`	_	_
13-180	5111-5112	`	_	_
13-181	5113-5116	sop	_	_
13-182	5117-5118	└	_	_
13-183	5118-5119	─	_	_
13-184	5119-5120	─	_	_
13-185	5120-5121	─	_	_
13-186	5121-5134	bicycle\_final	_	_
13-187	5135-5136	\|	_	_
13-188	5139-5140	│	_	_
13-189	5143-5155	111085122871	_	_
13-190	5155-5156	\_	_	_
13-191	5156-5157	0	_	_
13-192	5157-5158	.	_	_
13-193	5158-5161	jpg	_	_
13-194	5162-5163	\|	_	_
13-195	5174-5175	.	_	_
13-196	5175-5176	.	_	_
13-197	5176-5177	.	_	_
13-198	5178-5179	\|	_	_
13-199	5179-5180	.	_	_
13-200	5180-5181	.	_	_
13-201	5181-5182	.	_	_

#Text=└───cabinet\_final \|   │   xxx.jpg \|       ... \| bicycle.txt \| ... \| cabinet\_final.txt ```  \* For In-shop Clothes and PKU Vehicle id datasets, simply download them from the above given links and unzip their folder as they originally are.   ## Results  \_\_CUB200\_\_  Variants \| Loss/Sampling \|   NMI  \|  mARP  \| Recall @ 1 -- 2 -- 4 -- 8 ---------\|--------------- \|--------\|------\|----------------- fixed \|  Margin/Distance    \| 68.60 \| 54.98 \| 67.39 -- 77.43 --  84.82 --  90.83     learn \|  Margin/Distance    \| 69.84 \| 55.11 \| \_\_67.71\_\_ --  78.14 --  85.80 --  91.46   \_\_Cars196\_\_  Variants \| Loss/Sampling \|   NMI  \|  mARP  \| Recall @ 1 -- 2 -- 4 -- 8 ---------\|--------------- \|--------\|------\|----------------- fixed \|  Margin/Distance    \| 70.57 \| 65.89 \| \_\_87.22\_\_ -- 92.19 --  95.39 --  97.43     learn \|  Margin/Distance    \| 70.10 \| 65.54 \| 86.90 --  92.34 --  95.41 --  97.45   \_\_In-Shop Clothes\_\_  Variants \| Loss/Sampling    \|   NMI  \|  mARP  \| Recall @ 1 -- 10 -- 20 -- 30 ------\|---------------      \|--------\|------\|----------------- fixed \|  Margin/Distance \| 89.76 \| 87.86\| 89.84 -- 97.56 -- 98.21 -- 98.51 learn \|  Margin/Distance    \| 89.88 \| 88.50\| \_\_90.49\_\_ -- 97.48 -- 98.23 -- 98.51  \_\_Online Products\_\_  Variants \| Loss/Sampling \|   NMI  \|  mARP  \| Recall @ 1 -- 10 -- 100 ---------\|--------------- \|--------\|------\|----------------- fixed \|  Margin/Distance    \| 89.59 \| 79.32\| 79.50 -- 90.44 -- 95.08     learn \|  Margin/Distance    \| 89.68 \| 79.60\| \_\_79.80\_\_ --  90.46 --  95.26   \_\_VID (Large eval set)\_\_   Variants \| Loss/Sampling \|   NMI  \|  mARP  \| Recall @ 1 -- 5 ------\|---------------      \|--------\|------\|----------------- fixed \|  Margin/Distance \| 90.78 \| 92.89 \| \_\_94.01\_\_ -- 96.18 learn \|  Margin/Distance    \| 90.70 \| 92.68 \| 93.93 -- 95.99    \_Disclaimer: The results above are slightly different from those on the paper, as they were obtained before the code refactoring and with PyTorch (0.4.1) and Faiss (1.4.0).
14-1	5183-5184	└	_	_
14-2	5184-5185	─	_	_
14-3	5185-5186	─	_	_
14-4	5186-5187	─	_	_
14-5	5187-5200	cabinet\_final	_	_
14-6	5201-5202	\|	_	_
14-7	5205-5206	│	_	_
14-8	5209-5216	xxx.jpg	_	_
14-9	5217-5218	\|	_	_
14-10	5225-5226	.	_	_
14-11	5226-5227	.	_	_
14-12	5227-5228	.	_	_
14-13	5229-5230	\|	_	_
14-14	5231-5242	bicycle.txt	_	_
14-15	5243-5244	\|	_	_
14-16	5245-5246	.	_	_
14-17	5246-5247	.	_	_
14-18	5247-5248	.	_	_
14-19	5249-5250	\|	_	_
14-20	5251-5268	cabinet\_final.txt	_	_
14-21	5269-5270	`	_	_
14-22	5270-5271	`	_	_
14-23	5271-5272	`	_	_
14-24	5274-5275	\*	_	_
14-25	5276-5279	For	_	_
14-26	5280-5287	In-shop	_	_
14-27	5288-5295	Clothes	_	_
14-28	5296-5299	and	_	_
14-29	5300-5303	PKU	_	_
14-30	5304-5311	Vehicle	_	_
14-31	5312-5314	id	_	_
14-32	5315-5323	datasets	_	_
14-33	5323-5324	,	_	_
14-34	5325-5331	simply	_	_
14-35	5332-5340	download	_	_
14-36	5341-5345	them	_	_
14-37	5346-5350	from	_	_
14-38	5351-5354	the	_	_
14-39	5355-5360	above	_	_
14-40	5361-5366	given	_	_
14-41	5367-5372	links	_	_
14-42	5373-5376	and	_	_
14-43	5377-5382	unzip	_	_
14-44	5383-5388	their	_	_
14-45	5389-5395	folder	_	_
14-46	5396-5398	as	_	_
14-47	5399-5403	they	_	_
14-48	5404-5414	originally	_	_
14-49	5415-5418	are	_	_
14-50	5418-5419	.	_	_
14-51	5422-5423	#	_	_
14-52	5423-5424	#	_	_
14-53	5425-5432	Results	_	_
14-54	5434-5435	\_	_	_
14-55	5435-5436	\_	_	_
14-56	5436-5442	CUB200	_	_
14-57	5442-5443	\_	_	_
14-58	5443-5444	\_	_	_
14-59	5446-5454	Variants	_	_
14-60	5455-5456	\|	_	_
14-61	5457-5461	Loss	_	_
14-62	5461-5462	/	_	_
14-63	5462-5470	Sampling	_	_
14-64	5471-5472	\|	_	_
14-65	5475-5478	NMI	_	_
14-66	5480-5481	\|	_	_
14-67	5483-5487	mARP	_	_
14-68	5489-5490	\|	_	_
14-69	5491-5497	Recall	_	_
14-70	5498-5499	@	_	_
14-71	5500-5501	1	_	_
14-72	5502-5503	-	_	_
14-73	5503-5504	-	_	_
14-74	5505-5506	2	_	_
14-75	5507-5508	-	_	_
14-76	5508-5509	-	_	_
14-77	5510-5511	4	_	_
14-78	5512-5513	-	_	_
14-79	5513-5514	-	_	_
14-80	5515-5516	8	_	_
14-81	5517-5518	-	_	_
14-82	5518-5519	-	_	_
14-83	5519-5520	-	_	_
14-84	5520-5521	-	_	_
14-85	5521-5522	-	_	_
14-86	5522-5523	-	_	_
14-87	5523-5524	-	_	_
14-88	5524-5525	-	_	_
14-89	5525-5526	-	_	_
14-90	5526-5527	\|	_	_
14-91	5527-5528	-	_	_
14-92	5528-5529	-	_	_
14-93	5529-5530	-	_	_
14-94	5530-5531	-	_	_
14-95	5531-5532	-	_	_
14-96	5532-5533	-	_	_
14-97	5533-5534	-	_	_
14-98	5534-5535	-	_	_
14-99	5535-5536	-	_	_
14-100	5536-5537	-	_	_
14-101	5537-5538	-	_	_
14-102	5538-5539	-	_	_
14-103	5539-5540	-	_	_
14-104	5540-5541	-	_	_
14-105	5541-5542	-	_	_
14-106	5543-5544	\|	_	_
14-107	5544-5545	-	_	_
14-108	5545-5546	-	_	_
14-109	5546-5547	-	_	_
14-110	5547-5548	-	_	_
14-111	5548-5549	-	_	_
14-112	5549-5550	-	_	_
14-113	5550-5551	-	_	_
14-114	5551-5552	-	_	_
14-115	5552-5553	\|	_	_
14-116	5553-5554	-	_	_
14-117	5554-5555	-	_	_
14-118	5555-5556	-	_	_
14-119	5556-5557	-	_	_
14-120	5557-5558	-	_	_
14-121	5558-5559	-	_	_
14-122	5559-5560	\|	_	_
14-123	5560-5561	-	_	_
14-124	5561-5562	-	_	_
14-125	5562-5563	-	_	_
14-126	5563-5564	-	_	_
14-127	5564-5565	-	_	_
14-128	5565-5566	-	_	_
14-129	5566-5567	-	_	_
14-130	5567-5568	-	_	_
14-131	5568-5569	-	_	_
14-132	5569-5570	-	_	_
14-133	5570-5571	-	_	_
14-134	5571-5572	-	_	_
14-135	5572-5573	-	_	_
14-136	5573-5574	-	_	_
14-137	5574-5575	-	_	_
14-138	5575-5576	-	_	_
14-139	5576-5577	-	_	_
14-140	5578-5583	fixed	_	_
14-141	5584-5585	\|	_	_
14-142	5587-5593	Margin	_	_
14-143	5593-5594	/	_	_
14-144	5594-5602	Distance	_	_
14-145	5606-5607	\|	_	_
14-146	5608-5613	68.60	_	_
14-147	5614-5615	\|	_	_
14-148	5616-5621	54.98	_	_
14-149	5622-5623	\|	_	_
14-150	5624-5629	67.39	_	_
14-151	5630-5631	-	_	_
14-152	5631-5632	-	_	_
14-153	5633-5638	77.43	_	_
14-154	5639-5640	-	_	_
14-155	5640-5641	-	_	_
14-156	5643-5648	84.82	_	_
14-157	5649-5650	-	_	_
14-158	5650-5651	-	_	_
14-159	5653-5658	90.83	_	_
14-160	5663-5668	learn	_	_
14-161	5669-5670	\|	_	_
14-162	5672-5678	Margin	_	_
14-163	5678-5679	/	_	_
14-164	5679-5687	Distance	_	_
14-165	5691-5692	\|	_	_
14-166	5693-5698	69.84	_	_
14-167	5699-5700	\|	_	_
14-168	5701-5706	55.11	_	_
14-169	5707-5708	\|	_	_
14-170	5709-5710	\_	_	_
14-171	5710-5711	\_	_	_
14-172	5711-5716	67.71	_	_
14-173	5716-5717	\_	_	_
14-174	5717-5718	\_	_	_
14-175	5719-5720	-	_	_
14-176	5720-5721	-	_	_
14-177	5723-5728	78.14	_	_
14-178	5729-5730	-	_	_
14-179	5730-5731	-	_	_
14-180	5733-5738	85.80	_	_
14-181	5739-5740	-	_	_
14-182	5740-5741	-	_	_
14-183	5743-5748	91.46	_	_
14-184	5751-5752	\_	_	_
14-185	5752-5753	\_	_	_
14-186	5753-5760	Cars196	_	_
14-187	5760-5761	\_	_	_
14-188	5761-5762	\_	_	_
14-189	5764-5772	Variants	_	_
14-190	5773-5774	\|	_	_
14-191	5775-5779	Loss	_	_
14-192	5779-5780	/	_	_
14-193	5780-5788	Sampling	_	_
14-194	5789-5790	\|	_	_
14-195	5793-5796	NMI	_	_
14-196	5798-5799	\|	_	_
14-197	5801-5805	mARP	_	_
14-198	5807-5808	\|	_	_
14-199	5809-5815	Recall	_	_
14-200	5816-5817	@	_	_
14-201	5818-5819	1	_	_
14-202	5820-5821	-	_	_
14-203	5821-5822	-	_	_
14-204	5823-5824	2	_	_
14-205	5825-5826	-	_	_
14-206	5826-5827	-	_	_
14-207	5828-5829	4	_	_
14-208	5830-5831	-	_	_
14-209	5831-5832	-	_	_
14-210	5833-5834	8	_	_
14-211	5835-5836	-	_	_
14-212	5836-5837	-	_	_
14-213	5837-5838	-	_	_
14-214	5838-5839	-	_	_
14-215	5839-5840	-	_	_
14-216	5840-5841	-	_	_
14-217	5841-5842	-	_	_
14-218	5842-5843	-	_	_
14-219	5843-5844	-	_	_
14-220	5844-5845	\|	_	_
14-221	5845-5846	-	_	_
14-222	5846-5847	-	_	_
14-223	5847-5848	-	_	_
14-224	5848-5849	-	_	_
14-225	5849-5850	-	_	_
14-226	5850-5851	-	_	_
14-227	5851-5852	-	_	_
14-228	5852-5853	-	_	_
14-229	5853-5854	-	_	_
14-230	5854-5855	-	_	_
14-231	5855-5856	-	_	_
14-232	5856-5857	-	_	_
14-233	5857-5858	-	_	_
14-234	5858-5859	-	_	_
14-235	5859-5860	-	_	_
14-236	5861-5862	\|	_	_
14-237	5862-5863	-	_	_
14-238	5863-5864	-	_	_
14-239	5864-5865	-	_	_
14-240	5865-5866	-	_	_
14-241	5866-5867	-	_	_
14-242	5867-5868	-	_	_
14-243	5868-5869	-	_	_
14-244	5869-5870	-	_	_
14-245	5870-5871	\|	_	_
14-246	5871-5872	-	_	_
14-247	5872-5873	-	_	_
14-248	5873-5874	-	_	_
14-249	5874-5875	-	_	_
14-250	5875-5876	-	_	_
14-251	5876-5877	-	_	_
14-252	5877-5878	\|	_	_
14-253	5878-5879	-	_	_
14-254	5879-5880	-	_	_
14-255	5880-5881	-	_	_
14-256	5881-5882	-	_	_
14-257	5882-5883	-	_	_
14-258	5883-5884	-	_	_
14-259	5884-5885	-	_	_
14-260	5885-5886	-	_	_
14-261	5886-5887	-	_	_
14-262	5887-5888	-	_	_
14-263	5888-5889	-	_	_
14-264	5889-5890	-	_	_
14-265	5890-5891	-	_	_
14-266	5891-5892	-	_	_
14-267	5892-5893	-	_	_
14-268	5893-5894	-	_	_
14-269	5894-5895	-	_	_
14-270	5896-5901	fixed	_	_
14-271	5902-5903	\|	_	_
14-272	5905-5911	Margin	_	_
14-273	5911-5912	/	_	_
14-274	5912-5920	Distance	_	_
14-275	5924-5925	\|	_	_
14-276	5926-5931	70.57	_	_
14-277	5932-5933	\|	_	_
14-278	5934-5939	65.89	_	_
14-279	5940-5941	\|	_	_
14-280	5942-5943	\_	_	_
14-281	5943-5944	\_	_	_
14-282	5944-5949	87.22	_	_
14-283	5949-5950	\_	_	_
14-284	5950-5951	\_	_	_
14-285	5952-5953	-	_	_
14-286	5953-5954	-	_	_
14-287	5955-5960	92.19	_	_
14-288	5961-5962	-	_	_
14-289	5962-5963	-	_	_
14-290	5965-5970	95.39	_	_
14-291	5971-5972	-	_	_
14-292	5972-5973	-	_	_
14-293	5975-5980	97.43	_	_
14-294	5985-5990	learn	_	_
14-295	5991-5992	\|	_	_
14-296	5994-6000	Margin	_	_
14-297	6000-6001	/	_	_
14-298	6001-6009	Distance	_	_
14-299	6013-6014	\|	_	_
14-300	6015-6020	70.10	_	_
14-301	6021-6022	\|	_	_
14-302	6023-6028	65.54	_	_
14-303	6029-6030	\|	_	_
14-304	6031-6036	86.90	_	_
14-305	6037-6038	-	_	_
14-306	6038-6039	-	_	_
14-307	6041-6046	92.34	_	_
14-308	6047-6048	-	_	_
14-309	6048-6049	-	_	_
14-310	6051-6056	95.41	_	_
14-311	6057-6058	-	_	_
14-312	6058-6059	-	_	_
14-313	6061-6066	97.45	_	_
14-314	6069-6070	\_	_	_
14-315	6070-6071	\_	_	_
14-316	6071-6078	In-Shop	_	_
14-317	6079-6086	Clothes	_	_
14-318	6086-6087	\_	_	_
14-319	6087-6088	\_	_	_
14-320	6090-6098	Variants	_	_
14-321	6099-6100	\|	_	_
14-322	6101-6105	Loss	_	_
14-323	6105-6106	/	_	_
14-324	6106-6114	Sampling	_	_
14-325	6118-6119	\|	_	_
14-326	6122-6125	NMI	_	_
14-327	6127-6128	\|	_	_
14-328	6130-6134	mARP	_	_
14-329	6136-6137	\|	_	_
14-330	6138-6144	Recall	_	_
14-331	6145-6146	@	_	_
14-332	6147-6148	1	_	_
14-333	6149-6150	-	_	_
14-334	6150-6151	-	_	_
14-335	6152-6154	10	_	_
14-336	6155-6156	-	_	_
14-337	6156-6157	-	_	_
14-338	6158-6160	20	_	_
14-339	6161-6162	-	_	_
14-340	6162-6163	-	_	_
14-341	6164-6166	30	_	_
14-342	6167-6168	-	_	_
14-343	6168-6169	-	_	_
14-344	6169-6170	-	_	_
14-345	6170-6171	-	_	_
14-346	6171-6172	-	_	_
14-347	6172-6173	-	_	_
14-348	6173-6174	\|	_	_
14-349	6174-6175	-	_	_
14-350	6175-6176	-	_	_
14-351	6176-6177	-	_	_
14-352	6177-6178	-	_	_
14-353	6178-6179	-	_	_
14-354	6179-6180	-	_	_
14-355	6180-6181	-	_	_
14-356	6181-6182	-	_	_
14-357	6182-6183	-	_	_
14-358	6183-6184	-	_	_
14-359	6184-6185	-	_	_
14-360	6185-6186	-	_	_
14-361	6186-6187	-	_	_
14-362	6187-6188	-	_	_
14-363	6188-6189	-	_	_
14-364	6195-6196	\|	_	_
14-365	6196-6197	-	_	_
14-366	6197-6198	-	_	_
14-367	6198-6199	-	_	_
14-368	6199-6200	-	_	_
14-369	6200-6201	-	_	_
14-370	6201-6202	-	_	_
14-371	6202-6203	-	_	_
14-372	6203-6204	-	_	_
14-373	6204-6205	\|	_	_
14-374	6205-6206	-	_	_
14-375	6206-6207	-	_	_
14-376	6207-6208	-	_	_
14-377	6208-6209	-	_	_
14-378	6209-6210	-	_	_
14-379	6210-6211	-	_	_
14-380	6211-6212	\|	_	_
14-381	6212-6213	-	_	_
14-382	6213-6214	-	_	_
14-383	6214-6215	-	_	_
14-384	6215-6216	-	_	_
14-385	6216-6217	-	_	_
14-386	6217-6218	-	_	_
14-387	6218-6219	-	_	_
14-388	6219-6220	-	_	_
14-389	6220-6221	-	_	_
14-390	6221-6222	-	_	_
14-391	6222-6223	-	_	_
14-392	6223-6224	-	_	_
14-393	6224-6225	-	_	_
14-394	6225-6226	-	_	_
14-395	6226-6227	-	_	_
14-396	6227-6228	-	_	_
14-397	6228-6229	-	_	_
14-398	6230-6235	fixed	_	_
14-399	6236-6237	\|	_	_
14-400	6239-6245	Margin	_	_
14-401	6245-6246	/	_	_
14-402	6246-6254	Distance	_	_
14-403	6255-6256	\|	_	_
14-404	6257-6262	89.76	_	_
14-405	6263-6264	\|	_	_
14-406	6265-6270	87.86	_	_
14-407	6270-6271	\|	_	_
14-408	6272-6277	89.84	_	_
14-409	6278-6279	-	_	_
14-410	6279-6280	-	_	_
14-411	6281-6286	97.56	_	_
14-412	6287-6288	-	_	_
14-413	6288-6289	-	_	_
14-414	6290-6295	98.21	_	_
14-415	6296-6297	-	_	_
14-416	6297-6298	-	_	_
14-417	6299-6304	98.51	_	_
14-418	6305-6310	learn	_	_
14-419	6311-6312	\|	_	_
14-420	6314-6320	Margin	_	_
14-421	6320-6321	/	_	_
14-422	6321-6329	Distance	_	_
14-423	6333-6334	\|	_	_
14-424	6335-6340	89.88	_	_
14-425	6341-6342	\|	_	_
14-426	6343-6348	88.50	_	_
14-427	6348-6349	\|	_	_
14-428	6350-6351	\_	_	_
14-429	6351-6352	\_	_	_
14-430	6352-6357	90.49	_	_
14-431	6357-6358	\_	_	_
14-432	6358-6359	\_	_	_
14-433	6360-6361	-	_	_
14-434	6361-6362	-	_	_
14-435	6363-6368	97.48	_	_
14-436	6369-6370	-	_	_
14-437	6370-6371	-	_	_
14-438	6372-6377	98.23	_	_
14-439	6378-6379	-	_	_
14-440	6379-6380	-	_	_
14-441	6381-6386	98.51	_	_
14-442	6388-6389	\_	_	_
14-443	6389-6390	\_	_	_
14-444	6390-6396	Online	_	_
14-445	6397-6405	Products	_	_
14-446	6405-6406	\_	_	_
14-447	6406-6407	\_	_	_
14-448	6409-6417	Variants	_	_
14-449	6418-6419	\|	_	_
14-450	6420-6424	Loss	_	_
14-451	6424-6425	/	_	_
14-452	6425-6433	Sampling	_	_
14-453	6434-6435	\|	_	_
14-454	6438-6441	NMI	_	_
14-455	6443-6444	\|	_	_
14-456	6446-6450	mARP	_	_
14-457	6452-6453	\|	_	_
14-458	6454-6460	Recall	_	_
14-459	6461-6462	@	_	_
14-460	6463-6464	1	_	_
14-461	6465-6466	-	_	_
14-462	6466-6467	-	_	_
14-463	6468-6470	10	_	_
14-464	6471-6472	-	_	_
14-465	6472-6473	-	_	_
14-466	6474-6477	100	_	_
14-467	6478-6479	-	_	_
14-468	6479-6480	-	_	_
14-469	6480-6481	-	_	_
14-470	6481-6482	-	_	_
14-471	6482-6483	-	_	_
14-472	6483-6484	-	_	_
14-473	6484-6485	-	_	_
14-474	6485-6486	-	_	_
14-475	6486-6487	-	_	_
14-476	6487-6488	\|	_	_
14-477	6488-6489	-	_	_
14-478	6489-6490	-	_	_
14-479	6490-6491	-	_	_
14-480	6491-6492	-	_	_
14-481	6492-6493	-	_	_
14-482	6493-6494	-	_	_
14-483	6494-6495	-	_	_
14-484	6495-6496	-	_	_
14-485	6496-6497	-	_	_
14-486	6497-6498	-	_	_
14-487	6498-6499	-	_	_
14-488	6499-6500	-	_	_
14-489	6500-6501	-	_	_
14-490	6501-6502	-	_	_
14-491	6502-6503	-	_	_
14-492	6504-6505	\|	_	_
14-493	6505-6506	-	_	_
14-494	6506-6507	-	_	_
14-495	6507-6508	-	_	_
14-496	6508-6509	-	_	_
14-497	6509-6510	-	_	_
14-498	6510-6511	-	_	_
14-499	6511-6512	-	_	_
14-500	6512-6513	-	_	_
14-501	6513-6514	\|	_	_
14-502	6514-6515	-	_	_
14-503	6515-6516	-	_	_
14-504	6516-6517	-	_	_
14-505	6517-6518	-	_	_
14-506	6518-6519	-	_	_
14-507	6519-6520	-	_	_
14-508	6520-6521	\|	_	_
14-509	6521-6522	-	_	_
14-510	6522-6523	-	_	_
14-511	6523-6524	-	_	_
14-512	6524-6525	-	_	_
14-513	6525-6526	-	_	_
14-514	6526-6527	-	_	_
14-515	6527-6528	-	_	_
14-516	6528-6529	-	_	_
14-517	6529-6530	-	_	_
14-518	6530-6531	-	_	_
14-519	6531-6532	-	_	_
14-520	6532-6533	-	_	_
14-521	6533-6534	-	_	_
14-522	6534-6535	-	_	_
14-523	6535-6536	-	_	_
14-524	6536-6537	-	_	_
14-525	6537-6538	-	_	_
14-526	6539-6544	fixed	_	_
14-527	6545-6546	\|	_	_
14-528	6548-6554	Margin	_	_
14-529	6554-6555	/	_	_
14-530	6555-6563	Distance	_	_
14-531	6567-6568	\|	_	_
14-532	6569-6574	89.59	_	_
14-533	6575-6576	\|	_	_
14-534	6577-6582	79.32	_	_
14-535	6582-6583	\|	_	_
14-536	6584-6589	79.50	_	_
14-537	6590-6591	-	_	_
14-538	6591-6592	-	_	_
14-539	6593-6598	90.44	_	_
14-540	6599-6600	-	_	_
14-541	6600-6601	-	_	_
14-542	6602-6607	95.08	_	_
14-543	6612-6617	learn	_	_
14-544	6618-6619	\|	_	_
14-545	6621-6627	Margin	_	_
14-546	6627-6628	/	_	_
14-547	6628-6636	Distance	_	_
14-548	6640-6641	\|	_	_
14-549	6642-6647	89.68	_	_
14-550	6648-6649	\|	_	_
14-551	6650-6655	79.60	_	_
14-552	6655-6656	\|	_	_
14-553	6657-6658	\_	_	_
14-554	6658-6659	\_	_	_
14-555	6659-6664	79.80	_	_
14-556	6664-6665	\_	_	_
14-557	6665-6666	\_	_	_
14-558	6667-6668	-	_	_
14-559	6668-6669	-	_	_
14-560	6671-6676	90.46	_	_
14-561	6677-6678	-	_	_
14-562	6678-6679	-	_	_
14-563	6681-6686	95.26	_	_
14-564	6689-6690	\_	_	_
14-565	6690-6691	\_	_	_
14-566	6691-6694	VID	_	_
14-567	6695-6696	(	_	_
14-568	6696-6701	Large	_	_
14-569	6702-6706	eval	_	_
14-570	6707-6710	set	_	_
14-571	6710-6711	)	_	_
14-572	6711-6712	\_	_	_
14-573	6712-6713	\_	_	_
14-574	6716-6724	Variants	_	_
14-575	6725-6726	\|	_	_
14-576	6727-6731	Loss	_	_
14-577	6731-6732	/	_	_
14-578	6732-6740	Sampling	_	_
14-579	6741-6742	\|	_	_
14-580	6745-6748	NMI	_	_
14-581	6750-6751	\|	_	_
14-582	6753-6757	mARP	_	_
14-583	6759-6760	\|	_	_
14-584	6761-6767	Recall	_	_
14-585	6768-6769	@	_	_
14-586	6770-6771	1	_	_
14-587	6772-6773	-	_	_
14-588	6773-6774	-	_	_
14-589	6775-6776	5	_	_
14-590	6777-6778	-	_	_
14-591	6778-6779	-	_	_
14-592	6779-6780	-	_	_
14-593	6780-6781	-	_	_
14-594	6781-6782	-	_	_
14-595	6782-6783	-	_	_
14-596	6783-6784	\|	_	_
14-597	6784-6785	-	_	_
14-598	6785-6786	-	_	_
14-599	6786-6787	-	_	_
14-600	6787-6788	-	_	_
14-601	6788-6789	-	_	_
14-602	6789-6790	-	_	_
14-603	6790-6791	-	_	_
14-604	6791-6792	-	_	_
14-605	6792-6793	-	_	_
14-606	6793-6794	-	_	_
14-607	6794-6795	-	_	_
14-608	6795-6796	-	_	_
14-609	6796-6797	-	_	_
14-610	6797-6798	-	_	_
14-611	6798-6799	-	_	_
14-612	6805-6806	\|	_	_
14-613	6806-6807	-	_	_
14-614	6807-6808	-	_	_
14-615	6808-6809	-	_	_
14-616	6809-6810	-	_	_
14-617	6810-6811	-	_	_
14-618	6811-6812	-	_	_
14-619	6812-6813	-	_	_
14-620	6813-6814	-	_	_
14-621	6814-6815	\|	_	_
14-622	6815-6816	-	_	_
14-623	6816-6817	-	_	_
14-624	6817-6818	-	_	_
14-625	6818-6819	-	_	_
14-626	6819-6820	-	_	_
14-627	6820-6821	-	_	_
14-628	6821-6822	\|	_	_
14-629	6822-6823	-	_	_
14-630	6823-6824	-	_	_
14-631	6824-6825	-	_	_
14-632	6825-6826	-	_	_
14-633	6826-6827	-	_	_
14-634	6827-6828	-	_	_
14-635	6828-6829	-	_	_
14-636	6829-6830	-	_	_
14-637	6830-6831	-	_	_
14-638	6831-6832	-	_	_
14-639	6832-6833	-	_	_
14-640	6833-6834	-	_	_
14-641	6834-6835	-	_	_
14-642	6835-6836	-	_	_
14-643	6836-6837	-	_	_
14-644	6837-6838	-	_	_
14-645	6838-6839	-	_	_
14-646	6840-6845	fixed	_	_
14-647	6846-6847	\|	_	_
14-648	6849-6855	Margin	_	_
14-649	6855-6856	/	_	_
14-650	6856-6864	Distance	_	_
14-651	6865-6866	\|	_	_
14-652	6867-6872	90.78	_	_
14-653	6873-6874	\|	_	_
14-654	6875-6880	92.89	_	_
14-655	6881-6882	\|	_	_
14-656	6883-6884	\_	_	_
14-657	6884-6885	\_	_	_
14-658	6885-6890	94.01	_	_
14-659	6890-6891	\_	_	_
14-660	6891-6892	\_	_	_
14-661	6893-6894	-	_	_
14-662	6894-6895	-	_	_
14-663	6896-6901	96.18	_	_
14-664	6902-6907	learn	_	_
14-665	6908-6909	\|	_	_
14-666	6911-6917	Margin	_	_
14-667	6917-6918	/	_	_
14-668	6918-6926	Distance	_	_
14-669	6930-6931	\|	_	_
14-670	6932-6937	90.70	_	_
14-671	6938-6939	\|	_	_
14-672	6940-6945	92.68	_	_
14-673	6946-6947	\|	_	_
14-674	6948-6953	93.93	_	_
14-675	6954-6955	-	_	_
14-676	6955-6956	-	_	_
14-677	6957-6962	95.99	_	_
14-678	6966-6967	\_	_	_
14-679	6967-6977	Disclaimer	_	_
14-680	6977-6978	:	_	_
14-681	6979-6982	The	_	_
14-682	6983-6990	results	_	_
14-683	6991-6996	above	_	_
14-684	6997-7000	are	_	_
14-685	7001-7009	slightly	_	_
14-686	7010-7019	different	_	_
14-687	7020-7024	from	_	_
14-688	7025-7030	those	_	_
14-689	7031-7033	on	_	_
14-690	7034-7037	the	_	_
14-691	7038-7043	paper	_	_
14-692	7043-7044	,	_	_
14-693	7045-7047	as	_	_
14-694	7048-7052	they	_	_
14-695	7053-7057	were	_	_
14-696	7058-7066	obtained	_	_
14-697	7067-7073	before	_	_
14-698	7074-7077	the	_	_
14-699	7078-7082	code	_	_
14-700	7083-7094	refactoring	_	_
14-701	7095-7098	and	_	_
14-702	7099-7103	with	_	_
14-703	7104-7111	PyTorch	_	_
14-704	7112-7113	(	_	_
14-705	7113-7118	0.4.1	_	_
14-706	7118-7119	)	_	_
14-707	7120-7123	and	_	_
14-708	7124-7129	Faiss	_	_
14-709	7130-7131	(	_	_
14-710	7131-7136	1.4.0	_	_
14-711	7136-7137	)	_	_
14-712	7137-7138	.	_	_

#Text=Some deviations in results based on different PyTorch/Cuda/Faiss versions and hardware (e.g. between P100 and RTX GPUs) are to be expected.\_   ## Related Repos  \* Divide and Conquer the Embedding Space for Metric Learning (our previous paper on CVPR 2019):  https://github.com/CompVis/metric-learning-divide-and-conquer \* An easy-to-use repo to start your DML research, containing collections of models, losses, and samplers implemented in PyTorch: https://github.com/Confusezius/Revisiting\_Deep\_Metric\_Learning\_PyTorch  ## BibTex If you use this code in your research, please cite the following papers:  ``` @InProceedings{dcesml,   title={Divide and Conquer the Embedding Space for Metric Learning},   author={Sanakoyeu, Artsiom and Tschernezki, Vadim and B\\"uchler, Uta and Ommer, Bj\\"orn},   booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},   year={2019} }  @article{sanakoyeu2021improving,   title={Improving Deep Metric Learning by Divide and Conquer},    author={Artsiom Sanakoyeu and Pingchuan Ma and Vadim Tschernezki and Björn Ommer},   journal={IEEE Transactions on pattern analysis and machine intelligence},   year={2021},   publisher={IEEE} } ```
15-1	7139-7143	Some	_	_
15-2	7144-7154	deviations	_	_
15-3	7155-7157	in	_	_
15-4	7158-7165	results	_	_
15-5	7166-7171	based	_	_
15-6	7172-7174	on	_	_
15-7	7175-7184	different	_	_
15-8	7185-7192	PyTorch	_	_
15-9	7192-7193	/	_	_
15-10	7193-7197	Cuda	_	_
15-11	7197-7198	/	_	_
15-12	7198-7203	Faiss	_	_
15-13	7204-7212	versions	_	_
15-14	7213-7216	and	_	_
15-15	7217-7225	hardware	_	_
15-16	7226-7227	(	_	_
15-17	7227-7230	e.g	_	_
15-18	7230-7231	.	_	_
15-19	7232-7239	between	_	_
15-20	7240-7244	P100	_	_
15-21	7245-7248	and	_	_
15-22	7249-7252	RTX	_	_
15-23	7253-7257	GPUs	_	_
15-24	7257-7258	)	_	_
15-25	7259-7262	are	_	_
15-26	7263-7265	to	_	_
15-27	7266-7268	be	_	_
15-28	7269-7277	expected	_	_
15-29	7277-7278	.	_	_
15-30	7278-7279	\_	_	_
15-31	7282-7283	#	_	_
15-32	7283-7284	#	_	_
15-33	7285-7292	Related	_	_
15-34	7293-7298	Repos	_	_
15-35	7300-7301	\*	_	_
15-36	7302-7308	Divide	_	_
15-37	7309-7312	and	_	_
15-38	7313-7320	Conquer	_	_
15-39	7321-7324	the	_	_
15-40	7325-7334	Embedding	_	_
15-41	7335-7340	Space	_	_
15-42	7341-7344	for	_	_
15-43	7345-7351	Metric	_	_
15-44	7352-7360	Learning	_	_
15-45	7361-7362	(	_	_
15-46	7362-7365	our	_	_
15-47	7366-7374	previous	_	_
15-48	7375-7380	paper	_	_
15-49	7381-7383	on	_	_
15-50	7384-7388	CVPR	_	_
15-51	7389-7393	2019	_	_
15-52	7393-7394	)	_	_
15-53	7394-7395	:	_	_
15-54	7397-7402	https	_	_
15-55	7402-7403	:	_	_
15-56	7403-7404	/	_	_
15-57	7404-7405	/	_	_
15-58	7405-7415	github.com	_	_
15-59	7415-7416	/	_	_
15-60	7416-7423	CompVis	_	_
15-61	7423-7424	/	_	_
15-62	7424-7458	metric-learning-divide-and-conquer	_	_
15-63	7459-7460	\*	_	_
15-64	7461-7463	An	_	_
15-65	7464-7475	easy-to-use	_	_
15-66	7476-7480	repo	_	_
15-67	7481-7483	to	_	_
15-68	7484-7489	start	_	_
15-69	7490-7494	your	_	_
15-70	7495-7498	DML	_	_
15-71	7499-7507	research	_	_
15-72	7507-7508	,	_	_
15-73	7509-7519	containing	_	_
15-74	7520-7531	collections	_	_
15-75	7532-7534	of	_	_
15-76	7535-7541	models	_	_
15-77	7541-7542	,	_	_
15-78	7543-7549	losses	_	_
15-79	7549-7550	,	_	_
15-80	7551-7554	and	_	_
15-81	7555-7563	samplers	_	_
15-82	7564-7575	implemented	_	_
15-83	7576-7578	in	_	_
15-84	7579-7586	PyTorch	_	_
15-85	7586-7587	:	_	_
15-86	7588-7593	https	_	_
15-87	7593-7594	:	_	_
15-88	7594-7595	/	_	_
15-89	7595-7596	/	_	_
15-90	7596-7606	github.com	_	_
15-91	7606-7607	/	_	_
15-92	7607-7618	Confusezius	_	_
15-93	7618-7619	/	_	_
15-94	7619-7658	Revisiting\_Deep\_Metric\_Learning\_PyTorch	_	_
15-94	7651-7658	PyTorch	_	_
15-95	7660-7661	#	_	_
15-96	7661-7662	#	_	_
15-97	7663-7669	BibTex	_	_
15-98	7670-7672	If	_	_
15-99	7673-7676	you	_	_
15-100	7677-7680	use	_	_
15-101	7681-7685	this	_	_
15-102	7686-7690	code	_	_
15-103	7691-7693	in	_	_
15-104	7694-7698	your	_	_
15-105	7699-7707	research	_	_
15-106	7707-7708	,	_	_
15-107	7709-7715	please	_	_
15-108	7716-7720	cite	_	_
15-109	7721-7724	the	_	_
15-110	7725-7734	following	_	_
15-111	7735-7741	papers	_	_
15-112	7741-7742	:	_	_
15-113	7744-7745	`	_	_
15-114	7745-7746	`	_	_
15-115	7746-7747	`	_	_
15-116	7748-7749	@	_	_
15-117	7749-7762	InProceedings	_	_
15-118	7762-7763	{	_	_
15-119	7763-7769	dcesml	_	_
15-120	7769-7770	,	_	_
15-121	7773-7778	title	_	_
15-122	7778-7779	=	_	_
15-123	7779-7780	{	_	_
15-124	7780-7786	Divide	_	_
15-125	7787-7790	and	_	_
15-126	7791-7798	Conquer	_	_
15-127	7799-7802	the	_	_
15-128	7803-7812	Embedding	_	_
15-129	7813-7818	Space	_	_
15-130	7819-7822	for	_	_
15-131	7823-7829	Metric	_	_
15-132	7830-7838	Learning	_	_
15-133	7838-7839	}	_	_
15-134	7839-7840	,	_	_
15-135	7843-7849	author	_	_
15-136	7849-7850	=	_	_
15-137	7850-7851	{	_	_
15-138	7851-7860	Sanakoyeu	_	_
15-139	7860-7861	,	_	_
15-140	7862-7869	Artsiom	_	_
15-141	7870-7873	and	_	_
15-142	7874-7885	Tschernezki	_	_
15-143	7885-7886	,	_	_
15-144	7887-7892	Vadim	_	_
15-145	7893-7896	and	_	_
15-146	7897-7898	B	_	_
15-147	7898-7899	\\	_	_
15-148	7899-7900	"	_	_
15-149	7900-7906	uchler	_	_
15-150	7906-7907	,	_	_
15-151	7908-7911	Uta	_	_
15-152	7912-7915	and	_	_
15-153	7916-7921	Ommer	_	_
15-154	7921-7922	,	_	_
15-155	7923-7925	Bj	_	_
15-156	7925-7926	\\	_	_
15-157	7926-7927	"	_	_
15-158	7927-7930	orn	_	_
15-159	7930-7931	}	_	_
15-160	7931-7932	,	_	_
15-161	7935-7944	booktitle	_	_
15-162	7944-7945	=	_	_
15-163	7945-7946	{	_	_
15-164	7946-7957	Proceedings	_	_
15-165	7958-7960	of	_	_
15-166	7961-7964	the	_	_
15-167	7965-7969	IEEE	_	_
15-168	7970-7980	Conference	_	_
15-169	7981-7983	on	_	_
15-170	7984-7992	Computer	_	_
15-171	7993-7999	Vision	_	_
15-172	8000-8003	and	_	_
15-173	8004-8011	Pattern	_	_
15-174	8012-8023	Recognition	_	_
15-175	8023-8024	}	_	_
15-176	8024-8025	,	_	_
15-177	8028-8032	year	_	_
15-178	8032-8033	=	_	_
15-179	8033-8034	{	_	_
15-180	8034-8038	2019	_	_
15-181	8038-8039	}	_	_
15-182	8040-8041	}	_	_
15-183	8043-8044	@	_	_
15-184	8044-8051	article	_	_
15-185	8051-8052	{	_	_
15-186	8052-8074	sanakoyeu2021improving	_	_
15-187	8074-8075	,	_	_
15-188	8078-8083	title	_	_
15-189	8083-8084	=	_	_
15-190	8084-8085	{	_	_
15-191	8085-8094	Improving	_	_
15-192	8095-8099	Deep	_	_
15-193	8100-8106	Metric	_	_
15-194	8107-8115	Learning	_	_
15-195	8116-8118	by	_	_
15-196	8119-8125	Divide	_	_
15-197	8126-8129	and	_	_
15-198	8130-8137	Conquer	_	_
15-199	8137-8138	}	_	_
15-200	8138-8139	,	_	_
15-201	8143-8149	author	_	_
15-202	8149-8150	=	_	_
15-203	8150-8151	{	_	_
15-204	8151-8158	Artsiom	_	_
15-205	8159-8168	Sanakoyeu	_	_
15-206	8169-8172	and	_	_
15-207	8173-8182	Pingchuan	_	_
15-208	8183-8185	Ma	_	_
15-209	8186-8189	and	_	_
15-210	8190-8195	Vadim	_	_
15-211	8196-8207	Tschernezki	_	_
15-212	8208-8211	and	_	_
15-213	8212-8217	Björn	_	_
15-214	8218-8223	Ommer	_	_
15-215	8223-8224	}	_	_
15-216	8224-8225	,	_	_
15-217	8228-8235	journal	_	_
15-218	8235-8236	=	_	_
15-219	8236-8237	{	_	_
15-220	8237-8241	IEEE	_	_
15-221	8242-8254	Transactions	_	_
15-222	8255-8257	on	_	_
15-223	8258-8265	pattern	_	_
15-224	8266-8274	analysis	_	_
15-225	8275-8278	and	_	_
15-226	8279-8286	machine	_	_
15-227	8287-8299	intelligence	_	_
15-228	8299-8300	}	_	_
15-229	8300-8301	,	_	_
15-230	8304-8308	year	_	_
15-231	8308-8309	=	_	_
15-232	8309-8310	{	_	_
15-233	8310-8314	2021	_	_
15-234	8314-8315	}	_	_
15-235	8315-8316	,	_	_
15-236	8319-8328	publisher	_	_
15-237	8328-8329	=	_	_
15-238	8329-8330	{	_	_
15-239	8330-8334	IEEE	_	_
15-240	8334-8335	}	_	_
15-241	8336-8337	}	_	_
15-242	8338-8339	`	_	_
15-243	8339-8340	`	_	_
15-244	8340-8341	`	_	_