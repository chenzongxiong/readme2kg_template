#FORMAT=WebAnno TSV 3.3
#T_SP=de.tudarmstadt.ukp.dkpro.core.api.ner.type.NamedEntity|identifier|value


#Text=# The Unhealthy Comments Corpus (UCC)   The Unhealthy Comments Corpus (UCC) is corpus of 44355 comments intended to assist in research on identifying subtle attributes which contribute to unhealthy conversations online.
1-1	0-1	#	_	_
1-2	2-5	The	_	_
1-3	6-15	Unhealthy	_	_
1-4	16-24	Comments	*[17]	EVALMETRIC[17]
1-5	25-31	Corpus	*[17]	EVALMETRIC[17]
1-6	32-33	(	*[17]	EVALMETRIC[17]
1-7	33-36	UCC	*[17]	EVALMETRIC[17]
1-8	36-37	)	*[17]	EVALMETRIC[17]
1-9	40-43	The	*[17]	EVALMETRIC[17]
1-10	44-53	Unhealthy	*[17]	EVALMETRIC[17]
1-11	54-62	Comments	*[17]	EVALMETRIC[17]
1-12	63-69	Corpus	*[17]	EVALMETRIC[17]
1-13	70-71	(	*[17]	EVALMETRIC[17]
1-14	71-74	UCC	*[17]	EVALMETRIC[17]
1-15	74-75	)	*[17]	EVALMETRIC[17]
1-16	76-78	is	*[17]	EVALMETRIC[17]
1-17	79-85	corpus	*[17]	EVALMETRIC[17]
1-18	86-88	of	*[17]	EVALMETRIC[17]
1-19	89-94	44355	*[17]	EVALMETRIC[17]
1-20	95-103	comments	*[17]	EVALMETRIC[17]
1-21	104-112	intended	*[17]	EVALMETRIC[17]
1-22	113-115	to	*[17]	EVALMETRIC[17]
1-23	116-122	assist	*[17]	EVALMETRIC[17]
1-24	123-125	in	*[17]	EVALMETRIC[17]
1-25	126-134	research	*[17]	EVALMETRIC[17]
1-26	135-137	on	*[17]	EVALMETRIC[17]
1-27	138-149	identifying	*[17]	EVALMETRIC[17]
1-28	150-156	subtle	*[17]	EVALMETRIC[17]
1-29	157-167	attributes	_	_
1-30	168-173	which	_	_
1-31	174-184	contribute	_	_
1-32	185-187	to	_	_
1-33	188-197	unhealthy	_	_
1-34	198-211	conversations	_	_
1-35	212-218	online	_	_
1-36	218-219	.	_	_

#Text=Each comment is labelled as either 'healthy' or 'unhealthy', in addition to binary labels for the presence of six potentially 'unhealthy' sub-attributes: (1) hostile\; (2) antagonistic, insulting, provocative or trolling\; (3) dismissive\; (4) condescending or patronising\; (5) sarcastic\; and/or (6) an unfair generalisation.
2-1	222-226	Each	_	_
2-2	227-234	comment	_	_
2-3	235-237	is	_	_
2-4	238-246	labelled	_	_
2-5	247-249	as	_	_
2-6	250-256	either	_	_
2-7	257-258	'	_	_
2-8	258-265	healthy	_	_
2-9	265-266	'	_	_
2-10	267-269	or	_	_
2-11	270-271	'	_	_
2-12	271-280	unhealthy	_	_
2-13	280-281	'	_	_
2-14	281-282	,	_	_
2-15	283-285	in	_	_
2-16	286-294	addition	_	_
2-17	295-297	to	_	_
2-18	298-304	binary	_	_
2-19	305-311	labels	_	_
2-20	312-315	for	_	_
2-21	316-319	the	_	_
2-22	320-328	presence	_	_
2-23	329-331	of	_	_
2-24	332-335	six	_	_
2-25	336-347	potentially	_	_
2-26	348-349	'	*[8]	PROJECT[8]
2-27	349-358	unhealthy	*[8]	PROJECT[8]
2-28	358-359	'	*[8]	PROJECT[8]
2-29	360-374	sub-attributes	_	_
2-30	374-375	:	_	_
2-31	376-377	(	_	_
2-32	377-378	1	_	_
2-33	378-379	)	_	_
2-34	380-387	hostile	_	_
2-35	387-388	\;	_	_
2-36	389-390	(	_	_
2-37	390-391	2	_	_
2-38	391-392	)	_	_
2-39	393-405	antagonistic	_	_
2-40	405-406	,	_	_
2-41	407-416	insulting	_	_
2-42	416-417	,	_	_
2-43	418-429	provocative	_	_
2-44	430-432	or	_	_
2-45	433-441	trolling	_	_
2-46	441-442	\;	_	_
2-47	443-444	(	_	_
2-48	444-445	3	_	_
2-49	445-446	)	_	_
2-50	447-457	dismissive	_	_
2-51	457-458	\;	_	_
2-52	459-460	(	_	_
2-53	460-461	4	_	_
2-54	461-462	)	_	_
2-55	463-476	condescending	_	_
2-56	477-479	or	_	_
2-57	480-491	patronising	_	_
2-58	491-492	\;	_	_
2-59	493-494	(	_	_
2-60	494-495	5	_	_
2-61	495-496	)	_	_
2-62	497-506	sarcastic	_	_
2-63	506-507	\;	_	_
2-64	508-511	and	_	_
2-65	511-512	/	_	_
2-66	512-514	or	_	_
2-67	515-516	(	_	_
2-68	516-517	6	_	_
2-69	517-518	)	_	_
2-70	519-521	an	_	_
2-71	522-528	unfair	_	_
2-72	529-543	generalisation	_	_
2-73	543-544	.	_	_

#Text=Each label also has an associated confidence score.
3-1	545-549	Each	_	_
3-2	550-555	label	*[12]	CONFERENCE[12]
3-3	556-560	also	*[12]	CONFERENCE[12]
3-4	561-564	has	*[12]	CONFERENCE[12]
3-5	565-567	an	*[12]	CONFERENCE[12]
3-6	568-578	associated	_	_
3-7	579-589	confidence	_	_
3-8	590-595	score	_	_
3-9	595-596	.	_	_

#Text=For a detailed description of the annotation process, quality control procedures, summary statistics and baseline modelling results, see our \[paper\](https://arxiv.org/abs/2010.07410), to appear in the \[Fourth Workshop on Online Abuse and Harms 2020\](https://www.workshopononlineabuse.com/).
4-1	598-601	For	_	_
4-2	602-603	a	_	_
4-3	604-612	detailed	_	_
4-4	613-624	description	_	_
4-5	625-627	of	_	_
4-6	628-631	the	_	_
4-7	632-642	annotation	_	_
4-8	643-650	process	_	_
4-9	650-651	,	_	_
4-10	652-659	quality	_	_
4-11	660-667	control	_	_
4-12	668-678	procedures	_	_
4-13	678-679	,	_	_
4-14	680-687	summary	_	_
4-15	688-698	statistics	_	_
4-16	699-702	and	_	_
4-17	703-711	baseline	_	_
4-18	712-721	modelling	_	_
4-19	722-729	results	_	_
4-20	729-730	,	_	_
4-21	731-734	see	_	_
4-22	735-738	our	_	_
4-23	739-740	\[	_	_
4-24	740-745	paper	_	_
4-25	745-746	\]	_	_
4-26	746-747	(	_	_
4-27	747-752	https	_	_
4-28	752-753	:	_	_
4-29	753-754	/	_	_
4-30	754-755	/	_	_
4-31	755-764	arxiv.org	_	_
4-32	764-765	/	_	_
4-33	765-768	abs	_	_
4-34	768-769	/	_	_
4-35	769-779	2010.07410	_	_
4-36	779-780	)	_	_
4-37	780-781	,	_	_
4-38	782-784	to	_	_
4-39	785-791	appear	_	_
4-40	792-794	in	_	_
4-41	795-798	the	_	_
4-42	799-800	\[	_	_
4-43	800-806	Fourth	_	_
4-44	807-815	Workshop	_	_
4-45	816-818	on	_	_
4-46	819-825	Online	_	_
4-47	826-831	Abuse	_	_
4-48	832-835	and	_	_
4-49	836-841	Harms	_	_
4-50	842-846	2020	_	_
4-51	846-847	\]	_	_
4-52	847-848	(	_	_
4-53	848-853	https	_	_
4-54	853-854	:	_	_
4-55	854-855	/	_	_
4-56	855-856	/	_	_
4-57	856-885	www.workshopononlineabuse.com	_	_
4-58	885-886	/	_	_
4-59	886-887	)	_	_
4-60	887-888	.	_	_

#Text=The UCC contributes further high quality data on  attributes  like  sarcasm,  hostility,  and  condescension, adding to existing datasets on these and related attributes, and provides (to the best of our knowledge) the first dataset of this scale with labels for dismissiveness,  unfair generalisations,  antagonistic behavior, and overall assessments of whether those comments fall within 'healthy' conversation.
5-1	890-893	The	_	_
5-2	894-897	UCC	_	_
5-3	898-909	contributes	_	_
5-4	910-917	further	_	_
5-5	918-922	high	_	_
5-6	923-930	quality	_	_
5-7	931-935	data	_	_
5-8	936-938	on	_	_
5-9	940-950	attributes	_	_
5-10	952-956	like	_	_
5-11	958-965	sarcasm	_	_
5-12	965-966	,	_	_
5-13	968-977	hostility	_	_
5-14	977-978	,	_	_
5-15	980-983	and	_	_
5-16	985-998	condescension	_	_
5-17	998-999	,	_	_
5-18	1000-1006	adding	_	_
5-19	1007-1009	to	_	_
5-20	1010-1018	existing	_	_
5-21	1019-1027	datasets	_	_
5-22	1028-1030	on	_	_
5-23	1031-1036	these	_	_
5-24	1037-1040	and	_	_
5-25	1041-1048	related	_	_
5-26	1049-1059	attributes	_	_
5-27	1059-1060	,	_	_
5-28	1061-1064	and	_	_
5-29	1065-1073	provides	_	_
5-30	1074-1075	(	_	_
5-31	1075-1077	to	_	_
5-32	1078-1081	the	_	_
5-33	1082-1086	best	_	_
5-34	1087-1089	of	*[5]	DATASET[5]
5-35	1090-1093	our	*[5]	DATASET[5]
5-36	1094-1103	knowledge	*[5]	DATASET[5]
5-37	1103-1104	)	*[5]	DATASET[5]
5-38	1105-1108	the	*[5]	DATASET[5]
5-39	1109-1114	first	*[5]	DATASET[5]
5-40	1115-1122	dataset	*[5]	DATASET[5]
5-41	1123-1125	of	*[5]	DATASET[5]
5-42	1126-1130	this	*[5]	DATASET[5]
5-43	1131-1136	scale	*[5]	DATASET[5]
5-44	1137-1141	with	*[5]	DATASET[5]
5-45	1142-1148	labels	*[5]	DATASET[5]
5-46	1149-1152	for	*[5]	DATASET[5]
5-47	1153-1167	dismissiveness	*[5]	DATASET[5]
5-48	1167-1168	,	*[5]	DATASET[5]
5-49	1170-1176	unfair	*[5]	DATASET[5]
5-50	1177-1192	generalisations	_	_
5-51	1192-1193	,	_	_
5-52	1195-1207	antagonistic	_	_
5-53	1208-1216	behavior	_	_
5-54	1216-1217	,	_	_
5-55	1218-1221	and	_	_
5-56	1222-1229	overall	_	_
5-57	1230-1241	assessments	_	_
5-58	1242-1244	of	_	_
5-59	1245-1252	whether	_	_
5-60	1253-1258	those	_	_
5-61	1259-1267	comments	_	_
5-62	1268-1272	fall	_	_
5-63	1273-1279	within	_	_
5-64	1280-1281	'	_	_
5-65	1281-1288	healthy	_	_
5-66	1288-1289	'	_	_
5-67	1290-1302	conversation	_	_
5-68	1302-1303	.	_	_

#Text=We hope that this dataset  can contribute to research on how to understand, monitor and deal with unhealthy online interactions to promote healthier conversations online.  ## The data  The dataset is provided as three .csv files, `train.csv`, `test.csv`, and `val.csv`.
6-1	1305-1307	We	_	_
6-2	1308-1312	hope	_	_
6-3	1313-1317	that	_	_
6-4	1318-1322	this	_	_
6-5	1323-1330	dataset	_	_
6-6	1332-1335	can	_	_
6-7	1336-1346	contribute	_	_
6-8	1347-1349	to	_	_
6-9	1350-1358	research	_	_
6-10	1359-1361	on	_	_
6-11	1362-1365	how	_	_
6-12	1366-1368	to	_	_
6-13	1369-1379	understand	_	_
6-14	1379-1380	,	_	_
6-15	1381-1388	monitor	_	_
6-16	1389-1392	and	_	_
6-17	1393-1397	deal	_	_
6-18	1398-1402	with	_	_
6-19	1403-1412	unhealthy	_	_
6-20	1413-1419	online	_	_
6-21	1420-1432	interactions	_	_
6-22	1433-1435	to	_	_
6-23	1436-1443	promote	_	_
6-24	1444-1453	healthier	_	_
6-25	1454-1467	conversations	_	_
6-26	1468-1474	online	_	_
6-27	1474-1475	.	_	_
6-28	1477-1478	#	_	_
6-29	1478-1479	#	_	_
6-30	1480-1483	The	_	_
6-31	1484-1488	data	_	_
6-32	1490-1493	The	_	_
6-33	1494-1501	dataset	_	_
6-34	1502-1504	is	_	_
6-35	1505-1513	provided	_	_
6-36	1514-1516	as	_	_
6-37	1517-1522	three	_	_
6-38	1523-1524	.	_	_
6-39	1524-1527	csv	_	_
6-40	1528-1533	files	_	_
6-41	1533-1534	,	_	_
6-42	1535-1536	`	_	_
6-43	1536-1545	train.csv	_	_
6-44	1545-1546	`	_	_
6-45	1546-1547	,	_	_
6-46	1548-1549	`	_	_
6-47	1549-1557	test.csv	_	_
6-48	1557-1558	`	_	_
6-49	1558-1559	,	_	_
6-50	1560-1563	and	_	_
6-51	1564-1565	`	*[9]	PROJECT[9]
6-52	1565-1572	val.csv	_	_
6-53	1572-1573	`	_	_
6-54	1573-1574	.	_	_

#Text=In addition to labels and confidence scores for each of the above-mentioned attributes, each comment includes the number of trusted judgements which were aggregated to yield the results labels and confidence scores (see paper for details).
7-1	1575-1577	In	_	_
7-2	1578-1586	addition	_	_
7-3	1587-1589	to	_	_
7-4	1590-1596	labels	_	_
7-5	1597-1600	and	_	_
7-6	1601-1611	confidence	_	_
7-7	1612-1618	scores	_	_
7-8	1619-1622	for	_	_
7-9	1623-1627	each	_	_
7-10	1628-1630	of	_	_
7-11	1631-1634	the	_	_
7-12	1635-1650	above-mentioned	_	_
7-13	1651-1661	attributes	_	_
7-14	1661-1662	,	_	_
7-15	1663-1667	each	_	_
7-16	1668-1675	comment	_	_
7-17	1676-1684	includes	_	_
7-18	1685-1688	the	*[14]	EVALMETRIC[14]
7-19	1689-1695	number	*[14]	EVALMETRIC[14]
7-20	1696-1698	of	*[14]	EVALMETRIC[14]
7-21	1699-1706	trusted	_	_
7-22	1707-1717	judgements	_	_
7-23	1718-1723	which	_	_
7-24	1724-1728	were	_	_
7-25	1729-1739	aggregated	_	_
7-26	1740-1742	to	_	_
7-27	1743-1748	yield	_	_
7-28	1749-1752	the	_	_
7-29	1753-1760	results	_	_
7-30	1761-1767	labels	_	_
7-31	1768-1771	and	_	_
7-32	1772-1782	confidence	_	_
7-33	1783-1789	scores	_	_
7-34	1790-1791	(	_	_
7-35	1791-1794	see	_	_
7-36	1795-1800	paper	_	_
7-37	1801-1804	for	_	_
7-38	1805-1812	details	_	_
7-39	1812-1813	)	_	_
7-40	1813-1814	.	_	_

#Text=We also provide the individual annotations of each comment in `unhealthy\_full.csv`.
8-1	1817-1819	We	_	_
8-2	1820-1824	also	_	_
8-3	1825-1832	provide	_	_
8-4	1833-1836	the	_	_
8-5	1837-1847	individual	_	_
8-6	1848-1859	annotations	_	_
8-7	1860-1862	of	_	_
8-8	1863-1867	each	_	_
8-9	1868-1875	comment	_	_
8-10	1876-1878	in	_	_
8-11	1879-1880	`	_	_
8-12	1880-1898	unhealthy\_full.csv	_	_
8-13	1898-1899	`	_	_
8-14	1899-1900	.	_	_

#Text=This contains all individual judgements which were aggregated to create the final dataset.
9-1	1901-1905	This	_	_
9-2	1906-1914	contains	_	_
9-3	1915-1918	all	_	_
9-4	1919-1929	individual	_	_
9-5	1930-1940	judgements	_	_
9-6	1941-1946	which	_	_
9-7	1947-1951	were	_	_
9-8	1952-1962	aggregated	_	_
9-9	1963-1965	to	_	_
9-10	1966-1972	create	_	_
9-11	1973-1976	the	_	_
9-12	1977-1982	final	_	_
9-13	1983-1990	dataset	_	_
9-14	1990-1991	.	_	_

#Text=Each of these annotations includes the trustworthiness score of the annotator, allowing users to impose higher trustworthiness thresholds or apply different aggregation methods as desired.
10-1	1992-1996	Each	_	_
10-2	1997-1999	of	_	_
10-3	2000-2005	these	_	_
10-4	2006-2017	annotations	_	_
10-5	2018-2026	includes	_	_
10-6	2027-2030	the	_	_
10-7	2031-2046	trustworthiness	_	_
10-8	2047-2052	score	_	_
10-9	2053-2055	of	_	_
10-10	2056-2059	the	_	_
10-11	2060-2069	annotator	_	_
10-12	2069-2070	,	_	_
10-13	2071-2079	allowing	_	_
10-14	2080-2085	users	_	_
10-15	2086-2088	to	_	_
10-16	2089-2095	impose	_	_
10-17	2096-2102	higher	_	_
10-18	2103-2118	trustworthiness	_	_
10-19	2119-2129	thresholds	_	_
10-20	2130-2132	or	_	_
10-21	2133-2138	apply	_	_
10-22	2139-2148	different	_	_
10-23	2149-2160	aggregation	_	_
10-24	2161-2168	methods	_	_
10-25	2169-2171	as	_	_
10-26	2172-2179	desired	_	_
10-27	2179-2180	.	_	_

#Text=The raw comments were taken from the \[comments\](https://github.com/sfu-discourse-lab/SOCC#comments) corpus within the \[SFU Opinion and Comments Corpus\](https://github.com/sfu-discourse-lab/SOCC).   ## Baseline classification  We provide notebooks to replicate our baseline classification results on this dataset in `UnhealthyConversations.ipynb`.
11-1	2182-2185	The	_	_
11-2	2186-2189	raw	_	_
11-3	2190-2198	comments	_	_
11-4	2199-2203	were	_	_
11-5	2204-2209	taken	_	_
11-6	2210-2214	from	_	_
11-7	2215-2218	the	_	_
11-8	2219-2220	\[	_	_
11-9	2220-2228	comments	_	_
11-10	2228-2229	\]	_	_
11-11	2229-2230	(	_	_
11-12	2230-2235	https	_	_
11-13	2235-2236	:	_	_
11-14	2236-2237	/	_	_
11-15	2237-2238	/	_	_
11-16	2238-2248	github.com	_	_
11-17	2248-2249	/	_	_
11-18	2249-2266	sfu-discourse-lab	_	_
11-19	2266-2267	/	_	_
11-20	2267-2271	SOCC	_	_
11-21	2271-2272	#	_	_
11-22	2272-2280	comments	_	_
11-23	2280-2281	)	_	_
11-24	2282-2288	corpus	_	_
11-25	2289-2295	within	_	_
11-26	2296-2299	the	_	_
11-27	2300-2301	\[	_	_
11-28	2301-2304	SFU	_	_
11-29	2305-2312	Opinion	_	_
11-30	2313-2316	and	_	_
11-31	2317-2325	Comments	_	_
11-32	2326-2332	Corpus	_	_
11-33	2332-2333	\]	_	_
11-34	2333-2334	(	_	_
11-35	2334-2339	https	_	_
11-36	2339-2340	:	_	_
11-37	2340-2341	/	_	_
11-38	2341-2342	/	_	_
11-39	2342-2352	github.com	_	_
11-40	2352-2353	/	_	_
11-41	2353-2370	sfu-discourse-lab	_	_
11-42	2370-2371	/	_	_
11-43	2371-2375	SOCC	_	_
11-44	2375-2376	)	_	_
11-45	2376-2377	.	_	_
11-46	2380-2381	#	_	_
11-47	2381-2382	#	_	_
11-48	2383-2391	Baseline	_	_
11-49	2392-2406	classification	_	_
11-50	2408-2410	We	_	_
11-51	2411-2418	provide	_	_
11-52	2419-2428	notebooks	_	_
11-53	2429-2431	to	_	_
11-54	2432-2441	replicate	_	_
11-55	2442-2445	our	_	_
11-56	2446-2454	baseline	_	_
11-57	2455-2469	classification	_	_
11-58	2470-2477	results	_	_
11-59	2478-2480	on	_	_
11-60	2481-2485	this	_	_
11-61	2486-2493	dataset	_	_
11-62	2494-2496	in	_	_
11-63	2497-2498	`	_	_
11-64	2498-2526	UnhealthyConversations.ipynb	_	_
11-65	2526-2527	`	_	_
11-66	2527-2528	.	_	_

#Text=Fine-tuning pre-trained BERT produces classifiers with modest performance compared to the state of the art for sequence classification.
12-1	2529-2540	Fine-tuning	_	_
12-2	2541-2552	pre-trained	_	_
12-3	2553-2557	BERT	*[14]	LICENSE[14]
12-4	2558-2566	produces	*[14]	LICENSE[14]
12-5	2567-2578	classifiers	*[14]	LICENSE[14]
12-6	2579-2583	with	*[14]	LICENSE[14]
12-7	2584-2590	modest	*[14]	LICENSE[14]
12-8	2591-2602	performance	*[14]	LICENSE[14]
12-9	2603-2611	compared	*[14]	LICENSE[14]
12-10	2612-2614	to	*[14]	LICENSE[14]
12-11	2615-2618	the	*[14]	LICENSE[14]
12-12	2619-2624	state	*[14]	LICENSE[14]
12-13	2625-2627	of	*[14]	LICENSE[14]
12-14	2628-2631	the	*[14]	LICENSE[14]
12-15	2632-2635	art	*[14]	LICENSE[14]
12-16	2636-2639	for	*[14]	LICENSE[14]
12-17	2640-2648	sequence	*[14]	LICENSE[14]
12-18	2649-2663	classification	_	_
12-19	2663-2664	.	_	_

#Text=The best performing attributes, 'hostile' and 'antagonistic' are also those most similar to the types of attributes typically annotated in comment classification work.
13-1	2665-2668	The	_	_
13-2	2669-2673	best	_	_
13-3	2674-2684	performing	_	_
13-4	2685-2695	attributes	_	_
13-5	2695-2696	,	_	_
13-6	2697-2698	'	_	_
13-7	2698-2705	hostile	_	_
13-8	2705-2706	'	_	_
13-9	2707-2710	and	_	_
13-10	2711-2712	'	_	_
13-11	2712-2724	antagonistic	_	_
13-12	2724-2725	'	_	_
13-13	2726-2729	are	_	_
13-14	2730-2734	also	_	_
13-15	2735-2740	those	_	_
13-16	2741-2745	most	_	_
13-17	2746-2753	similar	_	_
13-18	2754-2756	to	_	_
13-19	2757-2760	the	_	_
13-20	2761-2766	types	_	_
13-21	2767-2769	of	_	_
13-22	2770-2780	attributes	_	_
13-23	2781-2790	typically	*[6]	DATASET[6]
13-24	2791-2800	annotated	_	_
13-25	2801-2803	in	_	_
13-26	2804-2811	comment	_	_
13-27	2812-2826	classification	_	_
13-28	2827-2831	work	_	_
13-29	2831-2832	.	_	_

#Text=The other attributes seem to cluster together, with the ‘sarcastic’ label particularly noteworthy for its low performance. \[!
14-1	2833-2836	The	_	_
14-2	2837-2842	other	_	_
14-3	2843-2853	attributes	_	_
14-4	2854-2858	seem	_	_
14-5	2859-2861	to	_	_
14-6	2862-2869	cluster	_	_
14-7	2870-2878	together	_	_
14-8	2878-2879	,	_	_
14-9	2880-2884	with	_	_
14-10	2885-2888	the	_	_
14-11	2889-2890	‘	_	_
14-12	2890-2899	sarcastic	_	_
14-13	2899-2900	’	_	_
14-14	2901-2906	label	_	_
14-15	2907-2919	particularly	_	_
14-16	2920-2930	noteworthy	_	_
14-17	2931-2934	for	_	_
14-18	2935-2938	its	_	_
14-19	2939-2942	low	_	_
14-20	2943-2954	performance	_	_
14-21	2954-2955	.	_	_
14-22	2956-2957	\[	_	_
14-23	2957-2958	!	_	_

#Text=\[Open In Colab\](https://colab.research.google.com/assets/colab-badge.svg)\](https://colab.research.google.com/github/conversationai/unhealthy-conversations/blob/master/notebooks/UnhealthyConversations.ipynb)   !
15-1	2958-2959	\[	_	_
15-2	2959-2963	Open	_	_
15-3	2964-2966	In	_	_
15-4	2967-2972	Colab	_	_
15-5	2972-2973	\]	_	_
15-6	2973-2974	(	_	_
15-7	2974-2979	https	_	_
15-8	2979-2980	:	_	_
15-9	2980-2981	/	_	_
15-10	2981-2982	/	_	_
15-11	2982-3007	colab.research.google.com	_	_
15-12	3007-3008	/	*[15]	EVALMETRIC[15]
15-13	3008-3014	assets	*[15]	EVALMETRIC[15]
15-14	3014-3015	/	*[15]	EVALMETRIC[15]
15-15	3015-3030	colab-badge.svg	_	_
15-16	3030-3031	)	_	_
15-17	3031-3032	\]	_	_
15-18	3032-3033	(	_	_
15-19	3033-3038	https	_	_
15-20	3038-3039	:	_	_
15-21	3039-3040	/	_	_
15-22	3040-3041	/	_	_
15-23	3041-3066	colab.research.google.com	_	_
15-24	3066-3067	/	_	_
15-25	3067-3073	github	_	_
15-26	3073-3074	/	_	_
15-27	3074-3088	conversationai	_	_
15-28	3088-3089	/	_	_
15-29	3089-3112	unhealthy-conversations	_	_
15-30	3112-3113	/	_	_
15-31	3113-3117	blob	_	_
15-32	3117-3118	/	_	_
15-33	3118-3124	master	_	_
15-34	3124-3125	/	_	_
15-35	3125-3134	notebooks	_	_
15-36	3134-3135	/	_	_
15-37	3135-3163	UnhealthyConversations.ipynb	_	_
15-38	3163-3164	)	_	_
15-39	3167-3168	!	_	_

#Text=\[Figure here\](https://github.com/conversationai/unhealthy-conversations/blob/master/auc.pdf)  To give context to the model performance, we compare the performance with human workers.
16-1	3168-3169	\[	_	_
16-2	3169-3175	Figure	_	_
16-3	3176-3180	here	_	_
16-4	3180-3181	\]	_	_
16-5	3181-3182	(	_	_
16-6	3182-3187	https	_	_
16-7	3187-3188	:	_	_
16-8	3188-3189	/	_	_
16-9	3189-3190	/	_	_
16-10	3190-3200	github.com	_	_
16-11	3200-3201	/	_	_
16-12	3201-3215	conversationai	_	_
16-13	3215-3216	/	_	_
16-14	3216-3239	unhealthy-conversations	_	_
16-15	3239-3240	/	_	_
16-16	3240-3244	blob	_	_
16-17	3244-3245	/	_	_
16-18	3245-3251	master	_	_
16-19	3251-3252	/	_	_
16-20	3252-3259	auc.pdf	_	_
16-21	3259-3260	)	_	_
16-22	3262-3264	To	_	_
16-23	3265-3269	give	_	_
16-24	3270-3277	context	_	_
16-25	3278-3280	to	_	_
16-26	3281-3284	the	_	_
16-27	3285-3290	model	_	_
16-28	3291-3302	performance	_	_
16-29	3302-3303	,	_	_
16-30	3304-3306	we	_	_
16-31	3307-3314	compare	_	_
16-32	3315-3318	the	_	_
16-33	3319-3330	performance	*[15]	LICENSE[15]
16-34	3331-3335	with	*[15]	LICENSE[15]
16-35	3336-3341	human	*[15]	LICENSE[15]
16-36	3342-3349	workers	_	_
16-37	3349-3350	.	_	_

#Text=For each comment, we randomly hold out one annotator to act as our 'human model' and use the aggregated score of the other annotators as the ground truth to compute the ROC AUC (repeated 5 times then averaged).
17-1	3351-3354	For	_	_
17-2	3355-3359	each	_	_
17-3	3360-3367	comment	_	_
17-4	3367-3368	,	_	_
17-5	3369-3371	we	_	_
17-6	3372-3380	randomly	_	_
17-7	3381-3385	hold	_	_
17-8	3386-3389	out	_	_
17-9	3390-3393	one	_	_
17-10	3394-3403	annotator	_	_
17-11	3404-3406	to	_	_
17-12	3407-3410	act	_	_
17-13	3411-3413	as	_	_
17-14	3414-3417	our	_	_
17-15	3418-3419	'	_	_
17-16	3419-3424	human	_	_
17-17	3425-3430	model	_	_
17-18	3430-3431	'	_	_
17-19	3432-3435	and	_	_
17-20	3436-3439	use	_	_
17-21	3440-3443	the	_	_
17-22	3444-3454	aggregated	_	_
17-23	3455-3460	score	_	_
17-24	3461-3463	of	_	_
17-25	3464-3467	the	_	_
17-26	3468-3473	other	_	_
17-27	3474-3484	annotators	_	_
17-28	3485-3487	as	_	_
17-29	3488-3491	the	_	_
17-30	3492-3498	ground	_	_
17-31	3499-3504	truth	*[4]	WORKSHOP[4]
17-32	3505-3507	to	*[4]	WORKSHOP[4]
17-33	3508-3515	compute	*[4]	WORKSHOP[4]
17-34	3516-3519	the	*[4]	WORKSHOP[4]
17-35	3520-3523	ROC	*[4]	WORKSHOP[4]
17-36	3524-3527	AUC	*[4]	WORKSHOP[4]
17-37	3528-3529	(	*[4]	WORKSHOP[4]
17-38	3529-3537	repeated	*[4]	WORKSHOP[4]
17-39	3538-3539	5	*[4]	WORKSHOP[4]
17-40	3540-3545	times	*[4]	WORKSHOP[4]
17-41	3546-3550	then	*[4]	WORKSHOP[4]
17-42	3551-3559	averaged	_	_
17-43	3559-3560	)	_	_
17-44	3560-3561	.	_	_

#Text=We use the same test sets to compute the ROC AUC of the trained BERT model and average those scores as well.
18-1	3562-3564	We	_	_
18-2	3565-3568	use	_	_
18-3	3569-3572	the	_	_
18-4	3573-3577	same	_	_
18-5	3578-3582	test	_	_
18-6	3583-3587	sets	_	_
18-7	3588-3590	to	_	_
18-8	3591-3598	compute	_	_
18-9	3599-3602	the	_	_
18-10	3603-3606	ROC	_	_
18-11	3607-3610	AUC	_	_
18-12	3611-3613	of	_	_
18-13	3614-3617	the	_	_
18-14	3618-3625	trained	_	_
18-15	3626-3630	BERT	*[11]	PROJECT[11]
18-16	3631-3636	model	*[11]	PROJECT[11]
18-17	3637-3640	and	*[11]	PROJECT[11]
18-18	3641-3648	average	*[11]	PROJECT[11]
18-19	3649-3654	those	*[11]	PROJECT[11]
18-20	3655-3661	scores	*[11]	PROJECT[11]
18-21	3662-3664	as	_	_
18-22	3665-3669	well	_	_
18-23	3669-3670	.	_	_

#Text=As we can see, for all attributes other than 'sarcastic' the BERT model outperforms a randomly selected human annotator, indicating that it has sufficiently captured the semantic and syntactic structures for these attributes.
19-1	3671-3673	As	_	_
19-2	3674-3676	we	_	_
19-3	3677-3680	can	_	_
19-4	3681-3684	see	_	_
19-5	3684-3685	,	_	_
19-6	3686-3689	for	_	_
19-7	3690-3693	all	_	_
19-8	3694-3704	attributes	_	_
19-9	3705-3710	other	_	_
19-10	3711-3715	than	_	_
19-11	3716-3717	'	_	_
19-12	3717-3726	sarcastic	_	_
19-13	3726-3727	'	_	_
19-14	3728-3731	the	_	_
19-15	3732-3736	BERT	_	_
19-16	3737-3742	model	_	_
19-17	3743-3754	outperforms	_	_
19-18	3755-3756	a	_	_
19-19	3757-3765	randomly	_	_
19-20	3766-3774	selected	_	_
19-21	3775-3780	human	_	_
19-22	3781-3790	annotator	_	_
19-23	3790-3791	,	_	_
19-24	3792-3802	indicating	_	_
19-25	3803-3807	that	_	_
19-26	3808-3810	it	_	_
19-27	3811-3814	has	_	_
19-28	3815-3827	sufficiently	_	_
19-29	3828-3836	captured	_	_
19-30	3837-3840	the	_	_
19-31	3841-3849	semantic	*[16]	EVALMETRIC[16]
19-32	3850-3853	and	*[16]	EVALMETRIC[16]
19-33	3854-3863	syntactic	*[16]	EVALMETRIC[16]
19-34	3864-3874	structures	*[16]	EVALMETRIC[16]
19-35	3875-3878	for	*[16]	EVALMETRIC[16]
19-36	3879-3884	these	_	_
19-37	3885-3895	attributes	_	_
19-38	3895-3896	.	_	_

#Text=For 'sarcastic', the gap between the BERT model and human annotators indicates a rich area for studying whether model performance can be improved
20-1	3897-3900	For	_	_
20-2	3901-3902	'	_	_
20-3	3902-3911	sarcastic	_	_
20-4	3911-3912	'	_	_
20-5	3912-3913	,	_	_
20-6	3914-3917	the	_	_
20-7	3918-3921	gap	_	_
20-8	3922-3929	between	_	_
20-9	3930-3933	the	_	_
20-10	3934-3938	BERT	_	_
20-11	3939-3944	model	_	_
20-12	3945-3948	and	_	_
20-13	3949-3954	human	_	_
20-14	3955-3965	annotators	_	_
20-15	3966-3975	indicates	_	_
20-16	3976-3977	a	*[12]	PROJECT[12]
20-17	3978-3982	rich	_	_
20-18	3983-3987	area	_	_
20-19	3988-3991	for	_	_
20-20	3992-4000	studying	_	_
20-21	4001-4008	whether	_	_
20-22	4009-4014	model	_	_
20-23	4015-4026	performance	_	_
20-24	4027-4030	can	_	_
20-25	4031-4033	be	_	_
20-26	4034-4042	improved	_	_

#Text=.
21-1	4042-4043	.	_	_

#Text=\| Attribute}  \| Human AUC \| BERT AUC \| \|------------ \|-----------\|----------\| \|Antagonistic \|0.71       \|  0.82    \|  \|Condescending\| 0.72      \|    0.78  \| \|Dismissive   \| 0.68      \| 0.82     \| \|Generalisation \| 0.73    \| 0.74     \| \|Hostile       \|0.76      \|0.84      \| \|Sarcastic     \|0.72      \|0.64      \| \|Unhealthy     \| 0.62     \| 0.69   \|   Code for  this analysis is in `AUC\_analysis.ipynb`.  \_\_\_\_\_   This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. https://creativecommons.org/licenses/by-nc-sa/4.0/
22-1	4045-4046	\|	_	_
22-2	4047-4056	Attribute	_	_
22-3	4056-4057	}	_	_
22-4	4059-4060	\|	_	_
22-5	4061-4066	Human	_	_
22-6	4067-4070	AUC	_	_
22-7	4071-4072	\|	_	_
22-8	4073-4077	BERT	_	_
22-9	4078-4081	AUC	_	_
22-10	4082-4083	\|	_	_
22-11	4084-4085	\|	_	_
22-12	4085-4086	-	_	_
22-13	4086-4087	-	_	_
22-14	4087-4088	-	_	_
22-15	4088-4089	-	_	_
22-16	4089-4090	-	_	_
22-17	4090-4091	-	_	_
22-18	4091-4092	-	_	_
22-19	4092-4093	-	_	_
22-20	4093-4094	-	_	_
22-21	4094-4095	-	_	_
22-22	4095-4096	-	_	_
22-23	4096-4097	-	_	_
22-24	4098-4099	\|	_	_
22-25	4099-4100	-	_	_
22-26	4100-4101	-	_	_
22-27	4101-4102	-	_	_
22-28	4102-4103	-	_	_
22-29	4103-4104	-	_	_
22-30	4104-4105	-	_	_
22-31	4105-4106	-	_	_
22-32	4106-4107	-	_	_
22-33	4107-4108	-	_	_
22-34	4108-4109	-	_	_
22-35	4109-4110	-	_	_
22-36	4110-4111	\|	_	_
22-37	4111-4112	-	_	_
22-38	4112-4113	-	_	_
22-39	4113-4114	-	_	_
22-40	4114-4115	-	_	_
22-41	4115-4116	-	_	_
22-42	4116-4117	-	_	_
22-43	4117-4118	-	_	_
22-44	4118-4119	-	_	_
22-45	4119-4120	-	_	_
22-46	4120-4121	-	_	_
22-47	4121-4122	\|	_	_
22-48	4123-4124	\|	_	_
22-49	4124-4136	Antagonistic	_	_
22-50	4137-4138	\|	_	_
22-51	4138-4142	0.71	_	_
22-52	4149-4150	\|	_	_
22-53	4152-4156	0.82	_	_
22-54	4160-4161	\|	_	_
22-55	4163-4164	\|	_	_
22-56	4164-4177	Condescending	_	_
22-57	4177-4178	\|	_	_
22-58	4179-4183	0.72	_	_
22-59	4189-4190	\|	_	_
22-60	4194-4198	0.78	_	_
22-61	4200-4201	\|	_	_
22-62	4202-4203	\|	_	_
22-63	4203-4213	Dismissive	_	_
22-64	4216-4217	\|	_	_
22-65	4218-4222	0.68	_	_
22-66	4228-4229	\|	_	_
22-67	4230-4234	0.82	_	_
22-68	4239-4240	\|	_	_
22-69	4241-4242	\|	_	_
22-70	4242-4256	Generalisation	_	_
22-71	4257-4258	\|	_	_
22-72	4259-4263	0.73	_	_
22-73	4267-4268	\|	_	_
22-74	4269-4273	0.74	_	_
22-75	4278-4279	\|	_	_
22-76	4280-4281	\|	_	_
22-77	4281-4288	Hostile	_	_
22-78	4295-4296	\|	_	_
22-79	4296-4300	0.76	_	_
22-80	4306-4307	\|	_	_
22-81	4307-4311	0.84	_	_
22-82	4317-4318	\|	_	_
22-83	4319-4320	\|	_	_
22-84	4320-4329	Sarcastic	_	_
22-85	4334-4335	\|	_	_
22-86	4335-4339	0.72	_	_
22-87	4345-4346	\|	_	_
22-88	4346-4350	0.64	_	_
22-89	4356-4357	\|	_	_
22-90	4358-4359	\|	_	_
22-91	4359-4368	Unhealthy	_	_
22-92	4373-4374	\|	_	_
22-93	4375-4379	0.62	_	_
22-94	4384-4385	\|	_	_
22-95	4386-4390	0.69	_	_
22-96	4393-4394	\|	_	_
22-97	4397-4401	Code	_	_
22-98	4402-4405	for	_	_
22-99	4407-4411	this	_	_
22-100	4412-4420	analysis	_	_
22-101	4421-4423	is	_	_
22-102	4424-4426	in	_	_
22-103	4427-4428	`	_	_
22-104	4428-4446	AUC\_analysis.ipynb	_	_
22-104	4428-4431	AUC	_	_
22-105	4446-4447	`	_	_
22-106	4447-4448	.	_	_
22-107	4450-4451	\_	_	_
22-108	4451-4452	\_	_	_
22-109	4452-4453	\_	_	_
22-110	4453-4454	\_	_	_
22-111	4454-4455	\_	_	_
22-112	4458-4462	This	_	_
22-113	4463-4467	work	_	_
22-114	4468-4470	is	_	_
22-115	4471-4479	licensed	_	_
22-116	4480-4485	under	_	_
22-117	4486-4487	a	_	_
22-118	4488-4496	Creative	_	_
22-119	4497-4504	Commons	_	_
22-120	4505-4541	Attribution-NonCommercial-ShareAlike	_	_
22-121	4542-4545	4.0	_	_
22-122	4546-4559	International	_	_
22-123	4560-4567	License	_	_
22-124	4567-4568	.	_	_
22-125	4569-4574	https	_	_
22-126	4574-4575	:	_	_
22-127	4575-4576	/	_	_
22-128	4576-4577	/	_	_
22-129	4577-4596	creativecommons.org	*[14]	CONFERENCE[14]
22-130	4596-4597	/	*[14]	CONFERENCE[14]
22-131	4597-4605	licenses	_	_
22-132	4605-4606	/	_	_
22-133	4606-4614	by-nc-sa	_	_
22-134	4614-4615	/	_	_
22-135	4615-4618	4.0	_	_
22-136	4618-4619	/	_	_